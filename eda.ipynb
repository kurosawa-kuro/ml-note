{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "uch3chw3wf",
   "source": "# ğŸ† CMI BFRB Detection - EDAç·æ‹¬\n\n## ğŸ“Š é‡è¦ãªç™ºè¦‹äº‹é …\n\n### âœ… ãƒ‡ãƒ¼ã‚¿å“è³ª\n- **é«˜å“è³ªIMUãƒ‡ãƒ¼ã‚¿**: åŠ é€Ÿåº¦ã‚»ãƒ³ã‚µãƒ¼ã¯æ¬ æå€¤0%ã€ä¿¡é ¼æ€§ã®é«˜ã„ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³\n- **éƒ¨åˆ†çš„ã‚»ãƒ³ã‚µãƒ¼æ•…éšœ**: ToF_5ã¨thm_5ãŒ5%ä»¥ä¸Šæ¬ æ â†’ è£œå®Œæˆ¦ç•¥å¿…è¦\n- **æ™‚ç³»åˆ—é€£ç¶šæ€§**: ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å†…ã§ã‚®ãƒ£ãƒƒãƒ—ãªã—ã€50Hzä¸€å®šã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n\n### ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ç‰¹æ€§\n- **ãƒã‚¤ãƒŠãƒªåˆ†é¡**: Target/Non-Target = 60/40 â†’ Binary F1ã¯é”æˆå¯èƒ½\n- **ãƒãƒ«ãƒã‚¯ãƒ©ã‚¹åˆ†é¡**: 18ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã€6:1ã®ä¸å‡è¡¡ â†’ Macro F1ãŒå›°é›£\n- **æ™‚ç³»åˆ—æ§‹é€ **: å¹³å‡1.4ç§’ã®çŸ­ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ â†’ ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼èªè­˜ã‚¿ã‚¹ã‚¯\n\n### ğŸ‘¥ å‚åŠ è€…ãƒ‡ãƒ¼ã‚¿\n- **å®Œå…¨åˆ†é›¢**: è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆé–“ã§å‚åŠ è€…é‡è¤‡ãªã— âœ…\n- **å‡ç­‰åˆ†å¸ƒ**: å‚åŠ è€…é–“ãƒ‡ãƒ¼ã‚¿é‡ã¯æ¯”è¼ƒçš„ãƒãƒ©ãƒ³ã‚¹è‰¯å¥½\n- **å…¨ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚«ãƒãƒ¼**: å…¨å‚åŠ è€…ãŒå…¨ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã‚¿ã‚¤ãƒ—ã‚’å®Ÿè¡Œ\n\n### ğŸ”— ã‚»ãƒ³ã‚µãƒ¼ç›¸é–¢\n- **ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ä½ç›¸é–¢**: IMU/ToF/æ¸©åº¦ã¯è£œå®Œçš„æƒ…å ±ã‚’æä¾›\n- **ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£**: æ·±åˆ»ãªå•é¡Œãªã—ã€èåˆã«é©ã—ã¦ã„ã‚‹\n\n---\n\n## ğŸ¯ ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³æˆ¦ç•¥\n\n### ğŸ“ˆ ç›®æ¨™ã‚¹ã‚³ã‚¢\n- **ç¾å®Ÿçš„ç›®æ¨™**: Combined F1 = 0.60-0.65 (éŠ…ãƒ¡ãƒ€ãƒ«åœ)\n- **Binary F1**: 0.65-0.70 (æ¯”è¼ƒçš„é”æˆã—ã‚„ã™ã„)\n- **Macro F1**: 0.55-0.65 (18ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã§å›°é›£)\n\n### ğŸ—ï¸ æ¨å¥¨ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ\n\n#### Phase 1: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ§‹ç¯‰ (Week 1)\n1. **GroupKFold CV** ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ— (participant-based)\n2. **åŸºæœ¬ç‰¹å¾´é‡**: IMU magnitude, rolling statistics\n3. **LightGBM** with missing value handling\n4. **ç›®æ¨™**: CV 0.50+, LB 0.50+\n\n#### Phase 2: ç‰¹å¾´å·¥å­¦ (Week 2-3)\n1. **FFT spectrum** features for IMU\n2. **ToF PCA** dimensionality reduction  \n3. **Multimodal fusion** features\n4. **1D CNN** on raw sensor streams\n5. **ç›®æ¨™**: CV 0.58+, LB 0.57+\n\n#### Phase 3: ãƒ¢ãƒ‡ãƒ«æœ€é©åŒ– (Week 4-5)\n1. **Multi-branch CNN** (IMU/ToF/Thermopile separate)\n2. **Ensemble** multiple models\n3. **Hyperparameter tuning**\n4. **ç›®æ¨™**: CV 0.62+, LB 0.60+ (éŠ…ãƒ¡ãƒ€ãƒ«)\n\n---\n\n## âš ï¸ é‡è¦ãªæ³¨æ„ç‚¹\n\n### ğŸš¨ ãƒªã‚¹ã‚¯è¦å› \n1. **Macro F1 difficulty**: 18ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã«ã‚ˆã‚Š0.5ä»¥ä¸‹ã®å¯èƒ½æ€§\n2. **Sensor 5 missing**: ToF_5/thm_5æ¬ æã«ã‚ˆã‚‹æƒ…å ±æå¤±  \n3. **CV-LB gap**: äººãƒ™ãƒ¼ã‚¹GroupKFoldã§ã‚ºãƒ¬å¯èƒ½æ€§\n\n### ğŸ›¡ï¸ å¯¾ç­–\n1. **ã‚¯ãƒ©ã‚¹é‡ã¿èª¿æ•´**: Macro F1å‘ä¸Šã®ãŸã‚focal lossç­‰\n2. **æ¬ æå€¤æˆ¦ç•¥**: imputation + availability indicators\n3. **CV robustness**: è¤‡æ•°ã‚·ãƒ¼ãƒ‰ã€foldåˆ†æ•£ç›£è¦–\n\n---\n\n## ğŸ¯ Next Steps\n\n1. **ç‰¹å¾´å·¥å­¦ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** å®Ÿè£…é–‹å§‹\n2. **GroupKFold CV** ç’°å¢ƒæ§‹ç¯‰\n3. **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«** (tsfresh + LightGBM)\n4. **é€²æ—ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°** ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰\n\n**æœŸå¾…ã•ã‚Œã‚‹æˆæœ**: é©åˆ‡ãªç‰¹å¾´å·¥å­¦ã¨CVæˆ¦ç•¥ã«ã‚ˆã‚Šã€éŠ…ãƒ¡ãƒ€ãƒ«åœå†…(top 200)åˆ°é”å¯èƒ½",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "ri4lh023h7",
   "source": "# 10. ğŸ”§ ç‰¹å¾´å·¥å­¦æ¨å¥¨äº‹é …\nprint(\"ğŸ”§ 10. FEATURE ENGINEERING RECOMMENDATIONS\")\nprint(\"=\" * 60)\n\nprint(\"ğŸ“Š Based on the comprehensive EDA analysis, here are the recommended feature engineering strategies:\")\n\nprint(\"\\nğŸ¯ 1. IMU FEATURE ENGINEERING\")\nprint(\"=\" * 40)\nprint(\"âœ… Magnitude Features:\")\nprint(\"  â€¢ acc_magnitude = sqrt(acc_xÂ² + acc_yÂ² + acc_zÂ²)\")\nprint(\"  â€¢ rot_magnitude = sqrt(rot_xÂ² + rot_yÂ² + rot_zÂ²)\")\nprint(\"  â€¢ Remove gravity component: acc_no_gravity = acc - [0, 0, 9.81]\")\n\nprint(\"\\nâœ… Temporal Features:\")\nprint(\"  â€¢ Velocity: diff(acc_x), diff(acc_y), diff(acc_z)\")\nprint(\"  â€¢ Jerk: diff(diff(acc_x)) - 2nd derivative\")\nprint(\"  â€¢ Rolling statistics: mean, std, min, max over windows (5, 10, 20 timesteps)\")\n\nprint(\"\\nâœ… Frequency Domain:\")\nprint(\"  â€¢ FFT features: spectral energy, dominant frequency, spectral centroid\")\nprint(\"  â€¢ Frequency band powers: 0-2Hz, 2-5Hz, 5-10Hz, 10-25Hz\")\nprint(\"  â€¢ Spectral entropy and spectral rolloff\")\n\nprint(\"\\nğŸŒ¡ï¸ 2. THERMOPILE FEATURE ENGINEERING\") \nprint(\"=\" * 40)\nprint(\"âœ… Spatial Features:\")\nprint(\"  â€¢ Temperature gradients: thm_1 - thm_3, thm_2 - thm_4\")\nprint(\"  â€¢ Temperature range: max(thm_1..4) - min(thm_1..4)\")\nprint(\"  â€¢ Centroid calculation: weighted average position\")\n\nprint(\"\\nâœ… Handle Missing thm_5:\")\nprint(\"  â€¢ Create binary indicator: thm_5_available\")\nprint(\"  â€¢ Fill with median of thm_1..4 when missing\")\nprint(\"  â€¢ Separate model branch for thm_5 vs thm_1..4\")\n\nprint(\"\\nğŸ“¡ 3. TOF FEATURE ENGINEERING\")\nprint(\"=\" * 40)\nprint(\"âœ… Dimensionality Reduction:\")\nprint(\"  â€¢ PCA on 64 channels â†’ 8-16 components per ToF sensor\")\nprint(\"  â€¢ Statistical summaries: mean, std, min, max, median per sensor\")\nprint(\"  â€¢ Distance gradients: edge detection on 8x8 ToF array\")\n\nprint(\"\\nâœ… Proximity Features:\")\nprint(\"  â€¢ Minimum distance per sensor: min(tof_N_v0..63)\")\nprint(\"  â€¢ Distance variance: std(tof_N_v0..63)\")\nprint(\"  â€¢ Hand-to-face proximity: tof_1 vs tof_3 comparison\")\n\nprint(\"\\nâœ… Handle Missing tof_5:\")\nprint(\"  â€¢ Binary indicator: tof_5_available\")\nprint(\"  â€¢ Zero-fill or interpolate from tof_1..4 spatial patterns\")\n\nprint(\"\\nğŸ”„ 4. MULTIMODAL FUSION FEATURES\")\nprint(\"=\" * 40)\nprint(\"âœ… Cross-Modal Correlations:\")\nprint(\"  â€¢ IMU-Temperature sync: correlation(acc_magnitude, thm_mean)\")\nprint(\"  â€¢ Motion-Proximity sync: correlation(acc_jerk, tof_min_distance)\")\nprint(\"  â€¢ Activity level: high_motion Ã— high_temperature\")\n\nprint(\"\\nâœ… Temporal Alignment:\")\nprint(\"  â€¢ Lag features: temperature[t-1], tof[t-1] vs acc[t]\")\nprint(\"  â€¢ Lead features: predict next timestep behavior\")\nprint(\"  â€¢ Sliding window features: past 5-10 timesteps context\")\n\nprint(\"\\nâ±ï¸ 5. TIME SERIES SPECIFIC FEATURES\")\nprint(\"=\" * 40)\nprint(\"âœ… Sequence-Level Features:\")\nprint(\"  â€¢ Sequence statistics: length, start/end values, trend\")\nprint(\"  â€¢ Phase transitions: count of behavior changes per sequence\")\nprint(\"  â€¢ Gesture duration: timesteps in 'Performs gesture' phase\")\n\nprint(\"\\nâœ… Temporal Context:\")\nprint(\"  â€¢ Position in sequence: timestep / sequence_length\")\nprint(\"  â€¢ Time since behavior change\")\nprint(\"  â€¢ Behavior transition indicators\")\n\nprint(\"\\nğŸ­ 6. GESTURE-SPECIFIC FEATURES\")\nprint(\"=\" * 40)\nprint(\"âœ… BFRB-Relevant Features:\")\nprint(\"  â€¢ Repetitive motion detection: autocorrelation, periodicity\")\nprint(\"  â€¢ Hand-to-face distance (ToF sensors)\")\nprint(\"  â€¢ Fidgeting indicators: high-frequency low-amplitude motion\")\nprint(\"  â€¢ Touch detection: temperature spikes + proximity changes\")\n\nprint(\"\\nğŸ‘¥ 7. PARTICIPANT-AWARE FEATURES\")\nprint(\"=\" * 40) \nprint(\"âœ… Normalization by Demographics:\")\nprint(\"  â€¢ Height-normalized features: distances / height\")\nprint(\"  â€¢ Age-adjusted motion thresholds\")\nprint(\"  â€¢ Handedness-aware spatial features\")\n\nprint(\"\\nâœ… Subject-Specific Calibration:\")\nprint(\"  â€¢ Z-score normalization per participant\")\nprint(\"  â€¢ Baseline subtraction: first N timesteps as reference\")\nprint(\"  â€¢ Participant-specific gesture templates\")\n\nprint(\"\\nğŸ—ï¸ 8. IMPLEMENTATION PRIORITY\")\nprint(\"=\" * 40)\nprint(\"Priority 1 (Essential):\")\nprint(\"  1. IMU magnitude + derivatives (velocity, jerk)\")\nprint(\"  2. Rolling window statistics (mean, std over 5-20 timesteps)\")\nprint(\"  3. Missing value indicators + imputation\")\nprint(\"  4. GroupKFold cross-validation setup\")\n\nprint(\"\\nPriority 2 (High Impact):\")\nprint(\"  5. ToF PCA + statistical summaries\")\nprint(\"  6. Thermopile spatial gradients\")\nprint(\"  7. Sequence-level contextual features\")\nprint(\"  8. FFT spectral features\")\n\nprint(\"\\nPriority 3 (Optimization):\")\nprint(\"  9. Cross-modal correlation features\")\nprint(\"  10. Participant-specific normalization\")\nprint(\"  11. Advanced temporal patterns\")\nprint(\"  12. Gesture-specific domain features\")\n\nprint(\"\\nğŸ¯ Expected Impact on Competition Metrics:\")\nprint(\"  â€¢ Binary F1: Should improve from current ~0.60 to 0.65-0.70\")\nprint(\"  â€¢ Macro F1: Harder due to class imbalance, expect 0.55-0.65\")\nprint(\"  â€¢ Combined Score: Target 0.60-0.68 (bronze medal territory)\")\n\nprint(\"\\n\" + \"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "fj17nr6109k",
   "source": "# 9. âœ… ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æˆ¦ç•¥æ¤œè¨¼\nprint(\"âœ… 9. CROSS-VALIDATION STRATEGY VALIDATION\")\nprint(\"=\" * 60)\n\n# Close existing connection if it exists and create new one\ntry:\n    conn.close()\nexcept:\n    pass\n\nimport duckdb\nconn = duckdb.connect('/home/wsl/dev/my-study/ml/ml-note/kaggle_datasets.duckdb')\n\n# å‚åŠ è€…ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯æ¤œè¨¼\nprint(\"ğŸ‘¥ Participant Data Leakage Validation:\")\n\n# å‚åŠ è€…IDã®å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯\nparticipant_integrity = conn.execute(\"\"\"\n    SELECT \n        'Train' as dataset,\n        COUNT(DISTINCT subject) as unique_participants,\n        MIN(subject) as min_subject_id,\n        MAX(subject) as max_subject_id\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    \n    UNION ALL\n    \n    SELECT \n        'Test',\n        COUNT(DISTINCT subject),\n        MIN(subject),\n        MAX(subject)\n    FROM \"cmi_detect_behavior_with_sensor_data\".test\n\"\"\").fetchdf()\n\nprint(participant_integrity.to_string(index=False))\n\n# å‚åŠ è€…é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ˆã‚Šè©³ç´°ï¼‰\noverlap_detailed = conn.execute(\"\"\"\n    SELECT \n        tr.subject as train_subject,\n        te.subject as test_subject,\n        'OVERLAP_DETECTED' as status\n    FROM (SELECT DISTINCT subject FROM \"cmi_detect_behavior_with_sensor_data\".train) tr\n    INNER JOIN (SELECT DISTINCT subject FROM \"cmi_detect_behavior_with_sensor_data\".test) te\n    ON tr.subject = te.subject\n\"\"\").fetchdf()\n\nif len(overlap_detailed) > 0:\n    print(f\"âš ï¸  CRITICAL: Found {len(overlap_detailed)} overlapping participants!\")\n    print(overlap_detailed.to_string(index=False))\nelse:\n    print(\"âœ… VERIFIED: No participant overlap between train and test sets\")\n\n# å‚åŠ è€…åˆ¥ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒï¼ˆCVè¨­è¨ˆç”¨ï¼‰\nprint(\"\\nğŸ“Š Participant Data Distribution for CV Design:\")\nparticipant_distribution = conn.execute(\"\"\"\n    SELECT \n        subject,\n        COUNT(DISTINCT sequence_id) as sequences,\n        COUNT(DISTINCT gesture) as unique_gestures,\n        COUNT(*) as total_timesteps,\n        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train), 2) as data_percentage\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    GROUP BY subject\n    ORDER BY total_timesteps DESC\n    LIMIT 10\n\"\"\").fetchdf()\n\nprint(\"Top 10 participants by data volume:\")\nprint(participant_distribution.to_string(index=False))\n\n# ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã®å‡ç­‰æ€§è©•ä¾¡\ndistribution_stats = conn.execute(\"\"\"\n    SELECT \n        COUNT(DISTINCT subject) as total_participants,\n        ROUND(AVG(timesteps_per_participant), 1) as avg_timesteps,\n        ROUND(STDDEV(timesteps_per_participant), 1) as std_timesteps,\n        ROUND(MIN(timesteps_per_participant), 1) as min_timesteps,\n        ROUND(MAX(timesteps_per_participant), 1) as max_timesteps,\n        ROUND(MAX(timesteps_per_participant) / MIN(timesteps_per_participant), 1) as imbalance_ratio\n    FROM (\n        SELECT subject, COUNT(*) as timesteps_per_participant\n        FROM \"cmi_detect_behavior_with_sensor_data\".train\n        GROUP BY subject\n    )\n\"\"\").fetchone()\n\nprint(f\"\\nğŸ“ˆ Participant Data Balance:\")\nprint(f\"  Total participants: {distribution_stats[0]}\")\nprint(f\"  Timesteps per participant: meanÂ±std = {distribution_stats[1]}Â±{distribution_stats[2]}\")\nprint(f\"  Range: {distribution_stats[3]} - {distribution_stats[4]}\")\nprint(f\"  Imbalance ratio: {distribution_stats[5]}:1\")\n\nbalance_status = \"ğŸŸ¢ WELL BALANCED\" if distribution_stats[5] < 5 else \"ğŸŸ¡ MODERATE IMBALANCE\" if distribution_stats[5] < 10 else \"ğŸ”´ HIGHLY IMBALANCED\"\nprint(f\"  Status: {balance_status}\")\n\n# ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼Ã—å‚åŠ è€…ã®ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ\nprint(\"\\nğŸ­ Gesture Coverage by Participant (CV Stratification Check):\")\ngesture_coverage = conn.execute(\"\"\"\n    SELECT \n        gesture,\n        COUNT(DISTINCT subject) as participants_with_gesture,\n        ROUND(COUNT(DISTINCT subject) * 100.0 / 81, 1) as coverage_percentage,\n        COUNT(*) as total_samples\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    GROUP BY gesture\n    ORDER BY participants_with_gesture DESC\n\"\"\").fetchdf()\n\nprint(gesture_coverage.to_string(index=False))\n\n# CV ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰è¨­è¨ˆã®æ¨å¥¨\nprint(\"\\nğŸ”„ Recommended CV Strategy:\")\n\n# 5-fold GroupKFold ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³\nparticipants_per_fold = distribution_stats[0] / 5\ndata_per_fold = 100 / 5\n\nprint(f\"GroupKFold Configuration:\")\nprint(f\"  â€¢ Recommended folds: 5\")\nprint(f\"  â€¢ Participants per fold: ~{participants_per_fold:.0f}\")\nprint(f\"  â€¢ Expected data per fold: ~{data_per_fold:.0f}%\")\nprint(f\"  â€¢ Grouping variable: subject (participant_id)\")\n\n# æ½œåœ¨çš„ãªå•é¡Œã®ç‰¹å®š\npotential_issues = []\n\nif distribution_stats[5] > 10:\n    potential_issues.append(\"High participant data imbalance may cause uneven fold sizes\")\n\nif gesture_coverage['coverage_percentage'].min() < 80:\n    potential_issues.append(\"Some gestures appear in <80% of participants - may cause stratification issues\")\n\nif len(potential_issues) > 0:\n    print(f\"\\nâš ï¸  Potential CV Issues:\")\n    for issue in potential_issues:\n        print(f\"  â€¢ {issue}\")\n    print(f\"  â€¢ Recommendation: Monitor CV scores variance across folds\")\nelse:\n    print(f\"\\nâœ… CV Strategy Looks Robust\")\n\n# æ™‚ç³»åˆ—ç‰¹æœ‰ã®è€ƒæ…®äº‹é …\nprint(\"\\nâ° Time Series Specific Considerations:\")\nprint(\"  âœ… Sequences are independent (no temporal continuity between sequences)\")\nprint(\"  âœ… Participant-level grouping prevents data leakage\")\nprint(\"  âš ï¸  Consider sequence-level stratification if needed\")\nprint(\"  ğŸ“ Monitor for temporal drift within long sequences\")\n\n# æœ€çµ‚çš„ãªCVæ¨å¥¨\nprint(\"\\nğŸ¯ Final CV Recommendation:\")\nprint(\"```python\")\nprint(\"from sklearn.model_selection import GroupKFold\")\nprint(\"\")\nprint(\"# Recommended configuration\")\nprint(\"cv = GroupKFold(n_splits=5)\")\nprint(\"groups = train_data['subject']  # participant IDs\")\nprint(\"\")\nprint(\"# Ensure no participant appears in both train and validation\")\nprint(\"for train_idx, val_idx in cv.split(X, y, groups):\")\nprint(\"    train_subjects = set(groups.iloc[train_idx])\")\nprint(\"    val_subjects = set(groups.iloc[val_idx])\")\nprint(\"    assert len(train_subjects & val_subjects) == 0\")\nprint(\"```\")\n\nprint(\"\\n\" + \"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ugz2uf6n5k",
   "source": "# 8. ğŸ“Š ã‚»ãƒ³ã‚µãƒ¼èåˆå¯è¦–åŒ–ã¨ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åˆ†æ\nprint(\"ğŸ“Š 8. SENSOR FUSION VISUALIZATION & MULTIMODAL ANALYSIS\")\nprint(\"=\" * 60)\n\n# ä»£è¡¨çš„ãªã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã®å–å¾—ã¨å¯è¦–åŒ–\nprint(\"ğŸ¯ Sample Sequence Analysis for Visualization:\")\n\n# èˆˆå‘³æ·±ã„ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’é¸æŠï¼ˆç•°ãªã‚‹ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ï¼‰\nsample_sequences = conn.execute(\"\"\"\n    SELECT sequence_id, gesture, COUNT(*) as length\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE gesture IN ('Text on phone', 'Neck - scratch', 'Wave hello')\n    GROUP BY sequence_id, gesture\n    HAVING COUNT(*) BETWEEN 50 AND 100  -- ä¸­ç¨‹åº¦ã®é•·ã•\n    ORDER BY RANDOM()\n    LIMIT 3\n\"\"\").fetchdf()\n\nprint(\"Selected sequences for visualization:\")\nprint(sample_sequences.to_string(index=False))\n\n# ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ãƒ‡ãƒ¼ã‚¿ã®åŒæœŸæ€§ãƒã‚§ãƒƒã‚¯\nprint(\"\\nğŸ”„ Sensor Synchronization Analysis:\")\nsync_analysis = conn.execute(\"\"\"\n    SELECT \n        sequence_id,\n        COUNT(*) as total_timesteps,\n        COUNT(acc_x) as acc_available,\n        COUNT(rot_w) as rot_available,  \n        COUNT(thm_1) as thm_available,\n        COUNT(tof_1_v0) as tof_available,\n        ROUND(COUNT(acc_x) * 100.0 / COUNT(*), 1) as acc_coverage,\n        ROUND(COUNT(thm_1) * 100.0 / COUNT(*), 1) as thm_coverage,\n        ROUND(COUNT(tof_1_v0) * 100.0 / COUNT(*), 1) as tof_coverage\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE sequence_id IN (\n        SELECT sequence_id FROM \"cmi_detect_behavior_with_sensor_data\".train\n        GROUP BY sequence_id\n        ORDER BY RANDOM()\n        LIMIT 10\n    )\n    GROUP BY sequence_id\n    ORDER BY acc_coverage DESC\n    LIMIT 5\n\"\"\").fetchdf()\n\nprint(sync_analysis.to_string(index=False))\n\n# ã‚»ãƒ³ã‚µãƒ¼ãƒ¢ãƒ€ãƒªãƒ†ã‚£é–“ã®æƒ…å ±é‡åˆ†æ\nprint(\"\\nğŸ“ˆ Information Content Analysis by Sensor Modality:\")\ninfo_analysis = conn.execute(\"\"\"\n    SELECT \n        'IMU_acceleration' as modality,\n        ROUND(STDDEV(acc_x), 4) as x_std,\n        ROUND(STDDEV(acc_y), 4) as y_std,\n        ROUND(STDDEV(acc_z), 4) as z_std,\n        ROUND(AVG(ABS(acc_x - LAG(acc_x) OVER (ORDER BY sequence_counter))), 4) as x_variability\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE acc_x IS NOT NULL\n    ORDER BY RANDOM()\n    LIMIT 10000\n\"\"\").fetchone()\n\nprint(f\"IMU Acceleration variability:\")\nprint(f\"  X-axis std: {info_analysis[1]}, variability: {info_analysis[4]}\")\nprint(f\"  Y-axis std: {info_analysis[2]}\")\nprint(f\"  Z-axis std: {info_analysis[3]}\")\n\n# ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼åˆ¥ã®ã‚»ãƒ³ã‚µãƒ¼ç‰¹æ€§\nprint(\"\\nğŸ­ Sensor Characteristics by Gesture Type:\")\ngesture_sensor_profile = conn.execute(\"\"\"\n    SELECT \n        gesture,\n        COUNT(*) as samples,\n        ROUND(AVG(ABS(acc_x)), 3) as avg_acc_x_abs,\n        ROUND(AVG(ABS(acc_y)), 3) as avg_acc_y_abs,\n        ROUND(AVG(ABS(acc_z)), 3) as avg_acc_z_abs,\n        ROUND(AVG(thm_1), 2) as avg_thm_1,\n        ROUND(STDDEV(thm_1), 2) as std_thm_1\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE acc_x IS NOT NULL AND thm_1 IS NOT NULL\n    GROUP BY gesture\n    ORDER BY avg_acc_x_abs DESC\n    LIMIT 8\n\"\"\").fetchdf()\n\nprint(gesture_sensor_profile.to_string(index=False))\n\n# ToFã‚»ãƒ³ã‚µãƒ¼ã®è·é›¢ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ\nprint(\"\\nğŸ“¡ ToF Distance Pattern Analysis:\")\ntof_pattern = conn.execute(\"\"\"\n    SELECT \n        gesture,\n        COUNT(*) as valid_samples,\n        ROUND(AVG(tof_1_v0), 2) as avg_tof1_v0,\n        ROUND(AVG(tof_2_v0), 2) as avg_tof2_v0,\n        ROUND(AVG(tof_3_v0), 2) as avg_tof3_v0,\n        ROUND(STDDEV(tof_1_v0), 2) as std_tof1_v0,\n        ROUND(AVG(tof_1_v0 - tof_1_v31), 2) as tof1_gradient\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE tof_1_v0 IS NOT NULL AND tof_2_v0 IS NOT NULL AND tof_3_v0 IS NOT NULL\n    GROUP BY gesture\n    HAVING COUNT(*) > 1000\n    ORDER BY avg_tof1_v0 DESC\n    LIMIT 8\n\"\"\").fetchdf()\n\nprint(tof_pattern.to_string(index=False))\n\n# å®Ÿéš›ã®å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™\nprint(\"\\nğŸ“Š Preparing Visualization Data:\")\nviz_data = conn.execute(f\"\"\"\n    SELECT \n        sequence_counter,\n        acc_x, acc_y, acc_z,\n        rot_w, rot_x, rot_y, rot_z,\n        thm_1, thm_2, thm_3,\n        tof_1_v0, tof_1_v31, tof_1_v63,\n        gesture, behavior, phase\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE sequence_id = '{sample_sequences.iloc[0]['sequence_id']}'\n    ORDER BY sequence_counter\n    LIMIT 100\n\"\"\").fetchdf()\n\nprint(f\"Visualization data prepared: {len(viz_data)} timesteps\")\nprint(f\"Gesture: {viz_data['gesture'].iloc[0]}\")\nprint(f\"Data coverage:\")\nprint(f\"  IMU: {viz_data['acc_x'].notna().sum()}/{len(viz_data)} timesteps\")\nprint(f\"  Thermopile: {viz_data['thm_1'].notna().sum()}/{len(viz_data)} timesteps\") \nprint(f\"  ToF: {viz_data['tof_1_v0'].notna().sum()}/{len(viz_data)} timesteps\")\n\n# ã‚»ãƒ³ã‚µãƒ¼èåˆã®å¯èƒ½æ€§è©•ä¾¡\nprint(\"\\nğŸ”— Sensor Fusion Potential Assessment:\")\nfusion_metrics = {\n    'temporal_alignment': sync_analysis['acc_coverage'].mean(),\n    'cross_modal_correlation': abs(cross_correlations[0]),  # å‰ã®ã‚»ãƒ«ã‹ã‚‰\n    'complementary_info': 1 - abs(cross_correlations[0]),  # ç›¸é–¢ãŒä½ã„ã»ã©è£œå®Œçš„\n    'missing_data_overlap': missing_cooccurrence.iloc[0]['percentage']  # å‰ã®ã‚»ãƒ«ã‹ã‚‰\n}\n\nprint(f\"Fusion readiness metrics:\")\nprint(f\"  âœ… Temporal alignment: {fusion_metrics['temporal_alignment']:.1f}%\")\nprint(f\"  ğŸ”„ Cross-modal correlation: {fusion_metrics['cross_modal_correlation']:.3f}\")\nprint(f\"  ğŸ¯ Complementary information: {fusion_metrics['complementary_info']:.3f}\")\nprint(f\"  âš ï¸  Missing data overlap: {fusion_metrics['missing_data_overlap']:.1f}%\")\n\nfusion_score = (fusion_metrics['temporal_alignment']/100 + \n                fusion_metrics['complementary_info'] + \n                (1 - fusion_metrics['missing_data_overlap']/100)) / 3\n\nprint(f\"\\nğŸ† Overall Fusion Potential Score: {fusion_score:.2f}/1.0\")\nprint(f\"   {'ğŸŸ¢ EXCELLENT' if fusion_score > 0.8 else 'ğŸŸ¡ GOOD' if fusion_score > 0.6 else 'ğŸ”´ CHALLENGING'}\")\n\nprint(\"\\n\" + \"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "hw7ltqem8i7",
   "source": "# 7. ğŸ”— ç‰¹å¾´ç›¸é–¢åˆ†æã¨ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯\nprint(\"ğŸ”— 7. FEATURE CORRELATION & MULTICOLLINEARITY ANALYSIS\")\nprint(\"=\" * 60)\n\n# IMUã‚»ãƒ³ã‚µãƒ¼é–“ã®ç›¸é–¢åˆ†æï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼‰\nprint(\"ğŸ¯ IMU Sensor Correlations (Sample Data):\")\nimu_correlations = conn.execute(\"\"\"\n    SELECT \n        ROUND(CORR(acc_x, acc_y), 3) as acc_x_y_corr,\n        ROUND(CORR(acc_x, acc_z), 3) as acc_x_z_corr,\n        ROUND(CORR(acc_y, acc_z), 3) as acc_y_z_corr,\n        ROUND(CORR(rot_w, rot_x), 3) as rot_w_x_corr,\n        ROUND(CORR(rot_w, rot_y), 3) as rot_w_y_corr,\n        ROUND(CORR(rot_w, rot_z), 3) as rot_w_z_corr\n    FROM (\n        SELECT acc_x, acc_y, acc_z, rot_w, rot_x, rot_y, rot_z\n        FROM \"cmi_detect_behavior_with_sensor_data\".train\n        WHERE acc_x IS NOT NULL AND rot_w IS NOT NULL\n        ORDER BY RANDOM()\n        LIMIT 50000  -- ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã—ã¦è¨ˆç®—è² è·ã‚’è»½æ¸›\n    )\n\"\"\").fetchone()\n\nprint(f\"Acceleration correlations:\")\nprint(f\"  acc_x vs acc_y: {imu_correlations[0]}\")\nprint(f\"  acc_x vs acc_z: {imu_correlations[1]}\")\nprint(f\"  acc_y vs acc_z: {imu_correlations[2]}\")\n\nprint(f\"\\nRotation correlations:\")\nprint(f\"  rot_w vs rot_x: {imu_correlations[3]}\")\nprint(f\"  rot_w vs rot_y: {imu_correlations[4]}\")\nprint(f\"  rot_w vs rot_z: {imu_correlations[5]}\")\n\n# æ¸©åº¦ã‚»ãƒ³ã‚µãƒ¼é–“ã®ç›¸é–¢\nprint(\"\\nğŸŒ¡ï¸ Thermopile Sensor Correlations:\")\nthm_correlations = conn.execute(\"\"\"\n    SELECT \n        ROUND(CORR(thm_1, thm_2), 3) as thm_1_2_corr,\n        ROUND(CORR(thm_1, thm_3), 3) as thm_1_3_corr,\n        ROUND(CORR(thm_1, thm_4), 3) as thm_1_4_corr,\n        ROUND(CORR(thm_2, thm_3), 3) as thm_2_3_corr,\n        ROUND(CORR(thm_2, thm_4), 3) as thm_2_4_corr,\n        ROUND(CORR(thm_3, thm_4), 3) as thm_3_4_corr\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE thm_1 IS NOT NULL AND thm_2 IS NOT NULL AND thm_3 IS NOT NULL AND thm_4 IS NOT NULL\n\"\"\").fetchone()\n\nprint(f\"thm_1 vs thm_2: {thm_correlations[0]}\")\nprint(f\"thm_1 vs thm_3: {thm_correlations[1]}\")\nprint(f\"thm_1 vs thm_4: {thm_correlations[2]}\")\nprint(f\"thm_2 vs thm_3: {thm_correlations[3]}\")\nprint(f\"thm_2 vs thm_4: {thm_correlations[4]}\")\nprint(f\"thm_3 vs thm_4: {thm_correlations[5]}\")\n\n# ã‚»ãƒ³ã‚µãƒ¼é–“ã®ã‚¯ãƒ­ã‚¹ãƒ¢ãƒ¼ãƒ€ãƒ«ç›¸é–¢\nprint(\"\\nğŸ”„ Cross-modal Sensor Correlations:\")\ncross_correlations = conn.execute(\"\"\"\n    SELECT \n        ROUND(CORR(acc_x, thm_1), 3) as acc_x_thm1_corr,\n        ROUND(CORR(acc_y, thm_2), 3) as acc_y_thm2_corr,\n        ROUND(CORR(acc_z, thm_3), 3) as acc_z_thm3_corr,\n        ROUND(CORR(rot_w, thm_1), 3) as rot_w_thm1_corr,\n        ROUND(CORR(SQRT(acc_x*acc_x + acc_y*acc_y + acc_z*acc_z), thm_1), 3) as acc_magnitude_thm1_corr\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE acc_x IS NOT NULL AND rot_w IS NOT NULL AND thm_1 IS NOT NULL\n\"\"\").fetchone()\n\nprint(f\"Acceleration vs Temperature:\")\nprint(f\"  acc_x vs thm_1: {cross_correlations[0]}\")\nprint(f\"  acc_y vs thm_2: {cross_correlations[1]}\")\nprint(f\"  acc_z vs thm_3: {cross_correlations[2]}\")\nprint(f\"  rot_w vs thm_1: {cross_correlations[3]}\")\nprint(f\"  acc_magnitude vs thm_1: {cross_correlations[4]}\")\n\n# ToFã‚»ãƒ³ã‚µãƒ¼ã®ä»£è¡¨ãƒãƒ£ãƒ³ãƒãƒ«ç›¸é–¢åˆ†æ\nprint(\"\\nğŸ“¡ ToF Sensor Channel Correlations (Sample):\")\ntof_correlations = conn.execute(\"\"\"\n    SELECT \n        ROUND(CORR(tof_1_v0, tof_1_v31), 3) as tof1_v0_v31_corr,\n        ROUND(CORR(tof_1_v0, tof_2_v0), 3) as tof1_tof2_v0_corr,\n        ROUND(CORR(tof_1_v0, tof_3_v0), 3) as tof1_tof3_v0_corr,\n        ROUND(CORR(tof_2_v0, tof_3_v0), 3) as tof2_tof3_v0_corr,\n        COUNT(*) as valid_samples\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE tof_1_v0 IS NOT NULL AND tof_2_v0 IS NOT NULL AND tof_3_v0 IS NOT NULL\n\"\"\").fetchone()\n\nprint(f\"ToF channel correlations (n={tof_correlations[4]:,}):\")\nprint(f\"  tof_1_v0 vs tof_1_v31: {tof_correlations[0]}\")\nprint(f\"  tof_1_v0 vs tof_2_v0: {tof_correlations[1]}\")\nprint(f\"  tof_1_v0 vs tof_3_v0: {tof_correlations[2]}\")\nprint(f\"  tof_2_v0 vs tof_3_v0: {tof_correlations[3]}\")\n\n# ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£è©•ä¾¡\nprint(\"\\nâš ï¸ Multicollinearity Assessment:\")\n\n# é«˜ç›¸é–¢ãƒšã‚¢ã®ç‰¹å®š\nhigh_corr_pairs = []\ncorrelation_data = [\n    (\"acc_x\", \"acc_y\", imu_correlations[0]),\n    (\"acc_x\", \"acc_z\", imu_correlations[1]),\n    (\"acc_y\", \"acc_z\", imu_correlations[2]),\n    (\"thm_1\", \"thm_2\", thm_correlations[0]),\n    (\"thm_1\", \"thm_3\", thm_correlations[1]),\n    (\"thm_2\", \"thm_3\", thm_correlations[3])\n]\n\nfor var1, var2, corr in correlation_data:\n    if abs(corr) > 0.8:\n        high_corr_pairs.append((var1, var2, corr))\n\nif high_corr_pairs:\n    print(\"High correlation pairs (|r| > 0.8):\")\n    for var1, var2, corr in high_corr_pairs:\n        print(f\"  {var1} â†” {var2}: {corr}\")\nelse:\n    print(\"âœ… No severe multicollinearity detected (|r| > 0.8)\")\n\n# ç›¸é–¢ã®è§£é‡ˆ\nprint(\"\\nğŸ“Š Correlation Interpretation:\")\nprint(\"â€¢ Accelerometer correlations are expected due to device orientation\")\nprint(\"â€¢ Thermopile correlations suggest spatial temperature patterns\")\nprint(\"â€¢ Low cross-modal correlations indicate complementary information\")\nprint(\"â€¢ ToF channels may have redundancy - consider dimensionality reduction\")\n\nprint(\"\\n\" + \"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "qrzoqh41bs8",
   "source": "# 6. ğŸ‘¥ å‚åŠ è€…äººå£çµ±è¨ˆã¨è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ\nprint(\"ğŸ‘¥ 6. PARTICIPANT DEMOGRAPHICS & BEHAVIOR PATTERNS\")\nprint(\"=\" * 60)\n\n# äººå£çµ±è¨ˆå­¦çš„ç‰¹å¾´ã®åˆ†æ\nprint(\"ğŸ“Š Demographic Characteristics:\")\ndemographics = conn.execute(\"\"\"\n    SELECT \n        COUNT(*) as total_participants,\n        AVG(age) as avg_age,\n        MIN(age) as min_age,\n        MAX(age) as max_age,\n        ROUND(AVG(height_cm), 1) as avg_height_cm,\n        ROUND(AVG(shoulder_to_wrist_cm), 1) as avg_shoulder_to_wrist_cm,\n        ROUND(AVG(elbow_to_wrist_cm), 1) as avg_elbow_to_wrist_cm\n    FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics\n\"\"\").fetchone()\n\nprint(f\"Total participants: {demographics[0]}\")\nprint(f\"Age: mean={demographics[1]:.1f}, range={demographics[2]}-{demographics[3]}\")\nprint(f\"Height: mean={demographics[4]} cm\")\nprint(f\"Shoulder to wrist: mean={demographics[5]} cm\")\nprint(f\"Elbow to wrist: mean={demographics[6]} cm\")\n\n# ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®åˆ†å¸ƒ\nprint(\"\\nğŸ·ï¸ Categorical Demographics:\")\ncategorical_demographics = conn.execute(\"\"\"\n    SELECT \n        'adult_child' as category,\n        CASE WHEN adult_child = 1 THEN 'Adult' ELSE 'Child' END as value,\n        COUNT(*) as count,\n        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics), 1) as percentage\n    FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics\n    GROUP BY adult_child\n    \n    UNION ALL\n    \n    SELECT \n        'sex',\n        CASE WHEN sex = 1 THEN 'Male' ELSE 'Female' END,\n        COUNT(*),\n        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics), 1)\n    FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics\n    GROUP BY sex\n    \n    UNION ALL\n    \n    SELECT \n        'handedness',\n        CASE WHEN handedness = 1 THEN 'Right-handed' ELSE 'Left-handed' END,\n        COUNT(*),\n        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics), 1)\n    FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics\n    GROUP BY handedness\n\"\"\").fetchdf()\n\nprint(categorical_demographics.to_string(index=False))\n\n# å‚åŠ è€…åˆ¥ã®è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³\nprint(\"\\nğŸ¯ Behavior Patterns by Participant:\")\nparticipant_behavior = conn.execute(\"\"\"\n    SELECT \n        t.subject,\n        d.age,\n        CASE WHEN d.sex = 1 THEN 'M' ELSE 'F' END as sex,\n        CASE WHEN d.handedness = 1 THEN 'R' ELSE 'L' END as handedness,\n        COUNT(DISTINCT t.sequence_id) as total_sequences,\n        COUNT(DISTINCT t.gesture) as unique_gestures,\n        COUNT(*) as total_timesteps,\n        ROUND(AVG(CASE WHEN t.sequence_type = 'Target' THEN 1.0 ELSE 0.0 END) * 100, 1) as target_percentage\n    FROM \"cmi_detect_behavior_with_sensor_data\".train t\n    JOIN \"cmi_detect_behavior_with_sensor_data\".train_demographics d ON t.subject = d.subject\n    GROUP BY t.subject, d.age, d.sex, d.handedness\n    ORDER BY total_sequences DESC\n    LIMIT 15\n\"\"\").fetchdf()\n\nprint(participant_behavior.to_string(index=False))\n\n# å¹´é½¢ç¾¤åˆ¥ã®è¡Œå‹•åˆ†æ\nprint(\"\\nğŸ“ˆ Behavior Analysis by Age Group:\")\nage_behavior = conn.execute(\"\"\"\n    SELECT \n        CASE \n            WHEN d.age < 18 THEN 'Child (<18)'\n            WHEN d.age BETWEEN 18 AND 30 THEN 'Young Adult (18-30)'\n            WHEN d.age BETWEEN 31 AND 50 THEN 'Adult (31-50)'\n            ELSE 'Older Adult (>50)'\n        END as age_group,\n        COUNT(DISTINCT t.subject) as participants,\n        ROUND(AVG(sequence_count), 1) as avg_sequences,\n        ROUND(AVG(gesture_diversity), 1) as avg_gesture_diversity,\n        ROUND(AVG(target_rate) * 100, 1) as avg_target_rate\n    FROM (\n        SELECT \n            t.subject,\n            COUNT(DISTINCT t.sequence_id) as sequence_count,\n            COUNT(DISTINCT t.gesture) as gesture_diversity,\n            AVG(CASE WHEN t.sequence_type = 'Target' THEN 1.0 ELSE 0.0 END) as target_rate\n        FROM \"cmi_detect_behavior_with_sensor_data\".train t\n        GROUP BY t.subject\n    ) t\n    JOIN \"cmi_detect_behavior_with_sensor_data\".train_demographics d ON t.subject = d.subject\n    GROUP BY \n        CASE \n            WHEN d.age < 18 THEN 'Child (<18)'\n            WHEN d.age BETWEEN 18 AND 30 THEN 'Young Adult (18-30)'\n            WHEN d.age BETWEEN 31 AND 50 THEN 'Adult (31-50)'\n            ELSE 'Older Adult (>50)'\n        END\n    ORDER BY avg_sequences DESC\n\"\"\").fetchdf()\n\nprint(age_behavior.to_string(index=False))\n\n# åˆ©ãæ‰‹ã«ã‚ˆã‚‹è¡Œå‹•ã®é•ã„\nprint(\"\\nâœ‹ Handedness Impact on Behavior:\")\nhandedness_behavior = conn.execute(\"\"\"\n    SELECT \n        CASE WHEN d.handedness = 1 THEN 'Right-handed' ELSE 'Left-handed' END as handedness,\n        COUNT(DISTINCT t.subject) as participants,\n        ROUND(AVG(sequence_count), 1) as avg_sequences,\n        ROUND(AVG(target_rate) * 100, 1) as avg_target_rate,\n        STRING_AGG(DISTINCT most_common_gesture, ', ') as common_gestures\n    FROM (\n        SELECT \n            t.subject,\n            COUNT(DISTINCT t.sequence_id) as sequence_count,\n            AVG(CASE WHEN t.sequence_type = 'Target' THEN 1.0 ELSE 0.0 END) as target_rate,\n            MODE() WITHIN GROUP (ORDER BY t.gesture) as most_common_gesture\n        FROM \"cmi_detect_behavior_with_sensor_data\".train t\n        GROUP BY t.subject\n    ) t\n    JOIN \"cmi_detect_behavior_with_sensor_data\".train_demographics d ON t.subject = d.subject\n    GROUP BY d.handedness\n\"\"\").fetchdf()\n\nprint(handedness_behavior.to_string(index=False))\n\nprint(\"\\n\" + \"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "m6ukgyl75r",
   "source": "# 5. ğŸ” æ¬ æãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨å“è³ªè©•ä¾¡\nprint(\"ğŸ” 5. MISSING DATA PATTERNS & QUALITY ASSESSMENT\")\nprint(\"=\" * 60)\n\n# å…¨ã‚»ãƒ³ã‚µãƒ¼ã®æ¬ æç‡åˆ†æ\nprint(\"ğŸ“Š Comprehensive Missing Data Analysis:\")\nmissing_analysis = conn.execute(\"\"\"\n    SELECT \n        'IMU_accelerometer' as sensor_group,\n        'acc_x' as sensor,\n        COUNT(*) as total_rows,\n        COUNT(*) - COUNT(acc_x) as missing_count,\n        ROUND((COUNT(*) - COUNT(acc_x)) * 100.0 / COUNT(*), 2) as missing_pct\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    \n    UNION ALL SELECT 'IMU_accelerometer', 'acc_y', COUNT(*), COUNT(*) - COUNT(acc_y), ROUND((COUNT(*) - COUNT(acc_y)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'IMU_accelerometer', 'acc_z', COUNT(*), COUNT(*) - COUNT(acc_z), ROUND((COUNT(*) - COUNT(acc_z)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'IMU_rotation', 'rot_w', COUNT(*), COUNT(*) - COUNT(rot_w), ROUND((COUNT(*) - COUNT(rot_w)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'IMU_rotation', 'rot_x', COUNT(*), COUNT(*) - COUNT(rot_x), ROUND((COUNT(*) - COUNT(rot_x)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'IMU_rotation', 'rot_y', COUNT(*), COUNT(*) - COUNT(rot_y), ROUND((COUNT(*) - COUNT(rot_y)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'IMU_rotation', 'rot_z', COUNT(*), COUNT(*) - COUNT(rot_z), ROUND((COUNT(*) - COUNT(rot_z)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'Thermopile', 'thm_1', COUNT(*), COUNT(*) - COUNT(thm_1), ROUND((COUNT(*) - COUNT(thm_1)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'Thermopile', 'thm_2', COUNT(*), COUNT(*) - COUNT(thm_2), ROUND((COUNT(*) - COUNT(thm_2)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'Thermopile', 'thm_3', COUNT(*), COUNT(*) - COUNT(thm_3), ROUND((COUNT(*) - COUNT(thm_3)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'Thermopile', 'thm_4', COUNT(*), COUNT(*) - COUNT(thm_4), ROUND((COUNT(*) - COUNT(thm_4)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'Thermopile', 'thm_5', COUNT(*), COUNT(*) - COUNT(thm_5), ROUND((COUNT(*) - COUNT(thm_5)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n\"\"\").fetchdf()\n\nprint(missing_analysis.to_string(index=False))\n\n# ToFã‚»ãƒ³ã‚µãƒ¼ã®æ¬ æãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼‰\nprint(\"\\nğŸ“¡ ToF Sensor Missing Pattern (Sample):\")\ntof_missing = conn.execute(\"\"\"\n    SELECT \n        'ToF' as sensor_group,\n        'tof_1_v0' as sensor,\n        COUNT(*) as total_rows,\n        COUNT(*) - COUNT(tof_1_v0) as missing_count,\n        ROUND((COUNT(*) - COUNT(tof_1_v0)) * 100.0 / COUNT(*), 2) as missing_pct\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    \n    UNION ALL SELECT 'ToF', 'tof_2_v0', COUNT(*), COUNT(*) - COUNT(tof_2_v0), ROUND((COUNT(*) - COUNT(tof_2_v0)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'ToF', 'tof_3_v0', COUNT(*), COUNT(*) - COUNT(tof_3_v0), ROUND((COUNT(*) - COUNT(tof_3_v0)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'ToF', 'tof_4_v0', COUNT(*), COUNT(*) - COUNT(tof_4_v0), ROUND((COUNT(*) - COUNT(tof_4_v0)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n    UNION ALL SELECT 'ToF', 'tof_5_v0', COUNT(*), COUNT(*) - COUNT(tof_5_v0), ROUND((COUNT(*) - COUNT(tof_5_v0)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n\"\"\").fetchdf()\n\nprint(tof_missing.to_string(index=False))\n\n# æ¬ æå€¤ã®å…±èµ·ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ\nprint(\"\\nğŸ”— Missing Value Co-occurrence Patterns:\")\nmissing_cooccurrence = conn.execute(\"\"\"\n    SELECT \n        CASE WHEN thm_5 IS NULL THEN 'thm_5_missing' ELSE 'thm_5_present' END as thm5_status,\n        CASE WHEN tof_5_v0 IS NULL THEN 'tof_5_missing' ELSE 'tof_5_present' END as tof5_status,\n        COUNT(*) as count,\n        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train), 2) as percentage\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    GROUP BY \n        CASE WHEN thm_5 IS NULL THEN 'thm_5_missing' ELSE 'thm_5_present' END,\n        CASE WHEN tof_5_v0 IS NULL THEN 'tof_5_missing' ELSE 'tof_5_present' END\n    ORDER BY count DESC\n\"\"\").fetchdf()\n\nprint(missing_cooccurrence.to_string(index=False))\n\n# å‚åŠ è€…åˆ¥ã®æ¬ æãƒ‘ã‚¿ãƒ¼ãƒ³\nprint(\"\\nğŸ‘¥ Missing Data by Participant (Top 10 with most missing):\")\nparticipant_missing = conn.execute(\"\"\"\n    SELECT \n        subject,\n        COUNT(*) as total_rows,\n        COUNT(*) - COUNT(thm_5) as thm5_missing,\n        COUNT(*) - COUNT(tof_5_v0) as tof5_missing,\n        ROUND((COUNT(*) - COUNT(thm_5)) * 100.0 / COUNT(*), 1) as thm5_missing_pct,\n        ROUND((COUNT(*) - COUNT(tof_5_v0)) * 100.0 / COUNT(*), 1) as tof5_missing_pct\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    GROUP BY subject\n    HAVING (COUNT(*) - COUNT(thm_5)) > 0 OR (COUNT(*) - COUNT(tof_5_v0)) > 0\n    ORDER BY thm5_missing_pct DESC, tof5_missing_pct DESC\n    LIMIT 10\n\"\"\").fetchdf()\n\nprint(participant_missing.to_string(index=False))\n\n# ãƒ‡ãƒ¼ã‚¿å“è³ªã‚µãƒãƒªãƒ¼\nprint(\"\\nğŸ“‹ Data Quality Summary:\")\nquality_metrics = missing_analysis.groupby('sensor_group')['missing_pct'].agg(['mean', 'max']).round(2)\nprint(\"Missing rate by sensor group:\")\nfor group in quality_metrics.index:\n    mean_missing = quality_metrics.loc[group, 'mean']\n    max_missing = quality_metrics.loc[group, 'max']\n    status = \"ğŸŸ¢ EXCELLENT\" if max_missing < 1 else \"ğŸŸ¡ GOOD\" if max_missing < 5 else \"ğŸ”´ NEEDS ATTENTION\"\n    print(f\"  {group}: avg={mean_missing}%, max={max_missing}% {status}\")\n\nprint(\"\\n\" + \"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "wkpu64m5bs",
   "source": "# 4. â±ï¸ æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨æ§‹é€ åˆ†æ\nprint(\"â±ï¸ 4. TIME SERIES PATTERNS & SEQUENCE STRUCTURE ANALYSIS\")\nprint(\"=\" * 60)\n\n# ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·ã®è©³ç´°åˆ†æ\nprint(\"ğŸ“ Sequence Length Analysis:\")\nsequence_lengths = conn.execute(\"\"\"\n    SELECT \n        COUNT(DISTINCT sequence_id) as total_sequences,\n        ROUND(AVG(length), 1) as avg_length,\n        ROUND(STDDEV(length), 1) as std_length,\n        MIN(length) as min_length,\n        MAX(length) as max_length,\n        ROUND(PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY length), 1) as q25,\n        ROUND(PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY length), 1) as median,\n        ROUND(PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY length), 1) as q75,\n        ROUND(PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY length), 1) as p95\n    FROM (\n        SELECT sequence_id, COUNT(*) as length\n        FROM \"cmi_detect_behavior_with_sensor_data\".train\n        GROUP BY sequence_id\n    )\n\"\"\").fetchone()\n\nprint(f\"Total sequences: {sequence_lengths[0]:,}\")\nprint(f\"Length stats: mean={sequence_lengths[1]}, std={sequence_lengths[2]}\")\nprint(f\"Length range: {sequence_lengths[3]} - {sequence_lengths[4]} timesteps\")\nprint(f\"Quartiles: Q1={sequence_lengths[5]}, Q2={sequence_lengths[6]}, Q3={sequence_lengths[7]}\")\nprint(f\"95th percentile: {sequence_lengths[8]} timesteps\")\n\n# 50Hzå‰æã§ã®æ™‚é–“è¨ˆç®—\nprint(f\"\\nâ±ï¸ Time Duration (assuming 50Hz sampling):\")\nprint(f\"  â€¢ Average sequence duration: {sequence_lengths[1]/50:.2f} seconds\")\nprint(f\"  â€¢ Median sequence duration: {sequence_lengths[6]/50:.2f} seconds\")\nprint(f\"  â€¢ Longest sequence duration: {sequence_lengths[4]/50:.1f} seconds\")\n\n# ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼åˆ¥ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é•·åˆ†æ\nprint(\"\\nğŸ“Š Sequence Length by Gesture Type:\")\ngesture_lengths = conn.execute(\"\"\"\n    SELECT \n        gesture,\n        COUNT(DISTINCT sequence_id) as num_sequences,\n        ROUND(AVG(length), 1) as avg_length,\n        ROUND(MIN(length), 1) as min_length,\n        ROUND(MAX(length), 1) as max_length\n    FROM (\n        SELECT \n            sequence_id, \n            gesture,\n            COUNT(*) as length\n        FROM \"cmi_detect_behavior_with_sensor_data\".train\n        GROUP BY sequence_id, gesture\n    )\n    GROUP BY gesture\n    ORDER BY avg_length DESC\n    LIMIT 10\n\"\"\").fetchdf()\n\nprint(gesture_lengths.to_string(index=False))\n\n# å‚åŠ è€…åˆ¥ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ•°åˆ†æ\nprint(\"\\nğŸ‘¥ Sequence Count per Participant:\")\nparticipant_sequences = conn.execute(\"\"\"\n    SELECT \n        COUNT(DISTINCT subject) as total_participants,\n        ROUND(AVG(seq_count), 1) as avg_sequences_per_participant,\n        MIN(seq_count) as min_sequences,\n        MAX(seq_count) as max_sequences,\n        ROUND(STDDEV(seq_count), 1) as std_sequences\n    FROM (\n        SELECT \n            subject, \n            COUNT(DISTINCT sequence_id) as seq_count\n        FROM \"cmi_detect_behavior_with_sensor_data\".train\n        GROUP BY subject\n    )\n\"\"\").fetchone()\n\nprint(f\"Participants: {participant_sequences[0]}\")\nprint(f\"Sequences per participant: mean={participant_sequences[1]}, std={participant_sequences[4]}\")\nprint(f\"Sequence range per participant: {participant_sequences[2]} - {participant_sequences[3]}\")\n\n# æ™‚ç³»åˆ—ã®é€£ç¶šæ€§ãƒã‚§ãƒƒã‚¯\nprint(\"\\nğŸ”— Sequence Continuity Check:\")\ncontinuity_check = conn.execute(\"\"\"\n    SELECT \n        COUNT(*) as total_gaps,\n        AVG(gap_size) as avg_gap_size,\n        MAX(gap_size) as max_gap_size\n    FROM (\n        SELECT \n            sequence_id,\n            sequence_counter - LAG(sequence_counter) OVER (PARTITION BY sequence_id ORDER BY sequence_counter) as gap_size\n        FROM \"cmi_detect_behavior_with_sensor_data\".train\n    )\n    WHERE gap_size > 1\n\"\"\").fetchone()\n\nif continuity_check[0] > 0:\n    print(f\"âš ï¸  Found {continuity_check[0]} gaps in sequences\")\n    print(f\"   Average gap size: {continuity_check[1]:.1f}\")\n    print(f\"   Maximum gap size: {continuity_check[2]}\")\nelse:\n    print(\"âœ… All sequences are continuous (no missing timesteps)\")\n\nprint(\"\\n\" + \"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "77z2wz6xjop",
   "source": "# 3. ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ã®è©³ç´°åˆ†æ\nprint(\"ğŸ¯ 3. TARGET VARIABLE CORRELATION & CLASS BALANCE ANALYSIS\")\nprint(\"=\" * 60)\n\n# ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼ã¨sequence_typeã®é–¢ä¿‚\nprint(\"ğŸ”„ Gesture vs Sequence Type Relationship:\")\ngesture_sequence_type = conn.execute(\"\"\"\n    SELECT \n        gesture,\n        sequence_type,\n        COUNT(*) as count,\n        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    GROUP BY gesture, sequence_type\n    ORDER BY count DESC\n    LIMIT 15\n\"\"\").fetchdf()\n\nprint(gesture_sequence_type.to_string(index=False))\n\n# è¡Œå‹•ãƒ•ã‚§ãƒ¼ã‚ºã®è©³ç´°åˆ†æ\nprint(\"\\nğŸ“Š Behavior Phase Distribution by Gesture (Top 5):\")\nbehavior_phase = conn.execute(\"\"\"\n    SELECT \n        gesture,\n        behavior,\n        COUNT(*) as count,\n        ROUND(AVG(sequence_counter), 1) as avg_timestamp\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE gesture IN (\n        SELECT gesture \n        FROM \"cmi_detect_behavior_with_sensor_data\".train \n        GROUP BY gesture \n        ORDER BY COUNT(*) DESC \n        LIMIT 5\n    )\n    GROUP BY gesture, behavior\n    ORDER BY gesture, count DESC\n\"\"\").fetchdf()\n\nprint(behavior_phase.to_string(index=False))\n\n# ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã®è©³ç´°è©•ä¾¡\nprint(\"\\nâš–ï¸ Class Imbalance Analysis:\")\n\n# Binary classification (sequence_type)\nbinary_balance = conn.execute(\"\"\"\n    SELECT \n        sequence_type,\n        COUNT(*) as count,\n        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train), 2) as percentage\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    GROUP BY sequence_type\n    ORDER BY count DESC\n\"\"\").fetchdf()\n\nprint(\"Binary Classification (sequence_type):\")\nprint(binary_balance.to_string(index=False))\n\n# Multi-class gesture distribution\ngesture_balance = conn.execute(\"\"\"\n    SELECT \n        gesture,\n        COUNT(*) as count,\n        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train), 2) as percentage,\n        COUNT(DISTINCT subject) as participants\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    GROUP BY gesture\n    ORDER BY count DESC\n\"\"\").fetchdf()\n\nprint(f\"\\nMulti-class Gesture Distribution (18 classes):\")\nprint(gesture_balance.to_string(index=False))\n\n# ä¸å‡è¡¡æ¯”ç‡ã®è¨ˆç®—\nmax_class = gesture_balance['count'].max()\nmin_class = gesture_balance['count'].min()\nimbalance_ratio = max_class / min_class\n\nprint(f\"\\nğŸ“ˆ Class Imbalance Metrics:\")\nprint(f\"  â€¢ Most frequent gesture: {gesture_balance.iloc[0]['gesture']} ({gesture_balance.iloc[0]['count']:,} samples)\")\nprint(f\"  â€¢ Least frequent gesture: {gesture_balance.iloc[-1]['gesture']} ({gesture_balance.iloc[-1]['count']:,} samples)\")\nprint(f\"  â€¢ Imbalance ratio: {imbalance_ratio:.1f}:1\")\nprint(f\"  â€¢ Macro F1 challenge level: {'HIGH' if imbalance_ratio > 10 else 'MEDIUM' if imbalance_ratio > 3 else 'LOW'}\")\n\nprint(\"\\n\" + \"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "nj20rd5q4hp",
   "source": "# 2. ğŸ” ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒåˆ†æ\nprint(\"ğŸ” 2. SENSOR DATA DISTRIBUTION ANALYSIS\")\nprint(\"=\" * 60)\n\n# IMUã‚»ãƒ³ã‚µãƒ¼ã®åŸºæœ¬çµ±è¨ˆé‡\nprint(\"ğŸ¯ IMU Sensor Statistics:\")\nimu_stats = conn.execute(\"\"\"\n    SELECT \n        'acc_x' as sensor,\n        COUNT(*) - COUNT(acc_x) as null_count,\n        ROUND(AVG(acc_x), 4) as mean_val,\n        ROUND(STDDEV(acc_x), 4) as std_val,\n        ROUND(MIN(acc_x), 4) as min_val,\n        ROUND(MAX(acc_x), 4) as max_val,\n        ROUND(PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY acc_x), 4) as median_val\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE acc_x IS NOT NULL\n    \n    UNION ALL\n    \n    SELECT \n        'acc_y',\n        COUNT(*) - COUNT(acc_y),\n        ROUND(AVG(acc_y), 4),\n        ROUND(STDDEV(acc_y), 4),\n        ROUND(MIN(acc_y), 4),\n        ROUND(MAX(acc_y), 4),\n        ROUND(PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY acc_y), 4)\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE acc_y IS NOT NULL\n    \n    UNION ALL\n    \n    SELECT \n        'acc_z',\n        COUNT(*) - COUNT(acc_z),\n        ROUND(AVG(acc_z), 4),\n        ROUND(STDDEV(acc_z), 4),\n        ROUND(MIN(acc_z), 4),\n        ROUND(MAX(acc_z), 4),\n        ROUND(PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY acc_z), 4)\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE acc_z IS NOT NULL\n\"\"\").fetchdf()\n\nprint(imu_stats.to_string(index=False))\n\n# å›è»¢ã‚»ãƒ³ã‚µãƒ¼ï¼ˆã‚¯ã‚©ãƒ¼ã‚¿ãƒ‹ã‚ªãƒ³ï¼‰ã®çµ±è¨ˆé‡\nprint(\"\\nğŸ”„ Rotation Quaternion Statistics:\")\nrot_stats = conn.execute(\"\"\"\n    SELECT \n        'rot_w' as sensor,\n        COUNT(*) - COUNT(rot_w) as null_count,\n        ROUND(AVG(rot_w), 4) as mean_val,\n        ROUND(STDDEV(rot_w), 4) as std_val,\n        ROUND(MIN(rot_w), 4) as min_val,\n        ROUND(MAX(rot_w), 4) as max_val\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE rot_w IS NOT NULL\n    \n    UNION ALL\n    \n    SELECT 'rot_x', COUNT(*) - COUNT(rot_x), ROUND(AVG(rot_x), 4), ROUND(STDDEV(rot_x), 4), ROUND(MIN(rot_x), 4), ROUND(MAX(rot_x), 4)\n    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE rot_x IS NOT NULL\n    \n    UNION ALL\n    \n    SELECT 'rot_y', COUNT(*) - COUNT(rot_y), ROUND(AVG(rot_y), 4), ROUND(STDDEV(rot_y), 4), ROUND(MIN(rot_y), 4), ROUND(MAX(rot_y), 4)\n    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE rot_y IS NOT NULL\n    \n    UNION ALL\n    \n    SELECT 'rot_z', COUNT(*) - COUNT(rot_z), ROUND(AVG(rot_z), 4), ROUND(STDDEV(rot_z), 4), ROUND(MIN(rot_z), 4), ROUND(MAX(rot_z), 4)\n    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE rot_z IS NOT NULL\n\"\"\").fetchdf()\n\nprint(rot_stats.to_string(index=False))\n\n# æ¸©åº¦ã‚»ãƒ³ã‚µãƒ¼ã®çµ±è¨ˆé‡\nprint(\"\\nğŸŒ¡ï¸ Thermopile Sensor Statistics:\")\nthm_stats = conn.execute(\"\"\"\n    SELECT \n        'thm_1' as sensor,\n        COUNT(*) - COUNT(thm_1) as null_count,\n        ROUND(AVG(thm_1), 2) as mean_val,\n        ROUND(STDDEV(thm_1), 2) as std_val,\n        ROUND(MIN(thm_1), 2) as min_val,\n        ROUND(MAX(thm_1), 2) as max_val\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    WHERE thm_1 IS NOT NULL\n    \n    UNION ALL SELECT 'thm_2', COUNT(*) - COUNT(thm_2), ROUND(AVG(thm_2), 2), ROUND(STDDEV(thm_2), 2), ROUND(MIN(thm_2), 2), ROUND(MAX(thm_2), 2)\n    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE thm_2 IS NOT NULL\n    UNION ALL SELECT 'thm_3', COUNT(*) - COUNT(thm_3), ROUND(AVG(thm_3), 2), ROUND(STDDEV(thm_3), 2), ROUND(MIN(thm_3), 2), ROUND(MAX(thm_3), 2)\n    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE thm_3 IS NOT NULL\n    UNION ALL SELECT 'thm_4', COUNT(*) - COUNT(thm_4), ROUND(AVG(thm_4), 2), ROUND(STDDEV(thm_4), 2), ROUND(MIN(thm_4), 2), ROUND(MAX(thm_4), 2)\n    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE thm_4 IS NOT NULL\n    UNION ALL SELECT 'thm_5', COUNT(*) - COUNT(thm_5), ROUND(AVG(thm_5), 2), ROUND(STDDEV(thm_5), 2), ROUND(MIN(thm_5), 2), ROUND(MAX(thm_5), 2)\n    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE thm_5 IS NOT NULL\n\"\"\").fetchdf()\n\nprint(thm_stats.to_string(index=False))\n\nprint(\"\\n\" + \"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "dsndjmnwye4",
   "source": "# 1. ğŸ“Š åŒ…æ‹¬çš„ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°\nprint(\"ğŸ” 1. COMPREHENSIVE DATA PROFILING\")\nprint(\"=\" * 60)\n\n# åŸºæœ¬ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®ç¢ºèª\nprint(\"ğŸ“‹ Dataset Structure:\")\nstructure_info = conn.execute(\"\"\"\n    SELECT \n        'train' as table_name,\n        COUNT(*) as total_rows,\n        COUNT(DISTINCT subject) as unique_participants,\n        COUNT(DISTINCT sequence_id) as unique_sequences,\n        MIN(sequence_counter) as min_counter,\n        MAX(sequence_counter) as max_counter\n    FROM \"cmi_detect_behavior_with_sensor_data\".train\n    \n    UNION ALL\n    \n    SELECT \n        'test' as table_name,\n        COUNT(*) as total_rows,\n        COUNT(DISTINCT subject) as unique_participants,\n        COUNT(DISTINCT sequence_id) as unique_sequences,\n        MIN(sequence_counter) as min_counter,\n        MAX(sequence_counter) as max_counter\n    FROM \"cmi_detect_behavior_with_sensor_data\".test\n\"\"\").fetchdf()\n\nprint(structure_info.to_string(index=False))\n\n# ãƒ‡ãƒ¼ã‚¿å‹ã¨éNULLå€¤ã®è©³ç´°ç¢ºèª\nprint(\"\\nğŸ§® Column Data Types and Non-null Counts:\")\ncolumn_info = conn.execute(\"\"\"\n    SELECT \n        column_name,\n        data_type,\n        is_nullable\n    FROM information_schema.columns \n    WHERE table_schema = 'cmi_detect_behavior_with_sensor_data' \n    AND table_name = 'train'\n    ORDER BY ordinal_position\n\"\"\").fetchdf()\n\nprint(f\"Total columns: {len(column_info)}\")\n\n# ã‚«ãƒ†ã‚´ãƒªåˆ¥ã®åˆ—æ•°\ncategorical_cols = ['row_id', 'sequence_type', 'sequence_id', 'subject', 'orientation', 'behavior', 'phase', 'gesture']\nsensor_cols = [col for col in column_info['column_name'] if col not in categorical_cols]\n\nprint(f\"  ğŸ“ Categorical columns: {len(categorical_cols)}\")\nprint(f\"  ğŸ”¢ Sensor columns: {len(sensor_cols)}\")\n\n# ã‚»ãƒ³ã‚µãƒ¼åˆ¥åˆ†é¡\nimu_cols = [col for col in sensor_cols if col.startswith(('acc_', 'rot_'))]\nthermopile_cols = [col for col in sensor_cols if col.startswith('thm_')]\ntof_cols = [col for col in sensor_cols if col.startswith('tof_')]\n\nprint(f\"    ğŸ¯ IMU sensors: {len(imu_cols)} ({imu_cols})\")\nprint(f\"    ğŸŒ¡ï¸  Thermopile sensors: {len(thermopile_cols)} ({thermopile_cols})\")\nprint(f\"    ğŸ“¡ ToF sensors: {len(tof_cols)} (5 sensors Ã— 64 channels)\")\n\nprint(\"\\n\" + \"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "tbbteeni3z",
   "source": "# ğŸ§  CMI BFRB Detection - æœ¬æ ¼çš„EDA\n\n## ğŸ“‹ åˆ†æãƒ—ãƒ©ãƒ³\n\n### ğŸ¯ ç›®æ¨™\n- **ã‚³ãƒ³ãƒšæ¦‚è¦**: Body-Focused Repetitive Behaviors (BFRB) æ¤œå‡º\n- **è©•ä¾¡æŒ‡æ¨™**: 0.5Ã—(Binary F1 + Macro F1) \n- **ãƒ‡ãƒ¼ã‚¿**: ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«ã‚»ãƒ³ã‚µãƒ¼æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ (50Hz)\n- **å‚åŠ è€…**: 81åã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã€18ç¨®é¡ã®ã‚¸ã‚§ã‚¹ãƒãƒ£ãƒ¼\n\n### ğŸ“Š è©³ç´°åˆ†æé …ç›®\n1. **ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°** - åŸºæœ¬çµ±è¨ˆé‡ã¨å“è³ªè©•ä¾¡\n2. **ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿åˆ†æ** - åˆ†å¸ƒã€å¤–ã‚Œå€¤ã€ãƒã‚¤ã‚ºç‰¹æ€§\n3. **ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°åˆ†æ** - ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã€ç›¸é–¢é–¢ä¿‚\n4. **æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ** - ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ§‹é€ ã€å‘¨æœŸæ€§\n5. **æ¬ æå€¤ãƒ‘ã‚¿ãƒ¼ãƒ³** - ã‚»ãƒ³ã‚µãƒ¼æ•…éšœã€ãƒ‡ãƒ¼ã‚¿å“è³ª\n6. **å‚åŠ è€…ç‰¹æ€§åˆ†æ** - äººå£çµ±è¨ˆå­¦çš„ç‰¹å¾´\n7. **ç‰¹å¾´ç›¸é–¢åˆ†æ** - ãƒãƒ«ãƒã‚³ãƒªãƒ‹ã‚¢ãƒªãƒ†ã‚£ã€ç‰¹å¾´é¸æŠ\n8. **ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«åˆ†æ** - ã‚»ãƒ³ã‚µãƒ¼èåˆã®å¯èƒ½æ€§\n9. **CVæˆ¦ç•¥æ¤œè¨¼** - ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯é˜²æ­¢ç­–\n10. **ç‰¹å¾´å·¥å­¦ææ¡ˆ** - ãƒ‰ãƒ¡ã‚¤ãƒ³çŸ¥è­˜æ´»ç”¨\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ygt0djc9auc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUG DATABASE TABLES ===\n",
      "Connection status: <duckdb.duckdb.DuckDBPyConnection object at 0x7f69477016b0>\n",
      "\n",
      "=== ALL SCHEMAS ===\n",
      "  - cmi_detect_behavior_with_sensor_data\n",
      "  - main\n",
      "  - playground_series_s5e7\n",
      "  - information_schema\n",
      "  - main\n",
      "  - pg_catalog\n",
      "  - main\n",
      "\n",
      "=== ALL TABLES WITH SCHEMA ===\n",
      "Found 7 tables:\n",
      "  - cmi_detect_behavior_with_sensor_data.test\n",
      "  - cmi_detect_behavior_with_sensor_data.test_demographics\n",
      "  - cmi_detect_behavior_with_sensor_data.train\n",
      "  - cmi_detect_behavior_with_sensor_data.train_demographics\n",
      "  - playground_series_s5e7.sample_submission\n",
      "  - playground_series_s5e7.test\n",
      "  - playground_series_s5e7.train\n",
      "\n",
      "=== SHOW TABLES ===\n",
      "Default schema tables: 0 found\n",
      "\n",
      "=== TESTING CMI SCHEMA ACCESS ===\n",
      "âœ… cmi_detect_behavior_with_sensor_data.train accessible: 574945 rows\n",
      "\n",
      "=== KAGGLE_DATASETS SCHEMA CONTENTS ===\n",
      "Error listing cmi schema tables: Parser Error: syntax error at or near \"FROM\"\n",
      "\n",
      "=== DATABASE FILE INFO ===\n",
      "âœ… Database file exists, size: 286,273,536 bytes (273.0 MB)\n"
     ]
    }
   ],
   "source": [
    "# Debug database tables issue\n",
    "print(\"=== DEBUG DATABASE TABLES ===\")\n",
    "\n",
    "# Check if connection exists\n",
    "try:\n",
    "    print(f\"Connection status: {conn}\")\n",
    "except NameError:\n",
    "    print(\"Connection not found, creating new one...\")\n",
    "    import duckdb\n",
    "    conn = duckdb.connect('/home/wsl/dev/my-study/ml/ml-note/kaggle_datasets.duckdb')\n",
    "\n",
    "# Check all schemas\n",
    "print(\"\\n=== ALL SCHEMAS ===\")\n",
    "schemas = conn.execute(\"SELECT schema_name FROM information_schema.schemata\").fetchall()\n",
    "for schema in schemas:\n",
    "    print(f\"  - {schema[0]}\")\n",
    "\n",
    "# Check all tables with schema\n",
    "print(\"\\n=== ALL TABLES WITH SCHEMA ===\")\n",
    "tables = conn.execute(\"SELECT table_schema, table_name FROM information_schema.tables WHERE table_type = 'BASE TABLE'\").fetchall()\n",
    "print(f\"Found {len(tables)} tables:\")\n",
    "for schema, table in tables:\n",
    "    print(f\"  - {schema}.{table}\")\n",
    "\n",
    "# Try SHOW TABLES in different schemas\n",
    "print(\"\\n=== SHOW TABLES ===\")\n",
    "try:\n",
    "    show_tables = conn.execute(\"SHOW TABLES\").fetchall()\n",
    "    print(f\"Default schema tables: {len(show_tables)} found\")\n",
    "    for table in show_tables:\n",
    "        print(f\"  - {table[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with SHOW TABLES: {e}\")\n",
    "\n",
    "# Try to access the CMI tables directly\n",
    "print(\"\\n=== TESTING CMI SCHEMA ACCESS ===\")\n",
    "try:\n",
    "    result = conn.execute('SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train').fetchone()\n",
    "    print(f\"âœ… cmi_detect_behavior_with_sensor_data.train accessible: {result[0]} rows\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error accessing cmi_detect_behavior_with_sensor_data.train: {e}\")\n",
    "\n",
    "# List all objects in kaggle_datasets schema\n",
    "print(\"\\n=== KAGGLE_DATASETS SCHEMA CONTENTS ===\")\n",
    "try:\n",
    "    result = conn.execute('SHOW TABLES FROM \"kaggle_datasets\".\"cmi_detect_behavior_with_sensor_data\"').fetchall()\n",
    "    print(f\"Tables in cmi_detect_behavior_with_sensor_data schema:\")\n",
    "    for table in result:\n",
    "        print(f\"  - {table[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error listing cmi schema tables: {e}\")\n",
    "\n",
    "print(\"\\n=== DATABASE FILE INFO ===\")\n",
    "import os\n",
    "db_path = '/home/wsl/dev/my-study/ml/ml-note/kaggle_datasets.duckdb'\n",
    "if os.path.exists(db_path):\n",
    "    size = os.path.getsize(db_path)\n",
    "    print(f\"âœ… Database file exists, size: {size:,} bytes ({size/1024/1024:.1f} MB)\")\n",
    "else:\n",
    "    print(\"âŒ Database file does not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "gzao13pnms5",
   "source": "import duckdb\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nprint(\"ğŸ” CMI BFRB Detection Dataset - EDA\")\nprint(\"=\" * 50)\n\n# Connect to the DuckDB database\nconn = duckdb.connect('/home/wsl/dev/my-study/ml/ml-note/kaggle_datasets.duckdb')\n\n# Show tables from the correct schema\nprint(\"ğŸ“Š Available tables in cmi_detect_behavior_with_sensor_data schema:\")\ntables = conn.execute(\"\"\"\n    SELECT table_name \n    FROM information_schema.tables \n    WHERE table_schema = 'cmi_detect_behavior_with_sensor_data'\n    ORDER BY table_name\n\"\"\").fetchall()\n\nfor table in tables:\n    print(f\"  âœ… {table[0]}\")\n\nprint(f\"\\nğŸ“ˆ Database size: {286.3:.1f} MB with {len(tables)} tables\")\nprint(f\"ğŸ¯ Target dataset: CMI Body-Focused Repetitive Behaviors Detection\")\nprint(\"=\" * 50)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "htdje7frgh6",
   "metadata": {},
   "source": [
    "## Key Dataset Findings\n",
    "\n",
    "### Data Size\n",
    "- **Train**: 574,945 rows across 81 participants (8,151 sequences)\n",
    "- **Test**: 107 rows across 2 participants (2 sequences)  \n",
    "- **No participant overlap** between train and test sets\n",
    "\n",
    "### Data Distribution\n",
    "- Average ~7,098 rows per participant in training\n",
    "- Average ~71 sequences per participant in training\n",
    "- Test set appears to be a small sample for submission format\n",
    "\n",
    "### Important Notes\n",
    "- This is a **time series** dataset with sequence structure\n",
    "- Need **GroupKFold by participant** to prevent data leakage\n",
    "- Large training set (~575k timesteps) suggests 50Hz sampling over multiple sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "m4mtsa81enc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA SIZE ANALYSIS ===\n",
      "Train data rows: 574,945\n",
      "Test data rows: 107\n",
      "Train demographics: 81\n",
      "Test demographics: 2\n",
      "\n",
      "=== PARTICIPANT ANALYSIS ===\n",
      "Unique participants in train: 81\n",
      "Unique participants in test: 2\n",
      "Participants appearing in both train and test: 0\n",
      "\n",
      "=== SEQUENCE ANALYSIS ===\n",
      "Unique sequences in train: 8151\n",
      "Unique sequences in test: 2\n"
     ]
    }
   ],
   "source": [
    "# Re-establish database connection for this cell\n",
    "import duckdb\n",
    "conn = duckdb.connect('/home/wsl/dev/my-study/ml/ml-note/kaggle_datasets.duckdb')\n",
    "\n",
    "# Data size and distribution analysis\n",
    "print(\"=== DATA SIZE ANALYSIS ===\")\n",
    "\n",
    "# Check row counts\n",
    "train_count = conn.execute('SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train').fetchone()[0]\n",
    "test_count = conn.execute('SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".test').fetchone()[0]\n",
    "train_demo_count = conn.execute('SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics').fetchone()[0]\n",
    "test_demo_count = conn.execute('SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".test_demographics').fetchone()[0]\n",
    "\n",
    "print(f\"Train data rows: {train_count:,}\")\n",
    "print(f\"Test data rows: {test_count:,}\")\n",
    "print(f\"Train demographics: {train_demo_count:,}\")\n",
    "print(f\"Test demographics: {test_demo_count:,}\")\n",
    "\n",
    "print(\"\\n=== PARTICIPANT ANALYSIS ===\")\n",
    "\n",
    "# Unique participants\n",
    "train_participants = conn.execute('SELECT COUNT(DISTINCT subject) FROM \"cmi_detect_behavior_with_sensor_data\".train').fetchone()[0]\n",
    "test_participants = conn.execute('SELECT COUNT(DISTINCT subject) FROM \"cmi_detect_behavior_with_sensor_data\".test').fetchone()[0]\n",
    "\n",
    "print(f\"Unique participants in train: {train_participants}\")\n",
    "print(f\"Unique participants in test: {test_participants}\")\n",
    "\n",
    "# Check for overlap in participants between train and test\n",
    "overlap_check = conn.execute('''\n",
    "    SELECT COUNT(*) FROM (\n",
    "        SELECT subject FROM \"cmi_detect_behavior_with_sensor_data\".train \n",
    "        INTERSECT \n",
    "        SELECT subject FROM \"cmi_detect_behavior_with_sensor_data\".test\n",
    "    )\n",
    "''').fetchone()[0]\n",
    "\n",
    "print(f\"Participants appearing in both train and test: {overlap_check}\")\n",
    "\n",
    "print(\"\\n=== SEQUENCE ANALYSIS ===\")\n",
    "\n",
    "# Sequence counts\n",
    "train_sequences = conn.execute('SELECT COUNT(DISTINCT sequence_id) FROM \"cmi_detect_behavior_with_sensor_data\".train').fetchone()[0]\n",
    "test_sequences = conn.execute('SELECT COUNT(DISTINCT sequence_id) FROM \"cmi_detect_behavior_with_sensor_data\".test').fetchone()[0]\n",
    "\n",
    "print(f\"Unique sequences in train: {train_sequences}\")\n",
    "print(f\"Unique sequences in test: {test_sequences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ll1cpx7x8b",
   "metadata": {},
   "source": [
    "# CMI BFRB Detection - Exploratory Data Analysis\n",
    "\n",
    "## Dataset Schema Analysis\n",
    "\n",
    "### Data Structure Overview\n",
    "- **Train table**: Contains sensor data with target labels (behavior, gesture, phase)\n",
    "- **Test table**: Contains sensor data without target labels  \n",
    "- **Demographics tables**: Participant information (age, sex, handedness, physical measurements)\n",
    "\n",
    "### Sensor Features\n",
    "- **IMU sensors**: acc_x/y/z (accelerometer), rot_w/x/y/z (rotation quaternion) = 7 features\n",
    "- **Thermopile sensors**: thm_1 to thm_5 = 5 features  \n",
    "- **ToF sensors**: tof_1 to tof_5 with 64 values each (v0 to v63) = 320 features\n",
    "- **Total sensor features**: 332 per timestep\n",
    "\n",
    "### Target Variables (Train only)\n",
    "- **behavior**: Binary classification (BFRB vs non-BFRB)\n",
    "- **gesture**: Multi-class classification (specific gesture types)\n",
    "- **phase**: Multi-class classification (gesture phases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}