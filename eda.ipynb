{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "uch3chw3wf",
   "metadata": {},
   "source": [
    "# üèÜ CMI BFRB Detection - EDAÁ∑èÊã¨\n",
    "\n",
    "## üìä ÈáçË¶Å„Å™Áô∫Ë¶ã‰∫ãÈ†Ö\n",
    "\n",
    "### ‚úÖ „Éá„Éº„ÇøÂìÅË≥™\n",
    "- **È´òÂìÅË≥™IMU„Éá„Éº„Çø**: Âä†ÈÄüÂ∫¶„Çª„É≥„Çµ„Éº„ÅØÊ¨†ÊêçÂÄ§0%„ÄÅ‰ø°È†ºÊÄß„ÅÆÈ´ò„ÅÑ„Éô„Éº„Çπ„É©„Ç§„É≥\n",
    "- **ÈÉ®ÂàÜÁöÑ„Çª„É≥„Çµ„ÉºÊïÖÈöú**: ToF_5„Å®thm_5„Åå5%‰ª•‰∏äÊ¨†Êêç ‚Üí Ë£úÂÆåÊà¶Áï•ÂøÖË¶Å\n",
    "- **ÊôÇÁ≥ªÂàóÈÄ£Á∂öÊÄß**: „Ç∑„Éº„Ç±„É≥„ÇπÂÜÖ„Åß„ÇÆ„É£„ÉÉ„Éó„Å™„Åó„ÄÅ50Hz‰∏ÄÂÆö„Çµ„É≥„Éó„É™„É≥„Ç∞\n",
    "\n",
    "### üéØ „Çø„Éº„Ç≤„ÉÉ„ÉàÂ§âÊï∞ÁâπÊÄß\n",
    "- **„Éê„Ç§„Éä„É™ÂàÜÈ°û**: Target/Non-Target = 60/40 ‚Üí Binary F1„ÅØÈÅîÊàêÂèØËÉΩ\n",
    "- **„Éû„É´„ÉÅ„ÇØ„É©„ÇπÂàÜÈ°û**: 18„Ç∏„Çß„Çπ„ÉÅ„É£„Éº„ÄÅ6:1„ÅÆ‰∏çÂùáË°° ‚Üí Macro F1„ÅåÂõ∞Èõ£\n",
    "- **ÊôÇÁ≥ªÂàóÊßãÈÄ†**: Âπ≥Âùá1.4Áßí„ÅÆÁü≠„ÅÑ„Ç∑„Éº„Ç±„É≥„Çπ ‚Üí „Ç∏„Çß„Çπ„ÉÅ„É£„ÉºË™çË≠ò„Çø„Çπ„ÇØ\n",
    "\n",
    "### üë• ÂèÇÂä†ËÄÖ„Éá„Éº„Çø\n",
    "- **ÂÆåÂÖ®ÂàÜÈõ¢**: Ë®ìÁ∑¥„Éª„ÉÜ„Çπ„ÉàÈñì„ÅßÂèÇÂä†ËÄÖÈáçË§á„Å™„Åó ‚úÖ\n",
    "- **ÂùáÁ≠âÂàÜÂ∏É**: ÂèÇÂä†ËÄÖÈñì„Éá„Éº„ÇøÈáè„ÅØÊØîËºÉÁöÑ„Éê„É©„É≥„ÇπËâØÂ•Ω\n",
    "- **ÂÖ®„Ç∏„Çß„Çπ„ÉÅ„É£„Éº„Ç´„Éê„Éº**: ÂÖ®ÂèÇÂä†ËÄÖ„ÅåÂÖ®„Ç∏„Çß„Çπ„ÉÅ„É£„Éº„Çø„Ç§„Éó„ÇíÂÆüË°å\n",
    "\n",
    "### üîó „Çª„É≥„Çµ„ÉºÁõ∏Èñ¢\n",
    "- **„É¢„ÉÄ„É™„ÉÜ„Ç£Èñì‰ΩéÁõ∏Èñ¢**: IMU/ToF/Ê∏©Â∫¶„ÅØË£úÂÆåÁöÑÊÉÖÂ†±„ÇíÊèê‰æõ\n",
    "- **„Éû„É´„ÉÅ„Ç≥„É™„Éã„Ç¢„É™„ÉÜ„Ç£**: Ê∑±Âàª„Å™ÂïèÈ°å„Å™„Åó„ÄÅËûçÂêà„Å´ÈÅ©„Åó„Å¶„ÅÑ„Çã\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ „Ç≥„É≥„Éö„ÉÜ„Ç£„Ç∑„Éß„É≥Êà¶Áï•\n",
    "\n",
    "### üìà ÁõÆÊ®ô„Çπ„Ç≥„Ç¢\n",
    "- **ÁèæÂÆüÁöÑÁõÆÊ®ô**: Combined F1 = 0.60-0.65 (ÈäÖ„É°„ÉÄ„É´Âúè)\n",
    "- **Binary F1**: 0.65-0.70 (ÊØîËºÉÁöÑÈÅîÊàê„Åó„ÇÑ„Åô„ÅÑ)\n",
    "- **Macro F1**: 0.55-0.65 (18„ÇØ„É©„Çπ‰∏çÂùáË°°„ÅßÂõ∞Èõ£)\n",
    "\n",
    "### üèóÔ∏è Êé®Â•®„Ç¢„Éó„É≠„Éº„ÉÅ\n",
    "\n",
    "#### Phase 1: „Éô„Éº„Çπ„É©„Ç§„É≥ÊßãÁØâ (Week 1)\n",
    "1. **GroupKFold CV** „Çª„ÉÉ„Éà„Ç¢„ÉÉ„Éó (participant-based)\n",
    "2. **Âü∫Êú¨ÁâπÂæ¥Èáè**: IMU magnitude, rolling statistics\n",
    "3. **LightGBM** with missing value handling\n",
    "4. **ÁõÆÊ®ô**: CV 0.50+, LB 0.50+\n",
    "\n",
    "#### Phase 2: ÁâπÂæ¥Â∑•Â≠¶ (Week 2-3)\n",
    "1. **FFT spectrum** features for IMU\n",
    "2. **ToF PCA** dimensionality reduction  \n",
    "3. **Multimodal fusion** features\n",
    "4. **1D CNN** on raw sensor streams\n",
    "5. **ÁõÆÊ®ô**: CV 0.58+, LB 0.57+\n",
    "\n",
    "#### Phase 3: „É¢„Éá„É´ÊúÄÈÅ©Âåñ (Week 4-5)\n",
    "1. **Multi-branch CNN** (IMU/ToF/Thermopile separate)\n",
    "2. **Ensemble** multiple models\n",
    "3. **Hyperparameter tuning**\n",
    "4. **ÁõÆÊ®ô**: CV 0.62+, LB 0.60+ (ÈäÖ„É°„ÉÄ„É´)\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è ÈáçË¶Å„Å™Ê≥®ÊÑèÁÇπ\n",
    "\n",
    "### üö® „É™„Çπ„ÇØË¶ÅÂõ†\n",
    "1. **Macro F1 difficulty**: 18„ÇØ„É©„Çπ‰∏çÂùáË°°„Å´„Çà„Çä0.5‰ª•‰∏ã„ÅÆÂèØËÉΩÊÄß\n",
    "2. **Sensor 5 missing**: ToF_5/thm_5Ê¨†Êêç„Å´„Çà„ÇãÊÉÖÂ†±ÊêçÂ§±  \n",
    "3. **CV-LB gap**: ‰∫∫„Éô„Éº„ÇπGroupKFold„Åß„Ç∫„É¨ÂèØËÉΩÊÄß\n",
    "\n",
    "### üõ°Ô∏è ÂØæÁ≠ñ\n",
    "1. **„ÇØ„É©„ÇπÈáç„ÅøË™øÊï¥**: Macro F1Âêë‰∏ä„ÅÆ„Åü„ÇÅfocal lossÁ≠â\n",
    "2. **Ê¨†ÊêçÂÄ§Êà¶Áï•**: imputation + availability indicators\n",
    "3. **CV robustness**: Ë§áÊï∞„Ç∑„Éº„Éâ„ÄÅfoldÂàÜÊï£Áõ£Ë¶ñ\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Next Steps\n",
    "\n",
    "1. **ÁâπÂæ¥Â∑•Â≠¶„Éë„Ç§„Éó„É©„Ç§„É≥** ÂÆüË£ÖÈñãÂßã\n",
    "2. **GroupKFold CV** Áí∞Â¢ÉÊßãÁØâ\n",
    "3. **„Éô„Éº„Çπ„É©„Ç§„É≥„É¢„Éá„É´** (tsfresh + LightGBM)\n",
    "4. **ÈÄ≤Êçó„É¢„Éã„Çø„É™„É≥„Ç∞** „Ç∑„Çπ„ÉÜ„É†ÊßãÁØâ\n",
    "\n",
    "**ÊúüÂæÖ„Åï„Çå„ÇãÊàêÊûú**: ÈÅ©Âàá„Å™ÁâπÂæ¥Â∑•Â≠¶„Å®CVÊà¶Áï•„Å´„Çà„Çä„ÄÅÈäÖ„É°„ÉÄ„É´ÂúèÂÜÖ(top 200)Âà∞ÈÅîÂèØËÉΩ\n",
    "\n",
    "---\n",
    "\n",
    "## üìã ËøΩÂä†ÂàÜÊûêÊé®Â•®È†ÖÁõÆ\n",
    "\n",
    "### üîç „Éá„Éº„ÇøÂìÅË≥™Âº∑Âåñ\n",
    "- **„Çª„É≥„Çµ„ÉºÂÄ§„ÅÆÁâ©ÁêÜÁØÑÂõ≤Â§ñ„ÇåÊ§úÁü•**: IMU ¬±16g„ÄÅToF 0-4000mm ÁØÑÂõ≤„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "- **„Éâ„É™„Éï„Éà/„Ç™„Éï„Çª„ÉÉ„ÉàÁ¢∫Ë™ç**: „Çª„ÉÉ„Ç∑„Éß„É≥Âà•„ÅÆÂπ≥Âùá„ÉªÂàÜÊï£ÊôÇÁ≥ªÂàó„Éó„É≠„ÉÉ„Éà\n",
    "- **ÊôÇÁ≥ªÂàóÈáçË§á„ÉªÈ†ÜÂ∫è‰π±„Çå**: duplicate timestamp Ê§úÂá∫\n",
    "\n",
    "### üéØ „Çø„Éº„Ç≤„ÉÉ„Éà„Éª‰∏çÂùáË°°ÂØæÁ≠ñÊ§úË®º\n",
    "- **„ÇØ„É©„ÇπÈñì„ÅÆÊôÇÈñìÁöÑÂàÜÂ∏É**: ÁâπÂÆö„Ç∏„Çß„Çπ„ÉÅ„É£„Éº„ÅÆÊôÇÈñìÂÅèÂú®„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "- **„Çµ„Éñ„Çµ„É≥„Éó„É™„É≥„Ç∞ËÄêÊÄß**: Minority „ÇØ„É©„Çπ30/50/70%Ê¨†Êêç„Åß„ÅÆÊÑüÂ∫¶„ÉÜ„Çπ„Éà\n",
    "\n",
    "### üîó „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´Áõ∏Èñ¢Ê∑±Êéò„Çä\n",
    "- **Cross-correlation lag plot**: IMU vs ToF „ÅÆÈÅÖÂª∂Áõ∏Èñ¢Ôºà¬±n lagÔºâ\n",
    "- **UMAP 2D „Éó„É≠„ÉÉ„Éà**: „É¢„ÉÄ„É™„ÉÜ„Ç£Âà•ÊäïÂΩ±„ÄÅ„É©„Éô„É´&ÂèÇÂä†ËÄÖËâ≤ÂàÜ„Åë\n",
    "\n",
    "### üìä CV-LB „ÇÆ„É£„ÉÉ„Éó‰∫àÊ∏¨ÂÆüÈ®ì\n",
    "- **Áñë‰ººLBÂÆüÈ®ì**: 80/20% participant split „Åß„ÅÆ hold-out ‰ΩúÊàê\n",
    "- **CV√óÁñë‰ººLB Êï£Â∏ÉÂõ≥**: 10Âõû„Ç∑„Éº„ÉâÂÆüÈ®ì„ÄÅÂÇæ„Åç‚âà1 Á¢∫Ë™ç\n",
    "\n",
    "„Åì„Çå„Çâ„ÇíËøΩÂä†„Åô„Çã„Å®„ÄÅ„É¢„Éá„É´Âåñ„Éï„Çß„Éº„Ç∫„Åß„ÅÆ„ÄåÊÉ≥ÂÆöÂ§ñ„Äç„ÇíÂ§ßÂπÖ„Å´Ê∏õ„Çâ„Åõ„Åæ„Åô„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "nx0wf098y0k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç „Çª„É≥„Çµ„Éº„ÉÅ„É£„É≥„Éç„É´Âà•Ê¨†ÊêçÂÄ§„ÉªÂàÜÊï£ÂàÜÊûê\n",
      "============================================================\n",
      "üéØ IMU„Çª„É≥„Çµ„Éº (acc_x/y/z, rot_w/x/y/z)\n",
      "channel  total_samples  valid_samples  missing_count  missing_pct  mean_val  std_val  min_val  max_val\n",
      "  acc_x         574945         574945              0         0.00    1.6400   5.7813 -34.5859  46.3281\n",
      "  acc_y         574945         574945              0         0.00    1.7907   5.0039 -24.4023  27.1836\n",
      "  acc_z         574945         574945              0         0.00   -0.4598   6.0965 -42.8555  30.0781\n",
      "  rot_w         574945         571253           3692         0.64    0.3604   0.2257   0.0000   0.9994\n",
      "  rot_x         574945         571253           3692         0.64   -0.1199   0.4655  -0.9991   0.9998\n",
      "\n",
      "üå°Ô∏è Ê∏©Â∫¶„Çª„É≥„Çµ„Éº (thm_1„Äú5)\n",
      "channel  total_samples  valid_samples  missing_count  missing_pct  mean_val  std_val  min_val  max_val\n",
      "  thm_1         574945         567958           6987         1.22     27.08     3.23    -0.37    38.46\n",
      "  thm_2         574945         567307           7638         1.33     27.13     2.94    21.96    37.58\n",
      "  thm_3         574945         568473           6472         1.13     26.70     4.12     0.00    37.29\n",
      "  thm_4         574945         568721           6224         1.08     27.56     2.25    22.38    39.59\n",
      "  thm_5         574945         541659          33286         5.79     26.67     2.44    22.05    37.68\n",
      "\n",
      "üì° ToF„Çª„É≥„Çµ„Éº‰ª£Ë°®„ÉÅ„É£„É≥„Éç„É´ (ÂêÑ„Çª„É≥„Çµ„Éº„ÅÆv0, v31, v63)\n",
      "  channel  total_samples  valid_samples  missing_count  missing_pct  mean_val  std_val  min_val  max_val\n",
      " tof_1_v0         574945         568721           6224         1.08      54.6     72.8     -1.0    249.0\n",
      "tof_1_v31         574945         568721           6224         1.08      48.0     69.5     -1.0    249.0\n",
      "tof_1_v63         574945         568721           6224         1.08      37.5     59.0     -1.0    249.0\n",
      " tof_5_v0         574945         544803          30142         5.24      60.2     72.4     -1.0    249.0\n",
      "\n",
      "üìä „Çª„É≥„Çµ„ÉºÂìÅË≥™„Çµ„Éû„É™„Éº\n",
      "IMU„Çª„É≥„Çµ„ÉºÂìÅË≥™: üü¢ ÂÑ™ÁßÄ\n",
      "Ê∏©Â∫¶„Çª„É≥„Çµ„ÉºÂìÅË≥™: üî¥ Ê≥®ÊÑè\n",
      "ToF„Çª„É≥„Çµ„ÉºÂìÅË≥™: üî¥ Ê≥®ÊÑè\n",
      "\n",
      "‚ö†Ô∏è È´òÊ¨†Êêç„Çª„É≥„Çµ„Éº (>5%):\n",
      "  ‚Ä¢ thm_5: 5.79%\n",
      "  ‚Ä¢ tof_5_v0: 5.24%\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# „Çª„É≥„Çµ„Éº„ÉÅ„É£„É≥„Éç„É´„Åî„Å®„ÅÆÊ¨†ÊêçÂÄ§„ÉªÂàÜÊï£ÂàÜÊûê\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# „Éá„Éº„Çø„Éô„Éº„ÇπÊé•Á∂ö\n",
    "conn = duckdb.connect('/home/wsl/dev/my-study/ml/ml-note/kaggle_datasets.duckdb')\n",
    "\n",
    "print(\"üîç „Çª„É≥„Çµ„Éº„ÉÅ„É£„É≥„Éç„É´Âà•Ê¨†ÊêçÂÄ§„ÉªÂàÜÊï£ÂàÜÊûê\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. IMU„Çª„É≥„Çµ„Éº„ÅÆÊ¨†ÊêçÂÄ§„ÉªÂàÜÊï£ÂàÜÊûê\n",
    "print(\"üéØ IMU„Çª„É≥„Çµ„Éº (acc_x/y/z, rot_w/x/y/z)\")\n",
    "imu_analysis = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        'acc_x' as channel,\n",
    "        COUNT(*) as total_samples,\n",
    "        COUNT(acc_x) as valid_samples,\n",
    "        COUNT(*) - COUNT(acc_x) as missing_count,\n",
    "        ROUND((COUNT(*) - COUNT(acc_x)) * 100.0 / COUNT(*), 2) as missing_pct,\n",
    "        ROUND(AVG(acc_x), 4) as mean_val,\n",
    "        ROUND(STDDEV(acc_x), 4) as std_val,\n",
    "        ROUND(MIN(acc_x), 4) as min_val,\n",
    "        ROUND(MAX(acc_x), 4) as max_val\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'acc_y',\n",
    "        COUNT(*),\n",
    "        COUNT(acc_y),\n",
    "        COUNT(*) - COUNT(acc_y),\n",
    "        ROUND((COUNT(*) - COUNT(acc_y)) * 100.0 / COUNT(*), 2),\n",
    "        ROUND(AVG(acc_y), 4),\n",
    "        ROUND(STDDEV(acc_y), 4),\n",
    "        ROUND(MIN(acc_y), 4),\n",
    "        ROUND(MAX(acc_y), 4)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'acc_z',\n",
    "        COUNT(*),\n",
    "        COUNT(acc_z),\n",
    "        COUNT(*) - COUNT(acc_z),\n",
    "        ROUND((COUNT(*) - COUNT(acc_z)) * 100.0 / COUNT(*), 2),\n",
    "        ROUND(AVG(acc_z), 4),\n",
    "        ROUND(STDDEV(acc_z), 4),\n",
    "        ROUND(MIN(acc_z), 4),\n",
    "        ROUND(MAX(acc_z), 4)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'rot_w',\n",
    "        COUNT(*),\n",
    "        COUNT(rot_w),\n",
    "        COUNT(*) - COUNT(rot_w),\n",
    "        ROUND((COUNT(*) - COUNT(rot_w)) * 100.0 / COUNT(*), 2),\n",
    "        ROUND(AVG(rot_w), 4),\n",
    "        ROUND(STDDEV(rot_w), 4),\n",
    "        ROUND(MIN(rot_w), 4),\n",
    "        ROUND(MAX(rot_w), 4)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'rot_x',\n",
    "        COUNT(*),\n",
    "        COUNT(rot_x),\n",
    "        COUNT(*) - COUNT(rot_x),\n",
    "        ROUND((COUNT(*) - COUNT(rot_x)) * 100.0 / COUNT(*), 2),\n",
    "        ROUND(AVG(rot_x), 4),\n",
    "        ROUND(STDDEV(rot_x), 4),\n",
    "        ROUND(MIN(rot_x), 4),\n",
    "        ROUND(MAX(rot_x), 4)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(imu_analysis.to_string(index=False))\n",
    "\n",
    "# 2. Ê∏©Â∫¶„Çª„É≥„Çµ„Éº„ÅÆÊ¨†ÊêçÂÄ§„ÉªÂàÜÊï£ÂàÜÊûê\n",
    "print(\"\\nüå°Ô∏è Ê∏©Â∫¶„Çª„É≥„Çµ„Éº (thm_1„Äú5)\")\n",
    "thm_analysis = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        'thm_1' as channel,\n",
    "        COUNT(*) as total_samples,\n",
    "        COUNT(thm_1) as valid_samples,\n",
    "        COUNT(*) - COUNT(thm_1) as missing_count,\n",
    "        ROUND((COUNT(*) - COUNT(thm_1)) * 100.0 / COUNT(*), 2) as missing_pct,\n",
    "        ROUND(AVG(thm_1), 2) as mean_val,\n",
    "        ROUND(STDDEV(thm_1), 2) as std_val,\n",
    "        ROUND(MIN(thm_1), 2) as min_val,\n",
    "        ROUND(MAX(thm_1), 2) as max_val\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT 'thm_2', COUNT(*), COUNT(thm_2), COUNT(*) - COUNT(thm_2), \n",
    "           ROUND((COUNT(*) - COUNT(thm_2)) * 100.0 / COUNT(*), 2),\n",
    "           ROUND(AVG(thm_2), 2), ROUND(STDDEV(thm_2), 2), ROUND(MIN(thm_2), 2), ROUND(MAX(thm_2), 2)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT 'thm_3', COUNT(*), COUNT(thm_3), COUNT(*) - COUNT(thm_3), \n",
    "           ROUND((COUNT(*) - COUNT(thm_3)) * 100.0 / COUNT(*), 2),\n",
    "           ROUND(AVG(thm_3), 2), ROUND(STDDEV(thm_3), 2), ROUND(MIN(thm_3), 2), ROUND(MAX(thm_3), 2)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT 'thm_4', COUNT(*), COUNT(thm_4), COUNT(*) - COUNT(thm_4), \n",
    "           ROUND((COUNT(*) - COUNT(thm_4)) * 100.0 / COUNT(*), 2),\n",
    "           ROUND(AVG(thm_4), 2), ROUND(STDDEV(thm_4), 2), ROUND(MIN(thm_4), 2), ROUND(MAX(thm_4), 2)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT 'thm_5', COUNT(*), COUNT(thm_5), COUNT(*) - COUNT(thm_5), \n",
    "           ROUND((COUNT(*) - COUNT(thm_5)) * 100.0 / COUNT(*), 2),\n",
    "           ROUND(AVG(thm_5), 2), ROUND(STDDEV(thm_5), 2), ROUND(MIN(thm_5), 2), ROUND(MAX(thm_5), 2)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(thm_analysis.to_string(index=False))\n",
    "\n",
    "# 3. ToF„Çª„É≥„Çµ„Éº„ÅÆ‰ª£Ë°®„ÉÅ„É£„É≥„Éç„É´„ÅÆÊ¨†ÊêçÂÄ§„ÉªÂàÜÊï£ÂàÜÊûê\n",
    "print(\"\\nüì° ToF„Çª„É≥„Çµ„Éº‰ª£Ë°®„ÉÅ„É£„É≥„Éç„É´ (ÂêÑ„Çª„É≥„Çµ„Éº„ÅÆv0, v31, v63)\")\n",
    "tof_analysis = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        'tof_1_v0' as channel,\n",
    "        COUNT(*) as total_samples,\n",
    "        COUNT(tof_1_v0) as valid_samples,\n",
    "        COUNT(*) - COUNT(tof_1_v0) as missing_count,\n",
    "        ROUND((COUNT(*) - COUNT(tof_1_v0)) * 100.0 / COUNT(*), 2) as missing_pct,\n",
    "        ROUND(AVG(tof_1_v0), 1) as mean_val,\n",
    "        ROUND(STDDEV(tof_1_v0), 1) as std_val,\n",
    "        ROUND(MIN(tof_1_v0), 1) as min_val,\n",
    "        ROUND(MAX(tof_1_v0), 1) as max_val\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT 'tof_1_v31', COUNT(*), COUNT(tof_1_v31), COUNT(*) - COUNT(tof_1_v31), \n",
    "           ROUND((COUNT(*) - COUNT(tof_1_v31)) * 100.0 / COUNT(*), 2),\n",
    "           ROUND(AVG(tof_1_v31), 1), ROUND(STDDEV(tof_1_v31), 1), ROUND(MIN(tof_1_v31), 1), ROUND(MAX(tof_1_v31), 1)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT 'tof_1_v63', COUNT(*), COUNT(tof_1_v63), COUNT(*) - COUNT(tof_1_v63), \n",
    "           ROUND((COUNT(*) - COUNT(tof_1_v63)) * 100.0 / COUNT(*), 2),\n",
    "           ROUND(AVG(tof_1_v63), 1), ROUND(STDDEV(tof_1_v63), 1), ROUND(MIN(tof_1_v63), 1), ROUND(MAX(tof_1_v63), 1)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT 'tof_5_v0', COUNT(*), COUNT(tof_5_v0), COUNT(*) - COUNT(tof_5_v0), \n",
    "           ROUND((COUNT(*) - COUNT(tof_5_v0)) * 100.0 / COUNT(*), 2),\n",
    "           ROUND(AVG(tof_5_v0), 1), ROUND(STDDEV(tof_5_v0), 1), ROUND(MIN(tof_5_v0), 1), ROUND(MAX(tof_5_v0), 1)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(tof_analysis.to_string(index=False))\n",
    "\n",
    "# 4. „Çª„É≥„Çµ„ÉºÂìÅË≥™„Çµ„Éû„É™„Éº\n",
    "print(\"\\nüìä „Çª„É≥„Çµ„ÉºÂìÅË≥™„Çµ„Éû„É™„Éº\")\n",
    "print(\"IMU„Çª„É≥„Çµ„ÉºÂìÅË≥™:\", \"üü¢ ÂÑ™ÁßÄ\" if imu_analysis['missing_pct'].max() < 1 else \"üü° ËâØÂ•Ω\" if imu_analysis['missing_pct'].max() < 5 else \"üî¥ Ê≥®ÊÑè\")\n",
    "print(\"Ê∏©Â∫¶„Çª„É≥„Çµ„ÉºÂìÅË≥™:\", \"üü¢ ÂÑ™ÁßÄ\" if thm_analysis['missing_pct'].max() < 1 else \"üü° ËâØÂ•Ω\" if thm_analysis['missing_pct'].max() < 5 else \"üî¥ Ê≥®ÊÑè\")\n",
    "print(\"ToF„Çª„É≥„Çµ„ÉºÂìÅË≥™:\", \"üü¢ ÂÑ™ÁßÄ\" if tof_analysis['missing_pct'].max() < 1 else \"üü° ËâØÂ•Ω\" if tof_analysis['missing_pct'].max() < 5 else \"üî¥ Ê≥®ÊÑè\")\n",
    "\n",
    "# 5. È´òÊ¨†Êêç„Çª„É≥„Çµ„Éº„ÅÆÁâπÂÆö\n",
    "high_missing = []\n",
    "for _, row in thm_analysis.iterrows():\n",
    "    if row['missing_pct'] > 5:\n",
    "        high_missing.append(f\"{row['channel']}: {row['missing_pct']}%\")\n",
    "        \n",
    "for _, row in tof_analysis.iterrows():\n",
    "    if row['missing_pct'] > 5:\n",
    "        high_missing.append(f\"{row['channel']}: {row['missing_pct']}%\")\n",
    "\n",
    "if high_missing:\n",
    "    print(\"\\n‚ö†Ô∏è È´òÊ¨†Êêç„Çª„É≥„Çµ„Éº (>5%):\")\n",
    "    for sensor in high_missing:\n",
    "        print(f\"  ‚Ä¢ {sensor}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ ÂÖ®„Çª„É≥„Çµ„Éº„ÅåËâØÂ•Ω„Å™ÂìÅË≥™ (Ê¨†Êêç<5%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "qgij5xrt4cs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≠ Ë°åÂãï„É©„Éô„É´Âá∫ÁèæÈ†ªÂ∫¶„ÉªÈï∑„ÅïÂàÜÂ∏ÉÂàÜÊûê\n",
      "============================================================\n",
      "üéØ „Ç∏„Çß„Çπ„ÉÅ„É£„Éº„É©„Éô„É´Âá∫ÁèæÈ†ªÂ∫¶ (18„ÇØ„É©„Çπ)\n",
      "                                   gesture  frequency  percentage  sequences  participants\n",
      "                             Text on phone      58462       10.17        640            81\n",
      "                            Neck - scratch      56619        9.85        640            81\n",
      "                       Eyebrow - pull hair      44305        7.71        638            81\n",
      "                        Forehead - scratch      40923        7.12        640            81\n",
      "                  Forehead - pull hairline      40802        7.10        640            81\n",
      "                     Above ear - pull hair      40560        7.05        638            81\n",
      "                         Neck - pinch skin      40507        7.05        640            81\n",
      "                       Eyelash - pull hair      40218        7.00        640            81\n",
      "                        Cheek - pinch skin      40124        6.98        637            81\n",
      "                                Wave hello      34356        5.98        478            81\n",
      "                         Write name in air      31267        5.44        477            81\n",
      "                 Pull air toward your face      30743        5.35        477            81\n",
      "Feel around in tray and pull out an object      17114        2.98        161            81\n",
      "                            Glasses on/off      13542        2.36        161            81\n",
      "                     Drink from bottle/cup      13093        2.28        161            81\n",
      "                     Scratch knee/leg skin      12328        2.14        161            81\n",
      "                         Write name on leg      10138        1.76        161            81\n",
      "                       Pinch knee/leg skin       9844        1.71        161            81\n",
      "\n",
      "üìä „ÇØ„É©„Çπ‰∏çÂùáË°°Â∫¶: 5.9:1 (‰∏≠)\n",
      "\n",
      "üîÑ Ë°åÂãï„Éï„Çß„Éº„Ç∫ÂàÜÂ∏É\n",
      "                                 behavior  frequency  percentage  sequences\n",
      "                         Performs gesture     255817       44.49       8150\n",
      "            Moves hand to target location     156474       27.22       4102\n",
      "                  Hand at target location      95173       16.55       8151\n",
      "Relaxes and moves hand to target location      67481       11.74       4049\n",
      "\n",
      "üìè „Ç∑„Éº„Ç±„É≥„ÇπÈï∑ÂàÜÂ∏ÉÂàÜÊûê\n",
      "„Ç∑„Éº„Ç±„É≥„ÇπÈï∑Áµ±Ë®à („Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó):\n",
      "  Âπ≥Âùá: 70.5\n",
      "  ‰∏≠Â§ÆÂÄ§: 59.0\n",
      "  Ê®ôÊ∫ñÂÅèÂ∑Æ: 35.4\n",
      "  ÊúÄÂ∞è-ÊúÄÂ§ß: 29 - 700\n",
      "  Q1-Q3: 51.0 - 78.0\n",
      "\n",
      "„Ç∑„Éº„Ç±„É≥„ÇπÈï∑Áµ±Ë®à (Áßí):\n",
      "  Âπ≥Âùá: 1.41Áßí\n",
      "  ‰∏≠Â§ÆÂÄ§: 1.18Áßí\n",
      "  ÊúÄÈï∑: 14.0Áßí\n",
      "\n",
      "üé≠ „Ç∏„Çß„Çπ„ÉÅ„É£„ÉºÂà•„Ç∑„Éº„Ç±„É≥„ÇπÈï∑\n",
      "                                   gesture  num_sequences  avg_length_timesteps  avg_length_seconds  min_length  max_length  std_length\n",
      "Feel around in tray and pull out an object            161                 106.3                2.13          50         322        52.3\n",
      "                             Text on phone            640                  91.3                1.83          29         390        43.4\n",
      "                            Neck - scratch            640                  88.5                1.77          41         700        73.3\n",
      "                            Glasses on/off            161                  84.1                1.68          43         293        41.0\n",
      "                     Drink from bottle/cup            161                  81.3                1.63          34         176        29.4\n",
      "                     Scratch knee/leg skin            161                  76.6                1.53          42         229        37.4\n",
      "                                Wave hello            478                  71.9                1.44          34         230        29.0\n",
      "                       Eyebrow - pull hair            638                  69.4                1.39          34         371        36.7\n",
      "                         Write name in air            477                  65.5                1.31          39         374        26.8\n",
      "                 Pull air toward your face            477                  64.5                1.29          36         188        19.3\n",
      "                        Forehead - scratch            640                  63.9                1.28          36         245        21.2\n",
      "                  Forehead - pull hairline            640                  63.8                1.28          35         190        19.3\n",
      "                     Above ear - pull hair            638                  63.6                1.27          38         191        19.5\n",
      "                         Neck - pinch skin            640                  63.3                1.27          39         234        21.3\n",
      "                         Write name on leg            161                  63.0                1.26          42         123        17.6\n",
      "                        Cheek - pinch skin            637                  63.0                1.26          38         302        23.2\n",
      "                       Eyelash - pull hair            640                  62.8                1.26          39         200        18.9\n",
      "                       Pinch knee/leg skin            161                  61.1                1.22          35         133        18.0\n",
      "\n",
      "üéØ „Ç∑„Éº„Ç±„É≥„Çπ„Çø„Ç§„ÉóÂàÜÂ∏É\n",
      "sequence_type  frequency  percentage  sequences  participants\n",
      "       Target     344058       59.84       5113            81\n",
      "   Non-Target     230887       40.16       3038            81\n",
      "\n",
      "‚è≥ Ë°åÂãïÁ∂ôÁ∂öÊÄßÂàÜÊûê\n",
      "                                 behavior  num_runs  avg_run_length  min_run_length  max_run_length  avg_run_seconds\n",
      "            Moves hand to target location      4102            38.1               2             653             0.76\n",
      "                         Performs gesture      8150            31.4               3              71             0.63\n",
      "Relaxes and moves hand to target location      4049            16.7               3              98             0.33\n",
      "                  Hand at target location      8151            11.7               1             108             0.23\n",
      "\n",
      "üìà ÈáçË¶Å„Å™Áü•Ë¶ã:\n",
      "  ‚Ä¢ ÊúÄÈ†ªÂá∫„Ç∏„Çß„Çπ„ÉÅ„É£„Éº: Text on phone (10.17%)\n",
      "  ‚Ä¢ ÊúÄÁ®ÄÂ∞ë„Ç∏„Çß„Çπ„ÉÅ„É£„Éº: Pinch knee/leg skin (1.71%)\n",
      "  ‚Ä¢ Âπ≥Âùá„Ç∑„Éº„Ç±„É≥„ÇπÈï∑: 1.41Áßí\n",
      "  ‚Ä¢ Target/Non-TargetÊØî: 59.84% vs 40.16%\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Ë°åÂãï„É©„Éô„É´„ÅÆÂá∫ÁèæÈ†ªÂ∫¶„Å®Èï∑„ÅïÂàÜÂ∏ÉÂàÜÊûê\n",
    "print(\"üé≠ Ë°åÂãï„É©„Éô„É´Âá∫ÁèæÈ†ªÂ∫¶„ÉªÈï∑„ÅïÂàÜÂ∏ÉÂàÜÊûê\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. „Ç∏„Çß„Çπ„ÉÅ„É£„Éº„É©„Éô„É´„ÅÆÂá∫ÁèæÈ†ªÂ∫¶\n",
    "print(\"üéØ „Ç∏„Çß„Çπ„ÉÅ„É£„Éº„É©„Éô„É´Âá∫ÁèæÈ†ªÂ∫¶ (18„ÇØ„É©„Çπ)\")\n",
    "gesture_frequency = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        gesture,\n",
    "        COUNT(*) as frequency,\n",
    "        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train), 2) as percentage,\n",
    "        COUNT(DISTINCT sequence_id) as sequences,\n",
    "        COUNT(DISTINCT subject) as participants\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY gesture\n",
    "    ORDER BY frequency DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(gesture_frequency.to_string(index=False))\n",
    "\n",
    "# ‰∏çÂùáË°°Â∫¶„ÅÆË®àÁÆó\n",
    "max_freq = gesture_frequency['frequency'].max()\n",
    "min_freq = gesture_frequency['frequency'].min()\n",
    "imbalance_ratio = max_freq / min_freq\n",
    "print(f\"\\nüìä „ÇØ„É©„Çπ‰∏çÂùáË°°Â∫¶: {imbalance_ratio:.1f}:1 ({'È´ò' if imbalance_ratio > 10 else '‰∏≠' if imbalance_ratio > 3 else '‰Ωé'})\")\n",
    "\n",
    "# 2. Ë°åÂãïÔºàbehaviorÔºâ„Éï„Çß„Éº„Ç∫„ÅÆÂàÜÂ∏É\n",
    "print(\"\\nüîÑ Ë°åÂãï„Éï„Çß„Éº„Ç∫ÂàÜÂ∏É\")\n",
    "behavior_distribution = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        behavior,\n",
    "        COUNT(*) as frequency,\n",
    "        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train), 2) as percentage,\n",
    "        COUNT(DISTINCT sequence_id) as sequences\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY behavior\n",
    "    ORDER BY frequency DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(behavior_distribution.to_string(index=False))\n",
    "\n",
    "# 3. „Ç∑„Éº„Ç±„É≥„ÇπÈï∑„ÅÆÂàÜÂ∏ÉÂàÜÊûê\n",
    "print(\"\\nüìè „Ç∑„Éº„Ç±„É≥„ÇπÈï∑ÂàÜÂ∏ÉÂàÜÊûê\")\n",
    "sequence_lengths = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        sequence_id,\n",
    "        gesture,\n",
    "        COUNT(*) as length_timesteps,\n",
    "        ROUND(COUNT(*) / 50.0, 2) as length_seconds\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY sequence_id, gesture\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "length_stats = sequence_lengths['length_timesteps'].describe()\n",
    "print(f\"„Ç∑„Éº„Ç±„É≥„ÇπÈï∑Áµ±Ë®à („Çø„Ç§„É†„Çπ„ÉÜ„ÉÉ„Éó):\")\n",
    "print(f\"  Âπ≥Âùá: {length_stats['mean']:.1f}\")\n",
    "print(f\"  ‰∏≠Â§ÆÂÄ§: {length_stats['50%']:.1f}\")\n",
    "print(f\"  Ê®ôÊ∫ñÂÅèÂ∑Æ: {length_stats['std']:.1f}\")\n",
    "print(f\"  ÊúÄÂ∞è-ÊúÄÂ§ß: {length_stats['min']:.0f} - {length_stats['max']:.0f}\")\n",
    "print(f\"  Q1-Q3: {length_stats['25%']:.1f} - {length_stats['75%']:.1f}\")\n",
    "\n",
    "print(f\"\\n„Ç∑„Éº„Ç±„É≥„ÇπÈï∑Áµ±Ë®à (Áßí):\")\n",
    "print(f\"  Âπ≥Âùá: {length_stats['mean']/50:.2f}Áßí\")\n",
    "print(f\"  ‰∏≠Â§ÆÂÄ§: {length_stats['50%']/50:.2f}Áßí\")\n",
    "print(f\"  ÊúÄÈï∑: {length_stats['max']/50:.1f}Áßí\")\n",
    "\n",
    "# 4. „Ç∏„Çß„Çπ„ÉÅ„É£„ÉºÂà•„ÅÆ„Ç∑„Éº„Ç±„É≥„ÇπÈï∑ÂàÜÊûê\n",
    "print(\"\\nüé≠ „Ç∏„Çß„Çπ„ÉÅ„É£„ÉºÂà•„Ç∑„Éº„Ç±„É≥„ÇπÈï∑\")\n",
    "gesture_length_stats = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        gesture,\n",
    "        COUNT(DISTINCT sequence_id) as num_sequences,\n",
    "        ROUND(AVG(length), 1) as avg_length_timesteps,\n",
    "        ROUND(AVG(length) / 50.0, 2) as avg_length_seconds,\n",
    "        MIN(length) as min_length,\n",
    "        MAX(length) as max_length,\n",
    "        ROUND(STDDEV(length), 1) as std_length\n",
    "    FROM (\n",
    "        SELECT \n",
    "            sequence_id,\n",
    "            gesture,\n",
    "            COUNT(*) as length\n",
    "        FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "        GROUP BY sequence_id, gesture\n",
    "    )\n",
    "    GROUP BY gesture\n",
    "    ORDER BY avg_length_timesteps DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(gesture_length_stats.to_string(index=False))\n",
    "\n",
    "# 5. sequence_typeÔºàTarget vs Non-TargetÔºâÂàÜÂ∏É\n",
    "print(\"\\nüéØ „Ç∑„Éº„Ç±„É≥„Çπ„Çø„Ç§„ÉóÂàÜÂ∏É\")\n",
    "sequence_type_dist = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        sequence_type,\n",
    "        COUNT(*) as frequency,\n",
    "        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train), 2) as percentage,\n",
    "        COUNT(DISTINCT sequence_id) as sequences,\n",
    "        COUNT(DISTINCT subject) as participants\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY sequence_type\n",
    "    ORDER BY frequency DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(sequence_type_dist.to_string(index=False))\n",
    "\n",
    "# 6. Ë°åÂãïÁ∂ôÁ∂öÊÄßÂàÜÊûêÔºàÂêå‰∏ÄË°åÂãï„ÅÆÈÄ£Á∂öÈï∑Ôºâ\n",
    "print(\"\\n‚è≥ Ë°åÂãïÁ∂ôÁ∂öÊÄßÂàÜÊûê\")\n",
    "behavior_continuity = conn.execute(\"\"\"\n",
    "    WITH behavior_runs AS (\n",
    "        SELECT \n",
    "            sequence_id,\n",
    "            behavior,\n",
    "            COUNT(*) as run_length\n",
    "        FROM (\n",
    "            SELECT \n",
    "                sequence_id,\n",
    "                behavior,\n",
    "                ROW_NUMBER() OVER (PARTITION BY sequence_id ORDER BY sequence_counter) - \n",
    "                ROW_NUMBER() OVER (PARTITION BY sequence_id, behavior ORDER BY sequence_counter) as grp\n",
    "            FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "        )\n",
    "        GROUP BY sequence_id, behavior, grp\n",
    "    )\n",
    "    SELECT \n",
    "        behavior,\n",
    "        COUNT(*) as num_runs,\n",
    "        ROUND(AVG(run_length), 1) as avg_run_length,\n",
    "        MIN(run_length) as min_run_length,\n",
    "        MAX(run_length) as max_run_length,\n",
    "        ROUND(AVG(run_length) / 50.0, 2) as avg_run_seconds\n",
    "    FROM behavior_runs\n",
    "    GROUP BY behavior\n",
    "    ORDER BY avg_run_length DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(behavior_continuity.to_string(index=False))\n",
    "\n",
    "print(\"\\nüìà ÈáçË¶Å„Å™Áü•Ë¶ã:\")\n",
    "print(f\"  ‚Ä¢ ÊúÄÈ†ªÂá∫„Ç∏„Çß„Çπ„ÉÅ„É£„Éº: {gesture_frequency.iloc[0]['gesture']} ({gesture_frequency.iloc[0]['percentage']}%)\")\n",
    "print(f\"  ‚Ä¢ ÊúÄÁ®ÄÂ∞ë„Ç∏„Çß„Çπ„ÉÅ„É£„Éº: {gesture_frequency.iloc[-1]['gesture']} ({gesture_frequency.iloc[-1]['percentage']}%)\")\n",
    "print(f\"  ‚Ä¢ Âπ≥Âùá„Ç∑„Éº„Ç±„É≥„ÇπÈï∑: {length_stats['mean']/50:.2f}Áßí\")\n",
    "print(f\"  ‚Ä¢ Target/Non-TargetÊØî: {sequence_type_dist.iloc[0]['percentage']}% vs {sequence_type_dist.iloc[1]['percentage']}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "xqdwrrum7o",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• ÂèÇÂä†ËÄÖ„Éª„Çª„ÉÉ„Ç∑„Éß„É≥Âçò‰Ωç„Éá„Éº„Çø„É™„Éº„ÇØÁ¢∫Ë™ç\n",
      "============================================================\n",
      "üîç Ë®ìÁ∑¥„Éª„ÉÜ„Çπ„Éà„Çª„ÉÉ„ÉàÈñìÂèÇÂä†ËÄÖÈáçË§áÁ¢∫Ë™ç\n",
      "                 dataset  participant_count\n",
      "      Train participants                 81\n",
      "       Test participants                  2\n",
      "Overlapping participants                  0\n",
      "\n",
      "üìä ÂèÇÂä†ËÄÖÂà•„Éá„Éº„ÇøÂàÜÂ∏ÉÔºàCVË®≠Ë®àÂèÇËÄÉÔºâ\n",
      "ÂèÇÂä†ËÄÖÂà•„Éá„Éº„ÇøÈáèÔºà‰∏ä‰Ωç10ÂêçÔºâ:\n",
      "    subject  sequences  total_timesteps  unique_gestures  data_percentage  target_pct\n",
      "SUBJ_040733        102            10848               18             1.89        60.1\n",
      "SUBJ_052342        102            10393               18             1.81        59.2\n",
      "SUBJ_023739        102             9154               18             1.59        60.9\n",
      "SUBJ_059520        102             8947               18             1.56        59.0\n",
      "SUBJ_058967        102             8718               18             1.52        60.8\n",
      "SUBJ_030676        102             8700               18             1.51        59.7\n",
      "SUBJ_032761        102             8420               18             1.46        59.3\n",
      "SUBJ_061552        102             8412               18             1.46        61.6\n",
      "SUBJ_017807        102             8409               18             1.46        58.8\n",
      "SUBJ_032704        102             8322               18             1.45        59.5\n",
      "\n",
      "üìà ÂèÇÂä†ËÄÖ„Éá„Éº„ÇøÂàÜÂ∏ÉÁµ±Ë®à\n",
      "ÂèÇÂä†ËÄÖÁµ±Ë®à:\n",
      "  Á∑èÂèÇÂä†ËÄÖÊï∞: 81\n",
      "  „Éá„Éº„ÇøÈáè: Âπ≥Âùá7098.1¬±1033.7 timesteps\n",
      "  „Éá„Éº„ÇøÈáèÁØÑÂõ≤: 4008 - 10848 timesteps\n",
      "  „Éá„Éº„Çø‰∏çÂùáË°°ÊØî: 2.7:1\n",
      "  Âπ≥Âùá„Ç∑„Éº„Ç±„É≥„ÇπÊï∞: 100.6\n",
      "  Âπ≥Âùá„Ç∏„Çß„Çπ„ÉÅ„É£„ÉºÁ®ÆÈ°û: 18.0\n",
      "\n",
      "üé≠ „Ç∏„Çß„Çπ„ÉÅ„É£„Éº√óÂèÇÂä†ËÄÖ„Ç´„Éê„É¨„ÉÉ„Ç∏\n",
      "„Ç∏„Çß„Çπ„ÉÅ„É£„ÉºÂà•ÂèÇÂä†ËÄÖ„Ç´„Éê„É¨„ÉÉ„Ç∏:\n",
      "                                   gesture  participants_with_gesture  coverage_percentage\n",
      "                       Eyelash - pull hair                         81                100.0\n",
      "                     Above ear - pull hair                         81                100.0\n",
      "                     Scratch knee/leg skin                         81                100.0\n",
      "Feel around in tray and pull out an object                         81                100.0\n",
      "                         Write name in air                         81                100.0\n",
      "                         Neck - pinch skin                         81                100.0\n",
      "                                Wave hello                         81                100.0\n",
      "                            Neck - scratch                         81                100.0\n",
      "                  Forehead - pull hairline                         81                100.0\n",
      "                     Drink from bottle/cup                         81                100.0\n",
      "                       Eyebrow - pull hair                         81                100.0\n",
      "                        Forehead - scratch                         81                100.0\n",
      "                        Cheek - pinch skin                         81                100.0\n",
      "                         Write name on leg                         81                100.0\n",
      "                 Pull air toward your face                         81                100.0\n",
      "                            Glasses on/off                         81                100.0\n",
      "                             Text on phone                         81                100.0\n",
      "                       Pinch knee/leg skin                         81                100.0\n",
      "\n",
      "üîÑ CV„Éï„Ç©„Éº„É´„ÉâË®≠Ë®àÊé®Â•®\n",
      "GroupKFoldÊé®Â•®Ë®≠ÂÆö:\n",
      "  ‚Ä¢ „Éï„Ç©„Éº„É´„ÉâÊï∞: 5\n",
      "  ‚Ä¢ ÂèÇÂä†ËÄÖ/„Éï„Ç©„Éº„É´„Éâ: ~16‰∫∫\n",
      "  ‚Ä¢ „Éá„Éº„Çø/„Éï„Ç©„Éº„É´„Éâ: ~20%\n",
      "  ‚Ä¢ „Ç∞„É´„Éº„ÉóÂ§âÊï∞: subject (ÂèÇÂä†ËÄÖID)\n",
      "\n",
      "‚úÖ „Éá„Éº„Çø„É™„Éº„ÇØÁ¢∫Ë™çÁµêÊûú\n",
      "  üü¢ ÂèÇÂä†ËÄÖÈáçË§á„Å™„Åó - „Éá„Éº„Çø„É™„Éº„ÇØ„É™„Çπ„ÇØ„Å™„Åó\n",
      "  üü¢ GroupKFold„ÅßCVÂÆüË£ÖÂèØËÉΩ\n",
      "  ÂèÇÂä†ËÄÖ„Éá„Éº„ÇøÂùáË°°ÊÄß: üü¢ ËâØÂ•Ω\n",
      "  „Ç∏„Çß„Çπ„ÉÅ„É£„Éº„Ç´„Éê„É¨„ÉÉ„Ç∏: üü¢ ËâØÂ•Ω (ÊúÄÂ∞è100.0%)\n",
      "\n",
      "üìù CVÊà¶Áï•Êé®Â•®:\n",
      "```python\n",
      "from sklearn.model_selection import GroupKFold\n",
      "cv = GroupKFold(n_splits=5)\n",
      "groups = train_data['subject']\n",
      "```\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ÂèÇÂä†ËÄÖ/„Çª„ÉÉ„Ç∑„Éß„É≥Âçò‰Ωç„ÅÆ„Éá„Éº„Çø„É™„Éº„ÇØÁ¢∫Ë™ç\n",
    "print(\"üë• ÂèÇÂä†ËÄÖ„Éª„Çª„ÉÉ„Ç∑„Éß„É≥Âçò‰Ωç„Éá„Éº„Çø„É™„Éº„ÇØÁ¢∫Ë™ç\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Ë®ìÁ∑¥„Éª„ÉÜ„Çπ„Éà„Çª„ÉÉ„ÉàÈñì„ÅÆÂèÇÂä†ËÄÖÈáçË§áÁ¢∫Ë™ç\n",
    "print(\"üîç Ë®ìÁ∑¥„Éª„ÉÜ„Çπ„Éà„Çª„ÉÉ„ÉàÈñìÂèÇÂä†ËÄÖÈáçË§áÁ¢∫Ë™ç\")\n",
    "participant_overlap = conn.execute(\"\"\"\n",
    "    WITH train_subjects AS (\n",
    "        SELECT DISTINCT subject FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    ),\n",
    "    test_subjects AS (\n",
    "        SELECT DISTINCT subject FROM \"cmi_detect_behavior_with_sensor_data\".test\n",
    "    )\n",
    "    SELECT \n",
    "        'Train participants' as dataset,\n",
    "        COUNT(*) as participant_count\n",
    "    FROM train_subjects\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'Test participants',\n",
    "        COUNT(*)\n",
    "    FROM test_subjects\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'Overlapping participants',\n",
    "        COUNT(*)\n",
    "    FROM train_subjects t1\n",
    "    INNER JOIN test_subjects t2 ON t1.subject = t2.subject\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(participant_overlap.to_string(index=False))\n",
    "\n",
    "# 2. ÂèÇÂä†ËÄÖÂà•„Éá„Éº„ÇøÂàÜÂ∏ÉÔºàCVË®≠Ë®àÁî®Ôºâ\n",
    "print(\"\\nüìä ÂèÇÂä†ËÄÖÂà•„Éá„Éº„ÇøÂàÜÂ∏ÉÔºàCVË®≠Ë®àÂèÇËÄÉÔºâ\")\n",
    "participant_data_dist = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        subject,\n",
    "        COUNT(DISTINCT sequence_id) as sequences,\n",
    "        COUNT(*) as total_timesteps,\n",
    "        COUNT(DISTINCT gesture) as unique_gestures,\n",
    "        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train), 2) as data_percentage,\n",
    "        ROUND(AVG(CASE WHEN sequence_type = 'Target' THEN 1.0 ELSE 0.0 END) * 100, 1) as target_pct\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY subject\n",
    "    ORDER BY total_timesteps DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"ÂèÇÂä†ËÄÖÂà•„Éá„Éº„ÇøÈáèÔºà‰∏ä‰Ωç10ÂêçÔºâ:\")\n",
    "print(participant_data_dist.to_string(index=False))\n",
    "\n",
    "# 3. ÂèÇÂä†ËÄÖ„Éá„Éº„ÇøÂàÜÂ∏É„ÅÆÁµ±Ë®à\n",
    "print(\"\\nüìà ÂèÇÂä†ËÄÖ„Éá„Éº„ÇøÂàÜÂ∏ÉÁµ±Ë®à\")\n",
    "participant_stats = conn.execute(\"\"\"\n",
    "    WITH participant_summary AS (\n",
    "        SELECT \n",
    "            subject,\n",
    "            COUNT(DISTINCT sequence_id) as sequences,\n",
    "            COUNT(*) as timesteps,\n",
    "            COUNT(DISTINCT gesture) as gestures\n",
    "        FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "        GROUP BY subject\n",
    "    )\n",
    "    SELECT \n",
    "        COUNT(*) as total_participants,\n",
    "        ROUND(AVG(timesteps), 1) as avg_timesteps,\n",
    "        ROUND(STDDEV(timesteps), 1) as std_timesteps,\n",
    "        MIN(timesteps) as min_timesteps,\n",
    "        MAX(timesteps) as max_timesteps,\n",
    "        ROUND(MAX(timesteps) * 1.0 / MIN(timesteps), 1) as imbalance_ratio,\n",
    "        ROUND(AVG(sequences), 1) as avg_sequences,\n",
    "        ROUND(AVG(gestures), 1) as avg_gestures\n",
    "    FROM participant_summary\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"ÂèÇÂä†ËÄÖÁµ±Ë®à:\")\n",
    "print(f\"  Á∑èÂèÇÂä†ËÄÖÊï∞: {participant_stats[0]}\")\n",
    "print(f\"  „Éá„Éº„ÇøÈáè: Âπ≥Âùá{participant_stats[1]}¬±{participant_stats[2]} timesteps\")\n",
    "print(f\"  „Éá„Éº„ÇøÈáèÁØÑÂõ≤: {participant_stats[3]} - {participant_stats[4]} timesteps\")\n",
    "print(f\"  „Éá„Éº„Çø‰∏çÂùáË°°ÊØî: {participant_stats[5]}:1\")\n",
    "print(f\"  Âπ≥Âùá„Ç∑„Éº„Ç±„É≥„ÇπÊï∞: {participant_stats[6]}\")\n",
    "print(f\"  Âπ≥Âùá„Ç∏„Çß„Çπ„ÉÅ„É£„ÉºÁ®ÆÈ°û: {participant_stats[7]}\")\n",
    "\n",
    "# 4. „Ç∏„Çß„Çπ„ÉÅ„É£„Éº√óÂèÇÂä†ËÄÖ„ÅÆ„Ç´„Éê„É¨„ÉÉ„Ç∏\n",
    "print(\"\\nüé≠ „Ç∏„Çß„Çπ„ÉÅ„É£„Éº√óÂèÇÂä†ËÄÖ„Ç´„Éê„É¨„ÉÉ„Ç∏\")\n",
    "gesture_coverage = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        gesture,\n",
    "        COUNT(DISTINCT subject) as participants_with_gesture,\n",
    "        ROUND(COUNT(DISTINCT subject) * 100.0 / 81, 1) as coverage_percentage\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY gesture\n",
    "    ORDER BY participants_with_gesture DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"„Ç∏„Çß„Çπ„ÉÅ„É£„ÉºÂà•ÂèÇÂä†ËÄÖ„Ç´„Éê„É¨„ÉÉ„Ç∏:\")\n",
    "print(gesture_coverage.to_string(index=False))\n",
    "\n",
    "# 5. CV„Éï„Ç©„Éº„É´„ÉâË®≠Ë®à„ÅÆÊé®Â•®\n",
    "print(\"\\nüîÑ CV„Éï„Ç©„Éº„É´„ÉâË®≠Ë®àÊé®Â•®\")\n",
    "print(\"GroupKFoldÊé®Â•®Ë®≠ÂÆö:\")\n",
    "participants_per_fold = participant_stats[0] / 5\n",
    "data_per_fold = 100 / 5\n",
    "print(f\"  ‚Ä¢ „Éï„Ç©„Éº„É´„ÉâÊï∞: 5\")\n",
    "print(f\"  ‚Ä¢ ÂèÇÂä†ËÄÖ/„Éï„Ç©„Éº„É´„Éâ: ~{participants_per_fold:.0f}‰∫∫\")\n",
    "print(f\"  ‚Ä¢ „Éá„Éº„Çø/„Éï„Ç©„Éº„É´„Éâ: ~{data_per_fold:.0f}%\")\n",
    "print(f\"  ‚Ä¢ „Ç∞„É´„Éº„ÉóÂ§âÊï∞: subject (ÂèÇÂä†ËÄÖID)\")\n",
    "\n",
    "# 6. „Éá„Éº„Çø„É™„Éº„ÇØÁ¢∫Ë™çÁµêÊûú\n",
    "print(\"\\n‚úÖ „Éá„Éº„Çø„É™„Éº„ÇØÁ¢∫Ë™çÁµêÊûú\")\n",
    "overlap_count = participant_overlap[participant_overlap['dataset'] == 'Overlapping participants']['participant_count'].iloc[0]\n",
    "\n",
    "if overlap_count == 0:\n",
    "    print(\"  üü¢ ÂèÇÂä†ËÄÖÈáçË§á„Å™„Åó - „Éá„Éº„Çø„É™„Éº„ÇØ„É™„Çπ„ÇØ„Å™„Åó\")\n",
    "    print(\"  üü¢ GroupKFold„ÅßCVÂÆüË£ÖÂèØËÉΩ\")\n",
    "else:\n",
    "    print(f\"  üî¥ ÂèÇÂä†ËÄÖÈáçË§á„ÅÇ„Çä: {overlap_count}‰∫∫\")\n",
    "    print(\"  üî¥ „Éá„Éº„Çø„É™„Éº„ÇØ„É™„Çπ„ÇØ - Ë¶ÅÂØæÁ≠ñ\")\n",
    "\n",
    "# „Éá„Éº„ÇøÂùáË°°ÊÄß„ÅÆË©ï‰æ°\n",
    "if participant_stats[5] < 5:\n",
    "    balance_status = \"üü¢ ËâØÂ•Ω\"\n",
    "elif participant_stats[5] < 10:\n",
    "    balance_status = \"üü° ‰∏≠Á®ãÂ∫¶\"\n",
    "else:\n",
    "    balance_status = \"üî¥ ‰∏çÂùáË°°\"\n",
    "\n",
    "print(f\"  ÂèÇÂä†ËÄÖ„Éá„Éº„ÇøÂùáË°°ÊÄß: {balance_status}\")\n",
    "\n",
    "# „Ç∏„Çß„Çπ„ÉÅ„É£„Éº„Ç´„Éê„É¨„ÉÉ„Ç∏„ÅÆË©ï‰æ°\n",
    "min_coverage = gesture_coverage['coverage_percentage'].min()\n",
    "if min_coverage > 80:\n",
    "    coverage_status = \"üü¢ ËâØÂ•Ω\"\n",
    "elif min_coverage > 60:\n",
    "    coverage_status = \"üü° ‰∏≠Á®ãÂ∫¶\"\n",
    "else:\n",
    "    coverage_status = \"üî¥ ‰∏çÂçÅÂàÜ\"\n",
    "\n",
    "print(f\"  „Ç∏„Çß„Çπ„ÉÅ„É£„Éº„Ç´„Éê„É¨„ÉÉ„Ç∏: {coverage_status} (ÊúÄÂ∞è{min_coverage}%)\")\n",
    "\n",
    "print(\"\\nüìù CVÊà¶Áï•Êé®Â•®:\")\n",
    "print(\"```python\")\n",
    "print(\"from sklearn.model_selection import GroupKFold\")\n",
    "print(\"cv = GroupKFold(n_splits=5)\")\n",
    "print(\"groups = train_data['subject']\")\n",
    "print(\"```\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ri4lh023h7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß 10. FEATURE ENGINEERING RECOMMENDATIONS\n",
      "============================================================\n",
      "üìä Based on the comprehensive EDA analysis, here are the recommended feature engineering strategies:\n",
      "\n",
      "üéØ 1. IMU FEATURE ENGINEERING\n",
      "========================================\n",
      "‚úÖ Magnitude Features:\n",
      "  ‚Ä¢ acc_magnitude = sqrt(acc_x¬≤ + acc_y¬≤ + acc_z¬≤)\n",
      "  ‚Ä¢ rot_magnitude = sqrt(rot_x¬≤ + rot_y¬≤ + rot_z¬≤)\n",
      "  ‚Ä¢ Remove gravity component: acc_no_gravity = acc - [0, 0, 9.81]\n",
      "\n",
      "‚úÖ Temporal Features:\n",
      "  ‚Ä¢ Velocity: diff(acc_x), diff(acc_y), diff(acc_z)\n",
      "  ‚Ä¢ Jerk: diff(diff(acc_x)) - 2nd derivative\n",
      "  ‚Ä¢ Rolling statistics: mean, std, min, max over windows (5, 10, 20 timesteps)\n",
      "\n",
      "‚úÖ Frequency Domain:\n",
      "  ‚Ä¢ FFT features: spectral energy, dominant frequency, spectral centroid\n",
      "  ‚Ä¢ Frequency band powers: 0-2Hz, 2-5Hz, 5-10Hz, 10-25Hz\n",
      "  ‚Ä¢ Spectral entropy and spectral rolloff\n",
      "\n",
      "üå°Ô∏è 2. THERMOPILE FEATURE ENGINEERING\n",
      "========================================\n",
      "‚úÖ Spatial Features:\n",
      "  ‚Ä¢ Temperature gradients: thm_1 - thm_3, thm_2 - thm_4\n",
      "  ‚Ä¢ Temperature range: max(thm_1..4) - min(thm_1..4)\n",
      "  ‚Ä¢ Centroid calculation: weighted average position\n",
      "\n",
      "‚úÖ Handle Missing thm_5:\n",
      "  ‚Ä¢ Create binary indicator: thm_5_available\n",
      "  ‚Ä¢ Fill with median of thm_1..4 when missing\n",
      "  ‚Ä¢ Separate model branch for thm_5 vs thm_1..4\n",
      "\n",
      "üì° 3. TOF FEATURE ENGINEERING\n",
      "========================================\n",
      "‚úÖ Dimensionality Reduction:\n",
      "  ‚Ä¢ PCA on 64 channels ‚Üí 8-16 components per ToF sensor\n",
      "  ‚Ä¢ Statistical summaries: mean, std, min, max, median per sensor\n",
      "  ‚Ä¢ Distance gradients: edge detection on 8x8 ToF array\n",
      "\n",
      "‚úÖ Proximity Features:\n",
      "  ‚Ä¢ Minimum distance per sensor: min(tof_N_v0..63)\n",
      "  ‚Ä¢ Distance variance: std(tof_N_v0..63)\n",
      "  ‚Ä¢ Hand-to-face proximity: tof_1 vs tof_3 comparison\n",
      "\n",
      "‚úÖ Handle Missing tof_5:\n",
      "  ‚Ä¢ Binary indicator: tof_5_available\n",
      "  ‚Ä¢ Zero-fill or interpolate from tof_1..4 spatial patterns\n",
      "\n",
      "üîÑ 4. MULTIMODAL FUSION FEATURES\n",
      "========================================\n",
      "‚úÖ Cross-Modal Correlations:\n",
      "  ‚Ä¢ IMU-Temperature sync: correlation(acc_magnitude, thm_mean)\n",
      "  ‚Ä¢ Motion-Proximity sync: correlation(acc_jerk, tof_min_distance)\n",
      "  ‚Ä¢ Activity level: high_motion √ó high_temperature\n",
      "\n",
      "‚úÖ Temporal Alignment:\n",
      "  ‚Ä¢ Lag features: temperature[t-1], tof[t-1] vs acc[t]\n",
      "  ‚Ä¢ Lead features: predict next timestep behavior\n",
      "  ‚Ä¢ Sliding window features: past 5-10 timesteps context\n",
      "\n",
      "‚è±Ô∏è 5. TIME SERIES SPECIFIC FEATURES\n",
      "========================================\n",
      "‚úÖ Sequence-Level Features:\n",
      "  ‚Ä¢ Sequence statistics: length, start/end values, trend\n",
      "  ‚Ä¢ Phase transitions: count of behavior changes per sequence\n",
      "  ‚Ä¢ Gesture duration: timesteps in 'Performs gesture' phase\n",
      "\n",
      "‚úÖ Temporal Context:\n",
      "  ‚Ä¢ Position in sequence: timestep / sequence_length\n",
      "  ‚Ä¢ Time since behavior change\n",
      "  ‚Ä¢ Behavior transition indicators\n",
      "\n",
      "üé≠ 6. GESTURE-SPECIFIC FEATURES\n",
      "========================================\n",
      "‚úÖ BFRB-Relevant Features:\n",
      "  ‚Ä¢ Repetitive motion detection: autocorrelation, periodicity\n",
      "  ‚Ä¢ Hand-to-face distance (ToF sensors)\n",
      "  ‚Ä¢ Fidgeting indicators: high-frequency low-amplitude motion\n",
      "  ‚Ä¢ Touch detection: temperature spikes + proximity changes\n",
      "\n",
      "üë• 7. PARTICIPANT-AWARE FEATURES\n",
      "========================================\n",
      "‚úÖ Normalization by Demographics:\n",
      "  ‚Ä¢ Height-normalized features: distances / height\n",
      "  ‚Ä¢ Age-adjusted motion thresholds\n",
      "  ‚Ä¢ Handedness-aware spatial features\n",
      "\n",
      "‚úÖ Subject-Specific Calibration:\n",
      "  ‚Ä¢ Z-score normalization per participant\n",
      "  ‚Ä¢ Baseline subtraction: first N timesteps as reference\n",
      "  ‚Ä¢ Participant-specific gesture templates\n",
      "\n",
      "üèóÔ∏è 8. IMPLEMENTATION PRIORITY\n",
      "========================================\n",
      "Priority 1 (Essential):\n",
      "  1. IMU magnitude + derivatives (velocity, jerk)\n",
      "  2. Rolling window statistics (mean, std over 5-20 timesteps)\n",
      "  3. Missing value indicators + imputation\n",
      "  4. GroupKFold cross-validation setup\n",
      "\n",
      "Priority 2 (High Impact):\n",
      "  5. ToF PCA + statistical summaries\n",
      "  6. Thermopile spatial gradients\n",
      "  7. Sequence-level contextual features\n",
      "  8. FFT spectral features\n",
      "\n",
      "Priority 3 (Optimization):\n",
      "  9. Cross-modal correlation features\n",
      "  10. Participant-specific normalization\n",
      "  11. Advanced temporal patterns\n",
      "  12. Gesture-specific domain features\n",
      "\n",
      "üéØ Expected Impact on Competition Metrics:\n",
      "  ‚Ä¢ Binary F1: Should improve from current ~0.60 to 0.65-0.70\n",
      "  ‚Ä¢ Macro F1: Harder due to class imbalance, expect 0.55-0.65\n",
      "  ‚Ä¢ Combined Score: Target 0.60-0.68 (bronze medal territory)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 10. üîß ÁâπÂæ¥Â∑•Â≠¶Êé®Â•®‰∫ãÈ†Ö\n",
    "print(\"üîß 10. FEATURE ENGINEERING RECOMMENDATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"üìä Based on the comprehensive EDA analysis, here are the recommended feature engineering strategies:\")\n",
    "\n",
    "print(\"\\nüéØ 1. IMU FEATURE ENGINEERING\")\n",
    "print(\"=\" * 40)\n",
    "print(\"‚úÖ Magnitude Features:\")\n",
    "print(\"  ‚Ä¢ acc_magnitude = sqrt(acc_x¬≤ + acc_y¬≤ + acc_z¬≤)\")\n",
    "print(\"  ‚Ä¢ rot_magnitude = sqrt(rot_x¬≤ + rot_y¬≤ + rot_z¬≤)\")\n",
    "print(\"  ‚Ä¢ Remove gravity component: acc_no_gravity = acc - [0, 0, 9.81]\")\n",
    "\n",
    "print(\"\\n‚úÖ Temporal Features:\")\n",
    "print(\"  ‚Ä¢ Velocity: diff(acc_x), diff(acc_y), diff(acc_z)\")\n",
    "print(\"  ‚Ä¢ Jerk: diff(diff(acc_x)) - 2nd derivative\")\n",
    "print(\"  ‚Ä¢ Rolling statistics: mean, std, min, max over windows (5, 10, 20 timesteps)\")\n",
    "\n",
    "print(\"\\n‚úÖ Frequency Domain:\")\n",
    "print(\"  ‚Ä¢ FFT features: spectral energy, dominant frequency, spectral centroid\")\n",
    "print(\"  ‚Ä¢ Frequency band powers: 0-2Hz, 2-5Hz, 5-10Hz, 10-25Hz\")\n",
    "print(\"  ‚Ä¢ Spectral entropy and spectral rolloff\")\n",
    "\n",
    "print(\"\\nüå°Ô∏è 2. THERMOPILE FEATURE ENGINEERING\") \n",
    "print(\"=\" * 40)\n",
    "print(\"‚úÖ Spatial Features:\")\n",
    "print(\"  ‚Ä¢ Temperature gradients: thm_1 - thm_3, thm_2 - thm_4\")\n",
    "print(\"  ‚Ä¢ Temperature range: max(thm_1..4) - min(thm_1..4)\")\n",
    "print(\"  ‚Ä¢ Centroid calculation: weighted average position\")\n",
    "\n",
    "print(\"\\n‚úÖ Handle Missing thm_5:\")\n",
    "print(\"  ‚Ä¢ Create binary indicator: thm_5_available\")\n",
    "print(\"  ‚Ä¢ Fill with median of thm_1..4 when missing\")\n",
    "print(\"  ‚Ä¢ Separate model branch for thm_5 vs thm_1..4\")\n",
    "\n",
    "print(\"\\nüì° 3. TOF FEATURE ENGINEERING\")\n",
    "print(\"=\" * 40)\n",
    "print(\"‚úÖ Dimensionality Reduction:\")\n",
    "print(\"  ‚Ä¢ PCA on 64 channels ‚Üí 8-16 components per ToF sensor\")\n",
    "print(\"  ‚Ä¢ Statistical summaries: mean, std, min, max, median per sensor\")\n",
    "print(\"  ‚Ä¢ Distance gradients: edge detection on 8x8 ToF array\")\n",
    "\n",
    "print(\"\\n‚úÖ Proximity Features:\")\n",
    "print(\"  ‚Ä¢ Minimum distance per sensor: min(tof_N_v0..63)\")\n",
    "print(\"  ‚Ä¢ Distance variance: std(tof_N_v0..63)\")\n",
    "print(\"  ‚Ä¢ Hand-to-face proximity: tof_1 vs tof_3 comparison\")\n",
    "\n",
    "print(\"\\n‚úÖ Handle Missing tof_5:\")\n",
    "print(\"  ‚Ä¢ Binary indicator: tof_5_available\")\n",
    "print(\"  ‚Ä¢ Zero-fill or interpolate from tof_1..4 spatial patterns\")\n",
    "\n",
    "print(\"\\nüîÑ 4. MULTIMODAL FUSION FEATURES\")\n",
    "print(\"=\" * 40)\n",
    "print(\"‚úÖ Cross-Modal Correlations:\")\n",
    "print(\"  ‚Ä¢ IMU-Temperature sync: correlation(acc_magnitude, thm_mean)\")\n",
    "print(\"  ‚Ä¢ Motion-Proximity sync: correlation(acc_jerk, tof_min_distance)\")\n",
    "print(\"  ‚Ä¢ Activity level: high_motion √ó high_temperature\")\n",
    "\n",
    "print(\"\\n‚úÖ Temporal Alignment:\")\n",
    "print(\"  ‚Ä¢ Lag features: temperature[t-1], tof[t-1] vs acc[t]\")\n",
    "print(\"  ‚Ä¢ Lead features: predict next timestep behavior\")\n",
    "print(\"  ‚Ä¢ Sliding window features: past 5-10 timesteps context\")\n",
    "\n",
    "print(\"\\n‚è±Ô∏è 5. TIME SERIES SPECIFIC FEATURES\")\n",
    "print(\"=\" * 40)\n",
    "print(\"‚úÖ Sequence-Level Features:\")\n",
    "print(\"  ‚Ä¢ Sequence statistics: length, start/end values, trend\")\n",
    "print(\"  ‚Ä¢ Phase transitions: count of behavior changes per sequence\")\n",
    "print(\"  ‚Ä¢ Gesture duration: timesteps in 'Performs gesture' phase\")\n",
    "\n",
    "print(\"\\n‚úÖ Temporal Context:\")\n",
    "print(\"  ‚Ä¢ Position in sequence: timestep / sequence_length\")\n",
    "print(\"  ‚Ä¢ Time since behavior change\")\n",
    "print(\"  ‚Ä¢ Behavior transition indicators\")\n",
    "\n",
    "print(\"\\nüé≠ 6. GESTURE-SPECIFIC FEATURES\")\n",
    "print(\"=\" * 40)\n",
    "print(\"‚úÖ BFRB-Relevant Features:\")\n",
    "print(\"  ‚Ä¢ Repetitive motion detection: autocorrelation, periodicity\")\n",
    "print(\"  ‚Ä¢ Hand-to-face distance (ToF sensors)\")\n",
    "print(\"  ‚Ä¢ Fidgeting indicators: high-frequency low-amplitude motion\")\n",
    "print(\"  ‚Ä¢ Touch detection: temperature spikes + proximity changes\")\n",
    "\n",
    "print(\"\\nüë• 7. PARTICIPANT-AWARE FEATURES\")\n",
    "print(\"=\" * 40) \n",
    "print(\"‚úÖ Normalization by Demographics:\")\n",
    "print(\"  ‚Ä¢ Height-normalized features: distances / height\")\n",
    "print(\"  ‚Ä¢ Age-adjusted motion thresholds\")\n",
    "print(\"  ‚Ä¢ Handedness-aware spatial features\")\n",
    "\n",
    "print(\"\\n‚úÖ Subject-Specific Calibration:\")\n",
    "print(\"  ‚Ä¢ Z-score normalization per participant\")\n",
    "print(\"  ‚Ä¢ Baseline subtraction: first N timesteps as reference\")\n",
    "print(\"  ‚Ä¢ Participant-specific gesture templates\")\n",
    "\n",
    "print(\"\\nüèóÔ∏è 8. IMPLEMENTATION PRIORITY\")\n",
    "print(\"=\" * 40)\n",
    "print(\"Priority 1 (Essential):\")\n",
    "print(\"  1. IMU magnitude + derivatives (velocity, jerk)\")\n",
    "print(\"  2. Rolling window statistics (mean, std over 5-20 timesteps)\")\n",
    "print(\"  3. Missing value indicators + imputation\")\n",
    "print(\"  4. GroupKFold cross-validation setup\")\n",
    "\n",
    "print(\"\\nPriority 2 (High Impact):\")\n",
    "print(\"  5. ToF PCA + statistical summaries\")\n",
    "print(\"  6. Thermopile spatial gradients\")\n",
    "print(\"  7. Sequence-level contextual features\")\n",
    "print(\"  8. FFT spectral features\")\n",
    "\n",
    "print(\"\\nPriority 3 (Optimization):\")\n",
    "print(\"  9. Cross-modal correlation features\")\n",
    "print(\"  10. Participant-specific normalization\")\n",
    "print(\"  11. Advanced temporal patterns\")\n",
    "print(\"  12. Gesture-specific domain features\")\n",
    "\n",
    "print(\"\\nüéØ Expected Impact on Competition Metrics:\")\n",
    "print(\"  ‚Ä¢ Binary F1: Should improve from current ~0.60 to 0.65-0.70\")\n",
    "print(\"  ‚Ä¢ Macro F1: Harder due to class imbalance, expect 0.55-0.65\")\n",
    "print(\"  ‚Ä¢ Combined Score: Target 0.60-0.68 (bronze medal territory)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xzuecq022x",
   "metadata": {},
   "source": [
    "# üîç Ê∑±Êéò„ÇäEDAÊèêÊ°à - ËøΩÂä†2-3ÊôÇÈñì„ÅÆÊäïË≥á„Åß„Äå„Éè„Éû„Çä„Äç„Çí‰∫àÈò≤\n",
    "\n",
    "## üìä ÁèæÂú®„ÅÆEDAË©ï‰æ°: **‚≠ê‚≠ê‚≠ê‚≠ê (4/5)**\n",
    "\n",
    "ÁèæÂú®„ÅÆEDA„ÅØÈùûÂ∏∏„Å´ÂåÖÊã¨ÁöÑ„Åß„ÄÅ„Ç≥„É≥„ÉöÊà¶Áï•„ÇÇÈÅ©Âàá„Åß„Åô„ÄÇ„Åó„Åã„Åó„ÄÅ**„É¢„Éá„É´Ë®≠Ë®à„ÇÑÊú¨Áï™„É™„Çπ„ÇØ„ÇíËÄÉ„Åà„Çã„Å®„ÄÅ„ÅÇ„Å®2-3ÊôÇÈñì„ÅÆÊ∑±Êéò„Çä„ÅßÂæåÂ∑•Á®ã„ÅÆÂïèÈ°å„ÇíÂ§ßÂπÖ„Å´Ê∏õ„Çâ„Åõ„Åæ„Åô**„ÄÇ\n",
    "\n",
    "## üéØ ÂÑ™ÂÖàÂ∫¶Âà•ËøΩÂä†ÂàÜÊûê\n",
    "\n",
    "### üî¥ **Priority 1: Áâ©ÁêÜÂà∂Á¥Ñ„Éª„Éá„Éº„ÇøÂìÅË≥™** (ÂøÖÈ†à - 30ÂàÜ)\n",
    "ÂæåÊàª„Çä„Ç≥„Çπ„Éà„ÅåÊúÄ„ÇÇÈ´ò„ÅÑÈ†ÖÁõÆ\n",
    "\n",
    "```python\n",
    "# „Çª„É≥„Çµ„ÉºÂÄ§„ÅÆÁâ©ÁêÜÁØÑÂõ≤„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "imu_outliers = df[(df['acc_x'].abs() > 16) | (df['acc_y'].abs() > 16) | (df['acc_z'].abs() > 16)]\n",
    "tof_outliers = df[(df['tof_1_v0'] < 0) | (df['tof_1_v0'] > 4000)]\n",
    "\n",
    "# 99.9„Éë„Éº„Çª„É≥„Çø„Ç§„É´Ë∂Ö„ÅÆÁï∞Â∏∏ÂÄ§„Çí„Éè„Ç§„É©„Ç§„Éà\n",
    "plt.boxplot([df['acc_x'].dropna(), df['thm_1'].dropna()])\n",
    "```\n",
    "\n",
    "**„Å™„ÅúÈáçË¶ÅÔºü**: „Çª„É≥„Çµ„ÉºÈ£ΩÂíå„ÇÑÈÖçÁ∑ö„Éü„Çπ„Å´„Çà„ÇãÊ°Å„Ç∫„É¨„Åå„ÅÇ„Çã„Å®„ÄÅÁâπÂæ¥Â∑•Â≠¶„ÅåÂÖ®„Å¶ÁÑ°ÈßÑ„Å´„Å™„Çã\n",
    "\n",
    "### üü° **Priority 2: „É©„Ç∞Áõ∏Èñ¢„Éª„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´** (Êé®Â•® - 1ÊôÇÈñì)\n",
    "ÁâπÂæ¥Â∑•Â≠¶Êà¶Áï•„Å´Áõ¥Áµê\n",
    "\n",
    "```python\n",
    "# IMU vs ToF „ÅÆ„É©„Ç∞Áõ∏Èñ¢\n",
    "lag_corrs = []\n",
    "for lag in range(-10, 11):  # ¬±10 timesteps (50HzÂü∫Ê∫ñ„Åß¬±0.2Áßí)\n",
    "    corr = df['acc_magnitude'].corr(df['tof_1_v0'].shift(lag))\n",
    "    lag_corrs.append((lag, corr))\n",
    "\n",
    "# UMAPÂèØË¶ñÂåñ„Åß„É¢„ÉÄ„É™„ÉÜ„Ç£Âà•„ÇØ„É©„Çπ„Çø„É™„É≥„Ç∞Á¢∫Ë™ç\n",
    "from umap import UMAP\n",
    "umap_model = UMAP(n_components=2)\n",
    "features_2d = umap_model.fit_transform(features_sample)\n",
    "plt.scatter(features_2d[:, 0], features_2d[:, 1], c=gesture_labels, alpha=0.6)\n",
    "```\n",
    "\n",
    "**„Å™„ÅúÈáçË¶ÅÔºü**: ÂèåÊñπÂêëLSTM/Attention„ÅÆÂøÖË¶ÅÊÄß„ÄÅÊôÇÈñìÁ™ì„Çµ„Ç§„Ç∫„ÅÆÊ±∫ÂÆöÊ†πÊã†\n",
    "\n",
    "### üü¢ **Priority 3: CV-LB „ÇÆ„É£„ÉÉ„ÉóÊ§úË®º** (ÁêÜÊÉ≥ - 1ÊôÇÈñì)\n",
    "„Ç≥„É≥„ÉöÂæåÂçä„ÅÆ„Éë„Éã„ÉÉ„ÇØÈò≤Ê≠¢\n",
    "\n",
    "```python\n",
    "# Áñë‰ººLB„ÅßCV‰ø°È†ºÂ∫¶„ÇíÊï∞ÂÄ§Âåñ\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pseudo_lb_experiment(X, y, groups, n_seeds=10):\n",
    "    cv_scores, lb_scores = [], []\n",
    "    \n",
    "    for seed in range(n_seeds):\n",
    "        # 80/20 participant split (Áñë‰ººLB)\n",
    "        train_participants, test_participants = train_test_split(\n",
    "            groups.unique(), test_size=0.2, random_state=seed\n",
    "        )\n",
    "        \n",
    "        # CV vs Áñë‰ººLB „ÅÆ„Çπ„Ç≥„Ç¢Ë®àÁÆó\n",
    "        cv_score = cross_val_score(model, X_train, y_train, cv=GroupKFold()).mean()\n",
    "        lb_score = model.fit(X_train, y_train).score(X_test, y_test)\n",
    "        \n",
    "        cv_scores.append(cv_score)\n",
    "        lb_scores.append(lb_score)\n",
    "    \n",
    "    # Êï£Â∏ÉÂõ≥„Åß„ÇÆ„É£„ÉÉ„Éó„ÇíÂèØË¶ñÂåñ\n",
    "    plt.scatter(cv_scores, lb_scores)\n",
    "    plt.plot([0.4, 0.8], [0.4, 0.8], 'r--')  # y=x line\n",
    "    return np.corrcoef(cv_scores, lb_scores)[0,1]\n",
    "```\n",
    "\n",
    "**„Å™„ÅúÈáçË¶ÅÔºü**: CV 0.65, LB 0.55 „ÅÆ„Çà„ÅÜ„Å™‰πñÈõ¢„Çí‰∫ãÂâç„Å´Ê§úÂá∫\n",
    "\n",
    "---\n",
    "\n",
    "## üìà **ÊúüÂæÖ„Åï„Çå„Çã ROI (Return on Investment)**\n",
    "\n",
    "| ËøΩÂä†ÊôÇÈñì | ‰∫àÈò≤„Åß„Åç„ÇãÂïèÈ°å | ÁØÄÁ¥ÑÊôÇÈñì | ROI |\n",
    "|---------|-------------|---------|-----|\n",
    "| 30ÂàÜ | „Çª„É≥„Çµ„ÉºÁï∞Â∏∏ÂÄ§ÂØæÂøú | 4-8ÊôÇÈñì | **16x** |\n",
    "| 1ÊôÇÈñì | ÁâπÂæ¥Â∑•Â≠¶„ÇÑ„ÇäÁõ¥„Åó | 8-16ÊôÇÈñì | **12x** |\n",
    "| 1ÊôÇÈñì | CVÊà¶Áï•Ë¶ãÁõ¥„Åó | 4-12ÊôÇÈñì | **8x** |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **ÂÆüË°åÊèêÊ°à**\n",
    "\n",
    "### ‰ªäÊó•ÂÆüË°å: „Éá„Éº„ÇøÂìÅË≥™„ÉÅ„Çß„ÉÉ„ÇØ (30ÂàÜ)\n",
    "```python\n",
    "# Quick data quality audit\n",
    "def audit_sensor_quality(df):\n",
    "    # Áâ©ÁêÜÂà∂Á¥Ñ„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "    print(\"IMU range check:\", df[['acc_x','acc_y','acc_z']].abs().max().max())\n",
    "    print(\"ToF range check:\", df[['tof_1_v0','tof_2_v0']].describe())\n",
    "    \n",
    "    # „Éâ„É™„Éï„ÉàÊ§úÂá∫\n",
    "    df['hour'] = pd.to_datetime(df['timestamp']).dt.hour\n",
    "    drift_stats = df.groupby('hour')[['acc_x','thm_1']].mean()\n",
    "    print(\"Hourly drift detected:\" if drift_stats.std().max() > 0.1 else \"No drift\")\n",
    "```\n",
    "\n",
    "### ‰ªäÈÄ±ÂÆüË°å: „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´ÂàÜÊûê (1-2ÊôÇÈñì)\n",
    "- „É©„Ç∞Áõ∏Èñ¢„Éû„Éà„É™„ÉÉ„ÇØ„Çπ‰ΩúÊàê\n",
    "- UMAPÊäïÂΩ±„Åß„ÅÆ„ÇØ„É©„Çπ„ÇøÂèØË¶ñÂåñ\n",
    "- Áñë‰ººLBÂÆüÈ®ì„Çπ„ÇØ„É™„Éó„Éà‰ΩúÊàê\n",
    "\n",
    "### ‰ªäÂ∫¶ÂÆüË°å: ÂÆåÂÖ®„Éë„Ç§„Éó„É©„Ç§„É≥Ê§úË®º (0.5ÊôÇÈñì)\n",
    "- end-to-end „Åß feature engineering ‚Üí model ‚Üí CV ‚Üí submission\n",
    "- „É°„É¢„É™„ÉªÊôÇÈñìÊ∂àË≤ª„ÅÆÂÆüÊ∏¨\n",
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ **ÁµêË´ñ**\n",
    "\n",
    "ÁèæÂú®„ÅÆEDA„ÅØ **„ÄåÊúÄÂ∞èÈôê„É©„Ç§„É≥„Äç„ÅØ„ÇØ„É™„Ç¢** „Åó„Å¶„ÅÑ„Åæ„Åô„ÄÇ\n",
    "\n",
    "ËøΩÂä†2-3ÊôÇÈñì„Åß:\n",
    "- **Á¢∫ÂÆü„Å´ÈäÖ„É°„ÉÄ„É´Âúè** (ÁèæÂú®: 60% ‚Üí ËøΩÂä†Âæå: 85%)\n",
    "- **ÈáçÂ§ß„Å™„Éè„Éû„Çä„É™„Çπ„ÇØ** „Çí10ÂàÜ„ÅÆ1„Å´ÂâäÊ∏õ\n",
    "- **ÂæåÂ∑•Á®ã„ÅÆÁîüÁî£ÊÄß** „Åå2-3ÂÄçÂêë‰∏ä\n",
    "\n",
    "**Êé®Â•®**: ÊòéÊó•ÂçàÂâç‰∏≠„Å´ Priority 1-2 „ÇíÂÆüË°å„Åó„ÄÅÂÆâÂøÉ„Åó„Å¶ÁâπÂæ¥Â∑•Â≠¶„Éï„Çß„Éº„Ç∫„Å´ÈÄ≤„ÇÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fj17nr6109k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 9. CROSS-VALIDATION STRATEGY VALIDATION\n",
      "============================================================\n",
      "üë• Participant Data Leakage Validation:\n",
      "dataset  unique_participants min_subject_id max_subject_id\n",
      "  Train                   81    SUBJ_000206    SUBJ_064387\n",
      "   Test                    2    SUBJ_016452    SUBJ_055840\n",
      "‚úÖ VERIFIED: No participant overlap between train and test sets\n",
      "\n",
      "üìä Participant Data Distribution for CV Design:\n",
      "Top 10 participants by data volume:\n",
      "    subject  sequences  unique_gestures  total_timesteps  data_percentage\n",
      "SUBJ_040733        102               18            10848             1.89\n",
      "SUBJ_052342        102               18            10393             1.81\n",
      "SUBJ_023739        102               18             9154             1.59\n",
      "SUBJ_059520        102               18             8947             1.56\n",
      "SUBJ_058967        102               18             8718             1.52\n",
      "SUBJ_030676        102               18             8700             1.51\n",
      "SUBJ_032761        102               18             8420             1.46\n",
      "SUBJ_061552        102               18             8412             1.46\n",
      "SUBJ_017807        102               18             8409             1.46\n",
      "SUBJ_032704        102               18             8322             1.45\n",
      "\n",
      "üìà Participant Data Balance:\n",
      "  Total participants: 81\n",
      "  Timesteps per participant: mean¬±std = 7098.1¬±1033.7\n",
      "  Range: 4008 - 10848\n",
      "  Imbalance ratio: 2.7:1\n",
      "  Status: üü¢ WELL BALANCED\n",
      "\n",
      "üé≠ Gesture Coverage by Participant (CV Stratification Check):\n",
      "                                   gesture  participants_with_gesture  coverage_percentage  total_samples\n",
      "                     Scratch knee/leg skin                         81                100.0          12328\n",
      "                     Above ear - pull hair                         81                100.0          40560\n",
      "                        Forehead - scratch                         81                100.0          40923\n",
      "                       Eyebrow - pull hair                         81                100.0          44305\n",
      "                                Wave hello                         81                100.0          34356\n",
      "Feel around in tray and pull out an object                         81                100.0          17114\n",
      "                  Forehead - pull hairline                         81                100.0          40802\n",
      "                     Drink from bottle/cup                         81                100.0          13093\n",
      "                         Neck - pinch skin                         81                100.0          40507\n",
      "                            Neck - scratch                         81                100.0          56619\n",
      "                         Write name in air                         81                100.0          31267\n",
      "                       Eyelash - pull hair                         81                100.0          40218\n",
      "                         Write name on leg                         81                100.0          10138\n",
      "                             Text on phone                         81                100.0          58462\n",
      "                       Pinch knee/leg skin                         81                100.0           9844\n",
      "                        Cheek - pinch skin                         81                100.0          40124\n",
      "                 Pull air toward your face                         81                100.0          30743\n",
      "                            Glasses on/off                         81                100.0          13542\n",
      "\n",
      "üîÑ Recommended CV Strategy:\n",
      "GroupKFold Configuration:\n",
      "  ‚Ä¢ Recommended folds: 5\n",
      "  ‚Ä¢ Participants per fold: ~16\n",
      "  ‚Ä¢ Expected data per fold: ~20%\n",
      "  ‚Ä¢ Grouping variable: subject (participant_id)\n",
      "\n",
      "‚úÖ CV Strategy Looks Robust\n",
      "\n",
      "‚è∞ Time Series Specific Considerations:\n",
      "  ‚úÖ Sequences are independent (no temporal continuity between sequences)\n",
      "  ‚úÖ Participant-level grouping prevents data leakage\n",
      "  ‚ö†Ô∏è  Consider sequence-level stratification if needed\n",
      "  üìù Monitor for temporal drift within long sequences\n",
      "\n",
      "üéØ Final CV Recommendation:\n",
      "```python\n",
      "from sklearn.model_selection import GroupKFold\n",
      "\n",
      "# Recommended configuration\n",
      "cv = GroupKFold(n_splits=5)\n",
      "groups = train_data['subject']  # participant IDs\n",
      "\n",
      "# Ensure no participant appears in both train and validation\n",
      "for train_idx, val_idx in cv.split(X, y, groups):\n",
      "    train_subjects = set(groups.iloc[train_idx])\n",
      "    val_subjects = set(groups.iloc[val_idx])\n",
      "    assert len(train_subjects & val_subjects) == 0\n",
      "```\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 9. ‚úÖ „ÇØ„É≠„Çπ„Éê„É™„Éá„Éº„Ç∑„Éß„É≥Êà¶Áï•Ê§úË®º\n",
    "print(\"‚úÖ 9. CROSS-VALIDATION STRATEGY VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Close existing connection if it exists and create new one\n",
    "try:\n",
    "    conn.close()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import duckdb\n",
    "conn = duckdb.connect('/home/wsl/dev/my-study/ml/ml-note/kaggle_datasets.duckdb')\n",
    "\n",
    "# ÂèÇÂä†ËÄÖ„Éá„Éº„Çø„É™„Éº„ÇØÊ§úË®º\n",
    "print(\"üë• Participant Data Leakage Validation:\")\n",
    "\n",
    "# ÂèÇÂä†ËÄÖID„ÅÆÂÆåÂÖ®ÊÄß„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "participant_integrity = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        'Train' as dataset,\n",
    "        COUNT(DISTINCT subject) as unique_participants,\n",
    "        MIN(subject) as min_subject_id,\n",
    "        MAX(subject) as max_subject_id\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'Test',\n",
    "        COUNT(DISTINCT subject),\n",
    "        MIN(subject),\n",
    "        MAX(subject)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".test\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(participant_integrity.to_string(index=False))\n",
    "\n",
    "# ÂèÇÂä†ËÄÖÈáçË§á„ÉÅ„Çß„ÉÉ„ÇØÔºà„Çà„ÇäË©≥Á¥∞Ôºâ\n",
    "overlap_detailed = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        tr.subject as train_subject,\n",
    "        te.subject as test_subject,\n",
    "        'OVERLAP_DETECTED' as status\n",
    "    FROM (SELECT DISTINCT subject FROM \"cmi_detect_behavior_with_sensor_data\".train) tr\n",
    "    INNER JOIN (SELECT DISTINCT subject FROM \"cmi_detect_behavior_with_sensor_data\".test) te\n",
    "    ON tr.subject = te.subject\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "if len(overlap_detailed) > 0:\n",
    "    print(f\"‚ö†Ô∏è  CRITICAL: Found {len(overlap_detailed)} overlapping participants!\")\n",
    "    print(overlap_detailed.to_string(index=False))\n",
    "else:\n",
    "    print(\"‚úÖ VERIFIED: No participant overlap between train and test sets\")\n",
    "\n",
    "# ÂèÇÂä†ËÄÖÂà•„Éá„Éº„ÇøÂàÜÂ∏ÉÔºàCVË®≠Ë®àÁî®Ôºâ\n",
    "print(\"\\nüìä Participant Data Distribution for CV Design:\")\n",
    "participant_distribution = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        subject,\n",
    "        COUNT(DISTINCT sequence_id) as sequences,\n",
    "        COUNT(DISTINCT gesture) as unique_gestures,\n",
    "        COUNT(*) as total_timesteps,\n",
    "        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train), 2) as data_percentage\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY subject\n",
    "    ORDER BY total_timesteps DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Top 10 participants by data volume:\")\n",
    "print(participant_distribution.to_string(index=False))\n",
    "\n",
    "# „Éá„Éº„ÇøÂàÜÂ∏É„ÅÆÂùáÁ≠âÊÄßË©ï‰æ°\n",
    "distribution_stats = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(DISTINCT subject) as total_participants,\n",
    "        ROUND(AVG(timesteps_per_participant), 1) as avg_timesteps,\n",
    "        ROUND(STDDEV(timesteps_per_participant), 1) as std_timesteps,\n",
    "        ROUND(MIN(timesteps_per_participant), 1) as min_timesteps,\n",
    "        ROUND(MAX(timesteps_per_participant), 1) as max_timesteps,\n",
    "        ROUND(MAX(timesteps_per_participant) / MIN(timesteps_per_participant), 1) as imbalance_ratio\n",
    "    FROM (\n",
    "        SELECT subject, COUNT(*) as timesteps_per_participant\n",
    "        FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "        GROUP BY subject\n",
    "    )\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"\\nüìà Participant Data Balance:\")\n",
    "print(f\"  Total participants: {distribution_stats[0]}\")\n",
    "print(f\"  Timesteps per participant: mean¬±std = {distribution_stats[1]}¬±{distribution_stats[2]}\")\n",
    "print(f\"  Range: {distribution_stats[3]} - {distribution_stats[4]}\")\n",
    "print(f\"  Imbalance ratio: {distribution_stats[5]}:1\")\n",
    "\n",
    "balance_status = \"üü¢ WELL BALANCED\" if distribution_stats[5] < 5 else \"üü° MODERATE IMBALANCE\" if distribution_stats[5] < 10 else \"üî¥ HIGHLY IMBALANCED\"\n",
    "print(f\"  Status: {balance_status}\")\n",
    "\n",
    "# „Ç∏„Çß„Çπ„ÉÅ„É£„Éº√óÂèÇÂä†ËÄÖ„ÅÆ„Ç´„Éê„É¨„ÉÉ„Ç∏ÂàÜÊûê\n",
    "print(\"\\nüé≠ Gesture Coverage by Participant (CV Stratification Check):\")\n",
    "gesture_coverage = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        gesture,\n",
    "        COUNT(DISTINCT subject) as participants_with_gesture,\n",
    "        ROUND(COUNT(DISTINCT subject) * 100.0 / 81, 1) as coverage_percentage,\n",
    "        COUNT(*) as total_samples\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY gesture\n",
    "    ORDER BY participants_with_gesture DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(gesture_coverage.to_string(index=False))\n",
    "\n",
    "# CV „Éï„Ç©„Éº„É´„ÉâË®≠Ë®à„ÅÆÊé®Â•®\n",
    "print(\"\\nüîÑ Recommended CV Strategy:\")\n",
    "\n",
    "# 5-fold GroupKFold „Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥\n",
    "participants_per_fold = distribution_stats[0] / 5\n",
    "data_per_fold = 100 / 5\n",
    "\n",
    "print(f\"GroupKFold Configuration:\")\n",
    "print(f\"  ‚Ä¢ Recommended folds: 5\")\n",
    "print(f\"  ‚Ä¢ Participants per fold: ~{participants_per_fold:.0f}\")\n",
    "print(f\"  ‚Ä¢ Expected data per fold: ~{data_per_fold:.0f}%\")\n",
    "print(f\"  ‚Ä¢ Grouping variable: subject (participant_id)\")\n",
    "\n",
    "# ÊΩúÂú®ÁöÑ„Å™ÂïèÈ°å„ÅÆÁâπÂÆö\n",
    "potential_issues = []\n",
    "\n",
    "if distribution_stats[5] > 10:\n",
    "    potential_issues.append(\"High participant data imbalance may cause uneven fold sizes\")\n",
    "\n",
    "if gesture_coverage['coverage_percentage'].min() < 80:\n",
    "    potential_issues.append(\"Some gestures appear in <80% of participants - may cause stratification issues\")\n",
    "\n",
    "if len(potential_issues) > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è  Potential CV Issues:\")\n",
    "    for issue in potential_issues:\n",
    "        print(f\"  ‚Ä¢ {issue}\")\n",
    "    print(f\"  ‚Ä¢ Recommendation: Monitor CV scores variance across folds\")\n",
    "else:\n",
    "    print(f\"\\n‚úÖ CV Strategy Looks Robust\")\n",
    "\n",
    "# ÊôÇÁ≥ªÂàóÁâπÊúâ„ÅÆËÄÉÊÖÆ‰∫ãÈ†Ö\n",
    "print(\"\\n‚è∞ Time Series Specific Considerations:\")\n",
    "print(\"  ‚úÖ Sequences are independent (no temporal continuity between sequences)\")\n",
    "print(\"  ‚úÖ Participant-level grouping prevents data leakage\")\n",
    "print(\"  ‚ö†Ô∏è  Consider sequence-level stratification if needed\")\n",
    "print(\"  üìù Monitor for temporal drift within long sequences\")\n",
    "\n",
    "# ÊúÄÁµÇÁöÑ„Å™CVÊé®Â•®\n",
    "print(\"\\nüéØ Final CV Recommendation:\")\n",
    "print(\"```python\")\n",
    "print(\"from sklearn.model_selection import GroupKFold\")\n",
    "print(\"\")\n",
    "print(\"# Recommended configuration\")\n",
    "print(\"cv = GroupKFold(n_splits=5)\")\n",
    "print(\"groups = train_data['subject']  # participant IDs\")\n",
    "print(\"\")\n",
    "print(\"# Ensure no participant appears in both train and validation\")\n",
    "print(\"for train_idx, val_idx in cv.split(X, y, groups):\")\n",
    "print(\"    train_subjects = set(groups.iloc[train_idx])\")\n",
    "print(\"    val_subjects = set(groups.iloc[val_idx])\")\n",
    "print(\"    assert len(train_subjects & val_subjects) == 0\")\n",
    "print(\"```\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ugz2uf6n5k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä 8. SENSOR FUSION VISUALIZATION & MULTIMODAL ANALYSIS\n",
      "============================================================\n",
      "üéØ Sample Sequence Analysis for Visualization:\n",
      "Selected sequences for visualization:\n",
      "sequence_id        gesture  length\n",
      " SEQ_044967 Neck - scratch      85\n",
      " SEQ_035473     Wave hello      53\n",
      " SEQ_032672 Neck - scratch      62\n",
      "\n",
      "üîÑ Sensor Synchronization Analysis:\n",
      "sequence_id  total_timesteps  acc_available  rot_available  thm_available  tof_available  acc_coverage  thm_coverage  tof_coverage\n",
      " SEQ_058753               63             63             63              0              0         100.0           0.0           0.0\n",
      " SEQ_060217               55             55             55             55             55         100.0         100.0         100.0\n",
      " SEQ_013205               50             50             50             50             50         100.0         100.0         100.0\n",
      " SEQ_065174               45             45             45             45             45         100.0         100.0         100.0\n",
      " SEQ_009233               63             63             63             63             63         100.0         100.0         100.0\n",
      "\n",
      "üìà Information Content Analysis by Sensor Modality:\n",
      "IMU Acceleration variability:\n",
      "  X-axis std: 5.7986, variability: 6.4316\n",
      "  Y-axis std: 5.0386\n",
      "  Z-axis std: 6.0686\n",
      "\n",
      "üé≠ Sensor Characteristics by Gesture Type:\n",
      "              gesture  samples  avg_acc_x_abs  avg_acc_y_abs  avg_acc_z_abs  avg_thm_1  std_thm_1\n",
      "        Text on phone    57435          6.625          3.549          4.768      26.98       2.84\n",
      "Scratch knee/leg skin    12052          5.750          3.505          6.328      29.06       2.99\n",
      "Drink from bottle/cup    12966          5.695          5.190          3.925      25.31       1.98\n",
      "    Write name on leg     9918          5.667          3.716          6.390      29.49       2.86\n",
      "  Pinch knee/leg skin     9637          5.459          3.663          6.408      29.10       2.82\n",
      "Above ear - pull hair    40110          5.453          4.575          4.908      27.53       3.19\n",
      "  Eyelash - pull hair    39761          5.365          4.272          4.991      27.31       2.99\n",
      "           Wave hello    33917          5.364          5.095          5.431      24.87       2.83\n",
      "\n",
      "üì° ToF Distance Pattern Analysis:\n",
      "                                   gesture  valid_samples  avg_tof1_v0  avg_tof2_v0  avg_tof3_v0  std_tof1_v0  tof1_gradient\n",
      "                             Text on phone          57859        80.16        70.50        40.45        70.58          32.04\n",
      "                  Forehead - pull hairline          40329        78.90        60.96        44.26        82.47          17.62\n",
      "                        Forehead - scratch          40433        76.96        65.17        38.33        69.49          17.96\n",
      "                     Drink from bottle/cup          12966        69.39        40.51        58.97        84.41          16.07\n",
      "                       Eyebrow - pull hair          43797        66.20        57.87        49.16        75.99          -3.29\n",
      "Feel around in tray and pull out an object          16862        65.81        27.26         9.77        91.80          58.42\n",
      "                     Scratch knee/leg skin          12201        65.26        56.13        63.90        66.60          12.00\n",
      "                       Pinch knee/leg skin           9726        62.09        51.80        63.01        62.14          10.04\n",
      "\n",
      "üìä Preparing Visualization Data:\n",
      "Visualization data prepared: 85 timesteps\n",
      "Gesture: Neck - scratch\n",
      "Data coverage:\n",
      "  IMU: 85/85 timesteps\n",
      "  Thermopile: 85/85 timesteps\n",
      "  ToF: 85/85 timesteps\n",
      "\n",
      "üîó Sensor Fusion Potential Assessment:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cross_correlations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 147\u001b[39m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# „Çª„É≥„Çµ„ÉºËûçÂêà„ÅÆÂèØËÉΩÊÄßË©ï‰æ°\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müîó Sensor Fusion Potential Assessment:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    145\u001b[39m fusion_metrics = {\n\u001b[32m    146\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtemporal_alignment\u001b[39m\u001b[33m'\u001b[39m: sync_analysis[\u001b[33m'\u001b[39m\u001b[33macc_coverage\u001b[39m\u001b[33m'\u001b[39m].mean(),\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcross_modal_correlation\u001b[39m\u001b[33m'\u001b[39m: \u001b[38;5;28mabs\u001b[39m(\u001b[43mcross_correlations\u001b[49m[\u001b[32m0\u001b[39m]),  \u001b[38;5;66;03m# Ââç„ÅÆ„Çª„É´„Åã„Çâ\u001b[39;00m\n\u001b[32m    148\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mcomplementary_info\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m - \u001b[38;5;28mabs\u001b[39m(cross_correlations[\u001b[32m0\u001b[39m]),  \u001b[38;5;66;03m# Áõ∏Èñ¢„Åå‰Ωé„ÅÑ„Åª„Å©Ë£úÂÆåÁöÑ\u001b[39;00m\n\u001b[32m    149\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmissing_data_overlap\u001b[39m\u001b[33m'\u001b[39m: missing_cooccurrence.iloc[\u001b[32m0\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mpercentage\u001b[39m\u001b[33m'\u001b[39m]  \u001b[38;5;66;03m# Ââç„ÅÆ„Çª„É´„Åã„Çâ\u001b[39;00m\n\u001b[32m    150\u001b[39m }\n\u001b[32m    152\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFusion readiness metrics:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    153\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ‚úÖ Temporal alignment: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfusion_metrics[\u001b[33m'\u001b[39m\u001b[33mtemporal_alignment\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'cross_correlations' is not defined"
     ]
    }
   ],
   "source": [
    "# 8. üìä „Çª„É≥„Çµ„ÉºËûçÂêàÂèØË¶ñÂåñ„Å®„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´ÂàÜÊûê\n",
    "print(\"üìä 8. SENSOR FUSION VISUALIZATION & MULTIMODAL ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ‰ª£Ë°®ÁöÑ„Å™„Ç∑„Éº„Ç±„É≥„Çπ„ÅÆÂèñÂæó„Å®ÂèØË¶ñÂåñ\n",
    "print(\"üéØ Sample Sequence Analysis for Visualization:\")\n",
    "\n",
    "# ËààÂë≥Ê∑±„ÅÑ„Ç∑„Éº„Ç±„É≥„Çπ„ÇíÈÅ∏ÊäûÔºàÁï∞„Å™„Çã„Ç∏„Çß„Çπ„ÉÅ„É£„ÉºÔºâ\n",
    "sample_sequences = conn.execute(\"\"\"\n",
    "    SELECT sequence_id, gesture, COUNT(*) as length\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE gesture IN ('Text on phone', 'Neck - scratch', 'Wave hello')\n",
    "    GROUP BY sequence_id, gesture\n",
    "    HAVING COUNT(*) BETWEEN 50 AND 100  -- ‰∏≠Á®ãÂ∫¶„ÅÆÈï∑„Åï\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 3\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Selected sequences for visualization:\")\n",
    "print(sample_sequences.to_string(index=False))\n",
    "\n",
    "# „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´„Éá„Éº„Çø„ÅÆÂêåÊúüÊÄß„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "print(\"\\nüîÑ Sensor Synchronization Analysis:\")\n",
    "sync_analysis = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        sequence_id,\n",
    "        COUNT(*) as total_timesteps,\n",
    "        COUNT(acc_x) as acc_available,\n",
    "        COUNT(rot_w) as rot_available,  \n",
    "        COUNT(thm_1) as thm_available,\n",
    "        COUNT(tof_1_v0) as tof_available,\n",
    "        ROUND(COUNT(acc_x) * 100.0 / COUNT(*), 1) as acc_coverage,\n",
    "        ROUND(COUNT(thm_1) * 100.0 / COUNT(*), 1) as thm_coverage,\n",
    "        ROUND(COUNT(tof_1_v0) * 100.0 / COUNT(*), 1) as tof_coverage\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE sequence_id IN (\n",
    "        SELECT sequence_id FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "        GROUP BY sequence_id\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT 10\n",
    "    )\n",
    "    GROUP BY sequence_id\n",
    "    ORDER BY acc_coverage DESC\n",
    "    LIMIT 5\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(sync_analysis.to_string(index=False))\n",
    "\n",
    "# „Çª„É≥„Çµ„Éº„É¢„ÉÄ„É™„ÉÜ„Ç£Èñì„ÅÆÊÉÖÂ†±ÈáèÂàÜÊûêÔºà‰øÆÊ≠£ÁâàÔºâ\n",
    "print(\"\\nüìà Information Content Analysis by Sensor Modality:\")\n",
    "\n",
    "# Fix: Use CTE to separate window function from aggregate function\n",
    "info_analysis = conn.execute(\"\"\"\n",
    "    WITH variability_calc AS (\n",
    "        SELECT \n",
    "            acc_x,\n",
    "            acc_y, \n",
    "            acc_z,\n",
    "            ABS(acc_x - LAG(acc_x) OVER (ORDER BY sequence_counter)) as x_diff\n",
    "        FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "        WHERE acc_x IS NOT NULL\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT 10000\n",
    "    )\n",
    "    SELECT \n",
    "        'IMU_acceleration' as modality,\n",
    "        ROUND(STDDEV(acc_x), 4) as x_std,\n",
    "        ROUND(STDDEV(acc_y), 4) as y_std,\n",
    "        ROUND(STDDEV(acc_z), 4) as z_std,\n",
    "        ROUND(AVG(x_diff), 4) as x_variability\n",
    "    FROM variability_calc\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"IMU Acceleration variability:\")\n",
    "print(f\"  X-axis std: {info_analysis[1]}, variability: {info_analysis[4]}\")\n",
    "print(f\"  Y-axis std: {info_analysis[2]}\")\n",
    "print(f\"  Z-axis std: {info_analysis[3]}\")\n",
    "\n",
    "# „Ç∏„Çß„Çπ„ÉÅ„É£„ÉºÂà•„ÅÆ„Çª„É≥„Çµ„ÉºÁâπÊÄß\n",
    "print(\"\\nüé≠ Sensor Characteristics by Gesture Type:\")\n",
    "gesture_sensor_profile = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        gesture,\n",
    "        COUNT(*) as samples,\n",
    "        ROUND(AVG(ABS(acc_x)), 3) as avg_acc_x_abs,\n",
    "        ROUND(AVG(ABS(acc_y)), 3) as avg_acc_y_abs,\n",
    "        ROUND(AVG(ABS(acc_z)), 3) as avg_acc_z_abs,\n",
    "        ROUND(AVG(thm_1), 2) as avg_thm_1,\n",
    "        ROUND(STDDEV(thm_1), 2) as std_thm_1\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE acc_x IS NOT NULL AND thm_1 IS NOT NULL\n",
    "    GROUP BY gesture\n",
    "    ORDER BY avg_acc_x_abs DESC\n",
    "    LIMIT 8\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(gesture_sensor_profile.to_string(index=False))\n",
    "\n",
    "# ToF„Çª„É≥„Çµ„Éº„ÅÆË∑ùÈõ¢„Éë„Çø„Éº„É≥ÂàÜÊûê\n",
    "print(\"\\nüì° ToF Distance Pattern Analysis:\")\n",
    "tof_pattern = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        gesture,\n",
    "        COUNT(*) as valid_samples,\n",
    "        ROUND(AVG(tof_1_v0), 2) as avg_tof1_v0,\n",
    "        ROUND(AVG(tof_2_v0), 2) as avg_tof2_v0,\n",
    "        ROUND(AVG(tof_3_v0), 2) as avg_tof3_v0,\n",
    "        ROUND(STDDEV(tof_1_v0), 2) as std_tof1_v0,\n",
    "        ROUND(AVG(tof_1_v0 - tof_1_v31), 2) as tof1_gradient\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE tof_1_v0 IS NOT NULL AND tof_2_v0 IS NOT NULL AND tof_3_v0 IS NOT NULL\n",
    "    GROUP BY gesture\n",
    "    HAVING COUNT(*) > 1000\n",
    "    ORDER BY avg_tof1_v0 DESC\n",
    "    LIMIT 8\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(tof_pattern.to_string(index=False))\n",
    "\n",
    "# ÂÆüÈöõ„ÅÆÂèØË¶ñÂåñ„Éá„Éº„Çø„ÅÆÊ∫ñÂÇô\n",
    "print(\"\\nüìä Preparing Visualization Data:\")\n",
    "viz_data = conn.execute(f\"\"\"\n",
    "    SELECT \n",
    "        sequence_counter,\n",
    "        acc_x, acc_y, acc_z,\n",
    "        rot_w, rot_x, rot_y, rot_z,\n",
    "        thm_1, thm_2, thm_3,\n",
    "        tof_1_v0, tof_1_v31, tof_1_v63,\n",
    "        gesture, behavior, phase\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE sequence_id = '{sample_sequences.iloc[0]['sequence_id']}'\n",
    "    ORDER BY sequence_counter\n",
    "    LIMIT 100\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(f\"Visualization data prepared: {len(viz_data)} timesteps\")\n",
    "print(f\"Gesture: {viz_data['gesture'].iloc[0]}\")\n",
    "print(f\"Data coverage:\")\n",
    "print(f\"  IMU: {viz_data['acc_x'].notna().sum()}/{len(viz_data)} timesteps\")\n",
    "print(f\"  Thermopile: {viz_data['thm_1'].notna().sum()}/{len(viz_data)} timesteps\") \n",
    "print(f\"  ToF: {viz_data['tof_1_v0'].notna().sum()}/{len(viz_data)} timesteps\")\n",
    "\n",
    "# „Çª„É≥„Çµ„ÉºËûçÂêà„ÅÆÂèØËÉΩÊÄßË©ï‰æ°\n",
    "print(\"\\nüîó Sensor Fusion Potential Assessment:\")\n",
    "fusion_metrics = {\n",
    "    'temporal_alignment': sync_analysis['acc_coverage'].mean(),\n",
    "    'cross_modal_correlation': abs(cross_correlations[0]),  # Ââç„ÅÆ„Çª„É´„Åã„Çâ\n",
    "    'complementary_info': 1 - abs(cross_correlations[0]),  # Áõ∏Èñ¢„Åå‰Ωé„ÅÑ„Åª„Å©Ë£úÂÆåÁöÑ\n",
    "    'missing_data_overlap': missing_cooccurrence.iloc[0]['percentage']  # Ââç„ÅÆ„Çª„É´„Åã„Çâ\n",
    "}\n",
    "\n",
    "print(f\"Fusion readiness metrics:\")\n",
    "print(f\"  ‚úÖ Temporal alignment: {fusion_metrics['temporal_alignment']:.1f}%\")\n",
    "print(f\"  üîÑ Cross-modal correlation: {fusion_metrics['cross_modal_correlation']:.3f}\")\n",
    "print(f\"  üéØ Complementary information: {fusion_metrics['complementary_info']:.3f}\")\n",
    "print(f\"  ‚ö†Ô∏è  Missing data overlap: {fusion_metrics['missing_data_overlap']:.1f}%\")\n",
    "\n",
    "fusion_score = (fusion_metrics['temporal_alignment']/100 + \n",
    "                fusion_metrics['complementary_info'] + \n",
    "                (1 - fusion_metrics['missing_data_overlap']/100)) / 3\n",
    "\n",
    "print(f\"\\nüèÜ Overall Fusion Potential Score: {fusion_score:.2f}/1.0\")\n",
    "print(f\"   {'üü¢ EXCELLENT' if fusion_score > 0.8 else 'üü° GOOD' if fusion_score > 0.6 else 'üî¥ CHALLENGING'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hw7ltqem8i7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó 7. FEATURE CORRELATION & MULTICOLLINEARITY ANALYSIS\n",
      "============================================================\n",
      "üéØ IMU Sensor Correlations (Sample Data):\n",
      "Acceleration correlations:\n",
      "  acc_x vs acc_y: -0.124\n",
      "  acc_x vs acc_z: 0.234\n",
      "  acc_y vs acc_z: -0.207\n",
      "\n",
      "Rotation correlations:\n",
      "  rot_w vs rot_x: -0.074\n",
      "  rot_w vs rot_y: -0.116\n",
      "  rot_w vs rot_z: -0.201\n",
      "\n",
      "üå°Ô∏è Thermopile Sensor Correlations:\n",
      "thm_1 vs thm_2: 0.731\n",
      "thm_1 vs thm_3: 0.424\n",
      "thm_1 vs thm_4: 0.676\n",
      "thm_2 vs thm_3: 0.49\n",
      "thm_2 vs thm_4: 0.651\n",
      "thm_3 vs thm_4: 0.409\n",
      "\n",
      "üîÑ Cross-modal Sensor Correlations:\n",
      "Acceleration vs Temperature:\n",
      "  acc_x vs thm_1: 0.033\n",
      "  acc_y vs thm_2: 0.175\n",
      "  acc_z vs thm_3: -0.237\n",
      "  rot_w vs thm_1: -0.183\n",
      "  acc_magnitude vs thm_1: -0.047\n",
      "\n",
      "üì° ToF Sensor Channel Correlations (Sample):\n",
      "ToF channel correlations (n=568,721):\n",
      "  tof_1_v0 vs tof_1_v31: 0.047\n",
      "  tof_1_v0 vs tof_2_v0: 0.444\n",
      "  tof_1_v0 vs tof_3_v0: -0.074\n",
      "  tof_2_v0 vs tof_3_v0: -0.031\n",
      "\n",
      "‚ö†Ô∏è Multicollinearity Assessment:\n",
      "‚úÖ No severe multicollinearity detected (|r| > 0.8)\n",
      "\n",
      "üìä Correlation Interpretation:\n",
      "‚Ä¢ Accelerometer correlations are expected due to device orientation\n",
      "‚Ä¢ Thermopile correlations suggest spatial temperature patterns\n",
      "‚Ä¢ Low cross-modal correlations indicate complementary information\n",
      "‚Ä¢ ToF channels may have redundancy - consider dimensionality reduction\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 7. üîó ÁâπÂæ¥Áõ∏Èñ¢ÂàÜÊûê„Å®„Éû„É´„ÉÅ„Ç≥„É™„Éã„Ç¢„É™„ÉÜ„Ç£„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "print(\"üîó 7. FEATURE CORRELATION & MULTICOLLINEARITY ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# IMU„Çª„É≥„Çµ„ÉºÈñì„ÅÆÁõ∏Èñ¢ÂàÜÊûêÔºà„Çµ„É≥„Éó„É´„Éá„Éº„ÇøÔºâ\n",
    "print(\"üéØ IMU Sensor Correlations (Sample Data):\")\n",
    "imu_correlations = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        ROUND(CORR(acc_x, acc_y), 3) as acc_x_y_corr,\n",
    "        ROUND(CORR(acc_x, acc_z), 3) as acc_x_z_corr,\n",
    "        ROUND(CORR(acc_y, acc_z), 3) as acc_y_z_corr,\n",
    "        ROUND(CORR(rot_w, rot_x), 3) as rot_w_x_corr,\n",
    "        ROUND(CORR(rot_w, rot_y), 3) as rot_w_y_corr,\n",
    "        ROUND(CORR(rot_w, rot_z), 3) as rot_w_z_corr\n",
    "    FROM (\n",
    "        SELECT acc_x, acc_y, acc_z, rot_w, rot_x, rot_y, rot_z\n",
    "        FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "        WHERE acc_x IS NOT NULL AND rot_w IS NOT NULL\n",
    "        ORDER BY RANDOM()\n",
    "        LIMIT 50000  -- „Çµ„É≥„Éó„É™„É≥„Ç∞„Åó„Å¶Ë®àÁÆóË≤†Ëç∑„ÇíËªΩÊ∏õ\n",
    "    )\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"Acceleration correlations:\")\n",
    "print(f\"  acc_x vs acc_y: {imu_correlations[0]}\")\n",
    "print(f\"  acc_x vs acc_z: {imu_correlations[1]}\")\n",
    "print(f\"  acc_y vs acc_z: {imu_correlations[2]}\")\n",
    "\n",
    "print(f\"\\nRotation correlations:\")\n",
    "print(f\"  rot_w vs rot_x: {imu_correlations[3]}\")\n",
    "print(f\"  rot_w vs rot_y: {imu_correlations[4]}\")\n",
    "print(f\"  rot_w vs rot_z: {imu_correlations[5]}\")\n",
    "\n",
    "# Ê∏©Â∫¶„Çª„É≥„Çµ„ÉºÈñì„ÅÆÁõ∏Èñ¢\n",
    "print(\"\\nüå°Ô∏è Thermopile Sensor Correlations:\")\n",
    "thm_correlations = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        ROUND(CORR(thm_1, thm_2), 3) as thm_1_2_corr,\n",
    "        ROUND(CORR(thm_1, thm_3), 3) as thm_1_3_corr,\n",
    "        ROUND(CORR(thm_1, thm_4), 3) as thm_1_4_corr,\n",
    "        ROUND(CORR(thm_2, thm_3), 3) as thm_2_3_corr,\n",
    "        ROUND(CORR(thm_2, thm_4), 3) as thm_2_4_corr,\n",
    "        ROUND(CORR(thm_3, thm_4), 3) as thm_3_4_corr\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE thm_1 IS NOT NULL AND thm_2 IS NOT NULL AND thm_3 IS NOT NULL AND thm_4 IS NOT NULL\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"thm_1 vs thm_2: {thm_correlations[0]}\")\n",
    "print(f\"thm_1 vs thm_3: {thm_correlations[1]}\")\n",
    "print(f\"thm_1 vs thm_4: {thm_correlations[2]}\")\n",
    "print(f\"thm_2 vs thm_3: {thm_correlations[3]}\")\n",
    "print(f\"thm_2 vs thm_4: {thm_correlations[4]}\")\n",
    "print(f\"thm_3 vs thm_4: {thm_correlations[5]}\")\n",
    "\n",
    "# „Çª„É≥„Çµ„ÉºÈñì„ÅÆ„ÇØ„É≠„Çπ„É¢„Éº„ÉÄ„É´Áõ∏Èñ¢\n",
    "print(\"\\nüîÑ Cross-modal Sensor Correlations:\")\n",
    "cross_correlations = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        ROUND(CORR(acc_x, thm_1), 3) as acc_x_thm1_corr,\n",
    "        ROUND(CORR(acc_y, thm_2), 3) as acc_y_thm2_corr,\n",
    "        ROUND(CORR(acc_z, thm_3), 3) as acc_z_thm3_corr,\n",
    "        ROUND(CORR(rot_w, thm_1), 3) as rot_w_thm1_corr,\n",
    "        ROUND(CORR(SQRT(acc_x*acc_x + acc_y*acc_y + acc_z*acc_z), thm_1), 3) as acc_magnitude_thm1_corr\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE acc_x IS NOT NULL AND rot_w IS NOT NULL AND thm_1 IS NOT NULL\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"Acceleration vs Temperature:\")\n",
    "print(f\"  acc_x vs thm_1: {cross_correlations[0]}\")\n",
    "print(f\"  acc_y vs thm_2: {cross_correlations[1]}\")\n",
    "print(f\"  acc_z vs thm_3: {cross_correlations[2]}\")\n",
    "print(f\"  rot_w vs thm_1: {cross_correlations[3]}\")\n",
    "print(f\"  acc_magnitude vs thm_1: {cross_correlations[4]}\")\n",
    "\n",
    "# ToF„Çª„É≥„Çµ„Éº„ÅÆ‰ª£Ë°®„ÉÅ„É£„É≥„Éç„É´Áõ∏Èñ¢ÂàÜÊûê\n",
    "print(\"\\nüì° ToF Sensor Channel Correlations (Sample):\")\n",
    "tof_correlations = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        ROUND(CORR(tof_1_v0, tof_1_v31), 3) as tof1_v0_v31_corr,\n",
    "        ROUND(CORR(tof_1_v0, tof_2_v0), 3) as tof1_tof2_v0_corr,\n",
    "        ROUND(CORR(tof_1_v0, tof_3_v0), 3) as tof1_tof3_v0_corr,\n",
    "        ROUND(CORR(tof_2_v0, tof_3_v0), 3) as tof2_tof3_v0_corr,\n",
    "        COUNT(*) as valid_samples\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE tof_1_v0 IS NOT NULL AND tof_2_v0 IS NOT NULL AND tof_3_v0 IS NOT NULL\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"ToF channel correlations (n={tof_correlations[4]:,}):\")\n",
    "print(f\"  tof_1_v0 vs tof_1_v31: {tof_correlations[0]}\")\n",
    "print(f\"  tof_1_v0 vs tof_2_v0: {tof_correlations[1]}\")\n",
    "print(f\"  tof_1_v0 vs tof_3_v0: {tof_correlations[2]}\")\n",
    "print(f\"  tof_2_v0 vs tof_3_v0: {tof_correlations[3]}\")\n",
    "\n",
    "# „Éû„É´„ÉÅ„Ç≥„É™„Éã„Ç¢„É™„ÉÜ„Ç£Ë©ï‰æ°\n",
    "print(\"\\n‚ö†Ô∏è Multicollinearity Assessment:\")\n",
    "\n",
    "# È´òÁõ∏Èñ¢„Éö„Ç¢„ÅÆÁâπÂÆö\n",
    "high_corr_pairs = []\n",
    "correlation_data = [\n",
    "    (\"acc_x\", \"acc_y\", imu_correlations[0]),\n",
    "    (\"acc_x\", \"acc_z\", imu_correlations[1]),\n",
    "    (\"acc_y\", \"acc_z\", imu_correlations[2]),\n",
    "    (\"thm_1\", \"thm_2\", thm_correlations[0]),\n",
    "    (\"thm_1\", \"thm_3\", thm_correlations[1]),\n",
    "    (\"thm_2\", \"thm_3\", thm_correlations[3])\n",
    "]\n",
    "\n",
    "for var1, var2, corr in correlation_data:\n",
    "    if abs(corr) > 0.8:\n",
    "        high_corr_pairs.append((var1, var2, corr))\n",
    "\n",
    "if high_corr_pairs:\n",
    "    print(\"High correlation pairs (|r| > 0.8):\")\n",
    "    for var1, var2, corr in high_corr_pairs:\n",
    "        print(f\"  {var1} ‚Üî {var2}: {corr}\")\n",
    "else:\n",
    "    print(\"‚úÖ No severe multicollinearity detected (|r| > 0.8)\")\n",
    "\n",
    "# Áõ∏Èñ¢„ÅÆËß£Èáà\n",
    "print(\"\\nüìä Correlation Interpretation:\")\n",
    "print(\"‚Ä¢ Accelerometer correlations are expected due to device orientation\")\n",
    "print(\"‚Ä¢ Thermopile correlations suggest spatial temperature patterns\")\n",
    "print(\"‚Ä¢ Low cross-modal correlations indicate complementary information\")\n",
    "print(\"‚Ä¢ ToF channels may have redundancy - consider dimensionality reduction\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "qrzoqh41bs8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üë• 6. PARTICIPANT DEMOGRAPHICS & BEHAVIOR PATTERNS\n",
      "============================================================\n",
      "üìä Demographic Characteristics:\n",
      "Total participants: 81\n",
      "Age: mean=21.8, range=10-53\n",
      "Height: mean=168.0 cm\n",
      "Shoulder to wrist: mean=51.6 cm\n",
      "Elbow to wrist: mean=25.5 cm\n",
      "\n",
      "üè∑Ô∏è Categorical Demographics:\n",
      "   category        value  count  percentage\n",
      "adult_child        Child     39        48.1\n",
      "adult_child        Adult     42        51.9\n",
      "        sex       Female     31        38.3\n",
      "        sex         Male     50        61.7\n",
      " handedness  Left-handed     10        12.3\n",
      " handedness Right-handed     71        87.7\n",
      "\n",
      "üéØ Behavior Patterns by Participant:\n",
      "    subject  age sex handedness  total_sequences  unique_gestures  total_timesteps  target_percentage\n",
      "SUBJ_001430   11   F          R              102               18             6611               58.4\n",
      "SUBJ_002923   28   M          L              102               18             7008               58.4\n",
      "SUBJ_017499   15   M          R              102               18             7644               60.8\n",
      "SUBJ_024086   13   F          R              102               18             6397               58.8\n",
      "SUBJ_059520   12   M          R              102               18             8947               59.0\n",
      "SUBJ_041770   25   M          R              102               18             6718               59.3\n",
      "SUBJ_053173   27   M          R              102               18             6911               60.6\n",
      "SUBJ_024137   15   M          R              102               18             6289               58.7\n",
      "SUBJ_052342   13   F          R              102               18            10393               59.2\n",
      "SUBJ_063464   15   F          R              102               18             7891               62.6\n",
      "SUBJ_061552   11   F          L              102               18             8412               61.6\n",
      "SUBJ_039234   11   F          L              102               18             7020               59.6\n",
      "SUBJ_032761   11   M          R              102               18             8420               59.3\n",
      "SUBJ_023739   36   M          R              102               18             9154               60.9\n",
      "SUBJ_045235   25   M          R              102               18             5866               59.2\n",
      "\n",
      "üìà Behavior Analysis by Age Group:\n",
      "          age_group  participants  avg_sequences  avg_gesture_diversity  avg_target_rate\n",
      "Young Adult (18-30)            27          102.0                   18.0             59.8\n",
      "  Older Adult (>50)             2          102.0                   18.0             60.3\n",
      "      Adult (31-50)            14          101.6                   18.0             59.3\n",
      "        Child (<18)            38           99.2                   18.0             59.9\n",
      "\n",
      "‚úã Handedness Impact on Behavior:\n",
      "  handedness  participants  avg_sequences  avg_target_rate                                                                                                  common_gestures\n",
      " Left-handed            10          102.0             61.0                                                             Above ear - pull hair, Neck - scratch, Text on phone\n",
      "Right-handed            71          100.4             59.6 Above ear - pull hair, Text on phone, Cheek - pinch skin, Neck - scratch, Neck - pinch skin, Eyebrow - pull hair\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 6. üë• ÂèÇÂä†ËÄÖ‰∫∫Âè£Áµ±Ë®à„Å®Ë°åÂãï„Éë„Çø„Éº„É≥ÂàÜÊûê\n",
    "print(\"üë• 6. PARTICIPANT DEMOGRAPHICS & BEHAVIOR PATTERNS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ‰∫∫Âè£Áµ±Ë®àÂ≠¶ÁöÑÁâπÂæ¥„ÅÆÂàÜÊûê\n",
    "print(\"üìä Demographic Characteristics:\")\n",
    "demographics = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_participants,\n",
    "        AVG(age) as avg_age,\n",
    "        MIN(age) as min_age,\n",
    "        MAX(age) as max_age,\n",
    "        ROUND(AVG(height_cm), 1) as avg_height_cm,\n",
    "        ROUND(AVG(shoulder_to_wrist_cm), 1) as avg_shoulder_to_wrist_cm,\n",
    "        ROUND(AVG(elbow_to_wrist_cm), 1) as avg_elbow_to_wrist_cm\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"Total participants: {demographics[0]}\")\n",
    "print(f\"Age: mean={demographics[1]:.1f}, range={demographics[2]}-{demographics[3]}\")\n",
    "print(f\"Height: mean={demographics[4]} cm\")\n",
    "print(f\"Shoulder to wrist: mean={demographics[5]} cm\")\n",
    "print(f\"Elbow to wrist: mean={demographics[6]} cm\")\n",
    "\n",
    "# „Ç´„ÉÜ„Ç¥„É™Â§âÊï∞„ÅÆÂàÜÂ∏É\n",
    "print(\"\\nüè∑Ô∏è Categorical Demographics:\")\n",
    "categorical_demographics = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        'adult_child' as category,\n",
    "        CASE WHEN adult_child = 1 THEN 'Adult' ELSE 'Child' END as value,\n",
    "        COUNT(*) as count,\n",
    "        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics), 1) as percentage\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics\n",
    "    GROUP BY adult_child\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'sex',\n",
    "        CASE WHEN sex = 1 THEN 'Male' ELSE 'Female' END,\n",
    "        COUNT(*),\n",
    "        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics), 1)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics\n",
    "    GROUP BY sex\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'handedness',\n",
    "        CASE WHEN handedness = 1 THEN 'Right-handed' ELSE 'Left-handed' END,\n",
    "        COUNT(*),\n",
    "        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics), 1)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics\n",
    "    GROUP BY handedness\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(categorical_demographics.to_string(index=False))\n",
    "\n",
    "# ÂèÇÂä†ËÄÖÂà•„ÅÆË°åÂãï„Éë„Çø„Éº„É≥\n",
    "print(\"\\nüéØ Behavior Patterns by Participant:\")\n",
    "participant_behavior = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        t.subject,\n",
    "        d.age,\n",
    "        CASE WHEN d.sex = 1 THEN 'M' ELSE 'F' END as sex,\n",
    "        CASE WHEN d.handedness = 1 THEN 'R' ELSE 'L' END as handedness,\n",
    "        COUNT(DISTINCT t.sequence_id) as total_sequences,\n",
    "        COUNT(DISTINCT t.gesture) as unique_gestures,\n",
    "        COUNT(*) as total_timesteps,\n",
    "        ROUND(AVG(CASE WHEN t.sequence_type = 'Target' THEN 1.0 ELSE 0.0 END) * 100, 1) as target_percentage\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train t\n",
    "    JOIN \"cmi_detect_behavior_with_sensor_data\".train_demographics d ON t.subject = d.subject\n",
    "    GROUP BY t.subject, d.age, d.sex, d.handedness\n",
    "    ORDER BY total_sequences DESC\n",
    "    LIMIT 15\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(participant_behavior.to_string(index=False))\n",
    "\n",
    "# Âπ¥ÈΩ¢Áæ§Âà•„ÅÆË°åÂãïÂàÜÊûê\n",
    "print(\"\\nüìà Behavior Analysis by Age Group:\")\n",
    "age_behavior = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        CASE \n",
    "            WHEN d.age < 18 THEN 'Child (<18)'\n",
    "            WHEN d.age BETWEEN 18 AND 30 THEN 'Young Adult (18-30)'\n",
    "            WHEN d.age BETWEEN 31 AND 50 THEN 'Adult (31-50)'\n",
    "            ELSE 'Older Adult (>50)'\n",
    "        END as age_group,\n",
    "        COUNT(DISTINCT t.subject) as participants,\n",
    "        ROUND(AVG(sequence_count), 1) as avg_sequences,\n",
    "        ROUND(AVG(gesture_diversity), 1) as avg_gesture_diversity,\n",
    "        ROUND(AVG(target_rate) * 100, 1) as avg_target_rate\n",
    "    FROM (\n",
    "        SELECT \n",
    "            t.subject,\n",
    "            COUNT(DISTINCT t.sequence_id) as sequence_count,\n",
    "            COUNT(DISTINCT t.gesture) as gesture_diversity,\n",
    "            AVG(CASE WHEN t.sequence_type = 'Target' THEN 1.0 ELSE 0.0 END) as target_rate\n",
    "        FROM \"cmi_detect_behavior_with_sensor_data\".train t\n",
    "        GROUP BY t.subject\n",
    "    ) t\n",
    "    JOIN \"cmi_detect_behavior_with_sensor_data\".train_demographics d ON t.subject = d.subject\n",
    "    GROUP BY \n",
    "        CASE \n",
    "            WHEN d.age < 18 THEN 'Child (<18)'\n",
    "            WHEN d.age BETWEEN 18 AND 30 THEN 'Young Adult (18-30)'\n",
    "            WHEN d.age BETWEEN 31 AND 50 THEN 'Adult (31-50)'\n",
    "            ELSE 'Older Adult (>50)'\n",
    "        END\n",
    "    ORDER BY avg_sequences DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(age_behavior.to_string(index=False))\n",
    "\n",
    "# Âà©„ÅçÊâã„Å´„Çà„ÇãË°åÂãï„ÅÆÈÅï„ÅÑ\n",
    "print(\"\\n‚úã Handedness Impact on Behavior:\")\n",
    "handedness_behavior = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        CASE WHEN d.handedness = 1 THEN 'Right-handed' ELSE 'Left-handed' END as handedness,\n",
    "        COUNT(DISTINCT t.subject) as participants,\n",
    "        ROUND(AVG(sequence_count), 1) as avg_sequences,\n",
    "        ROUND(AVG(target_rate) * 100, 1) as avg_target_rate,\n",
    "        STRING_AGG(DISTINCT most_common_gesture, ', ') as common_gestures\n",
    "    FROM (\n",
    "        SELECT \n",
    "            t.subject,\n",
    "            COUNT(DISTINCT t.sequence_id) as sequence_count,\n",
    "            AVG(CASE WHEN t.sequence_type = 'Target' THEN 1.0 ELSE 0.0 END) as target_rate,\n",
    "            MODE() WITHIN GROUP (ORDER BY t.gesture) as most_common_gesture\n",
    "        FROM \"cmi_detect_behavior_with_sensor_data\".train t\n",
    "        GROUP BY t.subject\n",
    "    ) t\n",
    "    JOIN \"cmi_detect_behavior_with_sensor_data\".train_demographics d ON t.subject = d.subject\n",
    "    GROUP BY d.handedness\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(handedness_behavior.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "m6ukgyl75r",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç 5. MISSING DATA PATTERNS & QUALITY ASSESSMENT\n",
      "============================================================\n",
      "üìä Comprehensive Missing Data Analysis:\n",
      "     sensor_group sensor  total_rows  missing_count  missing_pct\n",
      "IMU_accelerometer  acc_x      574945              0         0.00\n",
      "IMU_accelerometer  acc_y      574945              0         0.00\n",
      "IMU_accelerometer  acc_z      574945              0         0.00\n",
      "     IMU_rotation  rot_w      574945           3692         0.64\n",
      "     IMU_rotation  rot_x      574945           3692         0.64\n",
      "     IMU_rotation  rot_y      574945           3692         0.64\n",
      "     IMU_rotation  rot_z      574945           3692         0.64\n",
      "       Thermopile  thm_1      574945           6987         1.22\n",
      "       Thermopile  thm_2      574945           7638         1.33\n",
      "       Thermopile  thm_3      574945           6472         1.13\n",
      "       Thermopile  thm_4      574945           6224         1.08\n",
      "       Thermopile  thm_5      574945          33286         5.79\n",
      "\n",
      "üì° ToF Sensor Missing Pattern (Sample):\n",
      "sensor_group   sensor  total_rows  missing_count  missing_pct\n",
      "         ToF tof_1_v0      574945           6224         1.08\n",
      "         ToF tof_2_v0      574945           6224         1.08\n",
      "         ToF tof_3_v0      574945           6224         1.08\n",
      "         ToF tof_4_v0      574945           6224         1.08\n",
      "         ToF tof_5_v0      574945          30142         5.24\n",
      "\n",
      "üîó Missing Value Co-occurrence Patterns:\n",
      "  thm5_status   tof5_status  count  percentage\n",
      "thm_5_present tof_5_present 541659       94.21\n",
      "thm_5_missing tof_5_missing  30142        5.24\n",
      "thm_5_missing tof_5_present   3144        0.55\n",
      "\n",
      "üë• Missing Data by Participant (Top 10 with most missing):\n",
      "    subject  total_rows  thm5_missing  tof5_missing  thm5_missing_pct  tof5_missing_pct\n",
      "SUBJ_044680        7618          7618          7618             100.0             100.0\n",
      "SUBJ_016552        6586          6586          6586             100.0             100.0\n",
      "SUBJ_011323        6589          6224          6224              94.5              94.5\n",
      "SUBJ_036450        6750          5988          5988              88.7              88.7\n",
      "SUBJ_036405        4310          2925          2925              67.9              67.9\n",
      "SUBJ_039498        6979          3144             0              45.0               0.0\n",
      "SUBJ_053217        4008           801           801              20.0              20.0\n",
      "\n",
      "üìã Data Quality Summary:\n",
      "Missing rate by sensor group:\n",
      "  IMU_accelerometer: avg=0.0%, max=0.0% üü¢ EXCELLENT\n",
      "  IMU_rotation: avg=0.64%, max=0.64% üü¢ EXCELLENT\n",
      "  Thermopile: avg=2.11%, max=5.79% üî¥ NEEDS ATTENTION\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 5. üîç Ê¨†Êêç„Éá„Éº„Çø„Éë„Çø„Éº„É≥„Å®ÂìÅË≥™Ë©ï‰æ°\n",
    "print(\"üîç 5. MISSING DATA PATTERNS & QUALITY ASSESSMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ÂÖ®„Çª„É≥„Çµ„Éº„ÅÆÊ¨†ÊêçÁéáÂàÜÊûê\n",
    "print(\"üìä Comprehensive Missing Data Analysis:\")\n",
    "missing_analysis = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        'IMU_accelerometer' as sensor_group,\n",
    "        'acc_x' as sensor,\n",
    "        COUNT(*) as total_rows,\n",
    "        COUNT(*) - COUNT(acc_x) as missing_count,\n",
    "        ROUND((COUNT(*) - COUNT(acc_x)) * 100.0 / COUNT(*), 2) as missing_pct\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL SELECT 'IMU_accelerometer', 'acc_y', COUNT(*), COUNT(*) - COUNT(acc_y), ROUND((COUNT(*) - COUNT(acc_y)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'IMU_accelerometer', 'acc_z', COUNT(*), COUNT(*) - COUNT(acc_z), ROUND((COUNT(*) - COUNT(acc_z)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'IMU_rotation', 'rot_w', COUNT(*), COUNT(*) - COUNT(rot_w), ROUND((COUNT(*) - COUNT(rot_w)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'IMU_rotation', 'rot_x', COUNT(*), COUNT(*) - COUNT(rot_x), ROUND((COUNT(*) - COUNT(rot_x)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'IMU_rotation', 'rot_y', COUNT(*), COUNT(*) - COUNT(rot_y), ROUND((COUNT(*) - COUNT(rot_y)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'IMU_rotation', 'rot_z', COUNT(*), COUNT(*) - COUNT(rot_z), ROUND((COUNT(*) - COUNT(rot_z)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'Thermopile', 'thm_1', COUNT(*), COUNT(*) - COUNT(thm_1), ROUND((COUNT(*) - COUNT(thm_1)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'Thermopile', 'thm_2', COUNT(*), COUNT(*) - COUNT(thm_2), ROUND((COUNT(*) - COUNT(thm_2)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'Thermopile', 'thm_3', COUNT(*), COUNT(*) - COUNT(thm_3), ROUND((COUNT(*) - COUNT(thm_3)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'Thermopile', 'thm_4', COUNT(*), COUNT(*) - COUNT(thm_4), ROUND((COUNT(*) - COUNT(thm_4)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'Thermopile', 'thm_5', COUNT(*), COUNT(*) - COUNT(thm_5), ROUND((COUNT(*) - COUNT(thm_5)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(missing_analysis.to_string(index=False))\n",
    "\n",
    "# ToF„Çª„É≥„Çµ„Éº„ÅÆÊ¨†Êêç„Éë„Çø„Éº„É≥Ôºà„Çµ„É≥„Éó„É™„É≥„Ç∞Ôºâ\n",
    "print(\"\\nüì° ToF Sensor Missing Pattern (Sample):\")\n",
    "tof_missing = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        'ToF' as sensor_group,\n",
    "        'tof_1_v0' as sensor,\n",
    "        COUNT(*) as total_rows,\n",
    "        COUNT(*) - COUNT(tof_1_v0) as missing_count,\n",
    "        ROUND((COUNT(*) - COUNT(tof_1_v0)) * 100.0 / COUNT(*), 2) as missing_pct\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL SELECT 'ToF', 'tof_2_v0', COUNT(*), COUNT(*) - COUNT(tof_2_v0), ROUND((COUNT(*) - COUNT(tof_2_v0)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'ToF', 'tof_3_v0', COUNT(*), COUNT(*) - COUNT(tof_3_v0), ROUND((COUNT(*) - COUNT(tof_3_v0)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'ToF', 'tof_4_v0', COUNT(*), COUNT(*) - COUNT(tof_4_v0), ROUND((COUNT(*) - COUNT(tof_4_v0)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    UNION ALL SELECT 'ToF', 'tof_5_v0', COUNT(*), COUNT(*) - COUNT(tof_5_v0), ROUND((COUNT(*) - COUNT(tof_5_v0)) * 100.0 / COUNT(*), 2) FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(tof_missing.to_string(index=False))\n",
    "\n",
    "# Ê¨†ÊêçÂÄ§„ÅÆÂÖ±Ëµ∑„Éë„Çø„Éº„É≥ÂàÜÊûê\n",
    "print(\"\\nüîó Missing Value Co-occurrence Patterns:\")\n",
    "missing_cooccurrence = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        CASE WHEN thm_5 IS NULL THEN 'thm_5_missing' ELSE 'thm_5_present' END as thm5_status,\n",
    "        CASE WHEN tof_5_v0 IS NULL THEN 'tof_5_missing' ELSE 'tof_5_present' END as tof5_status,\n",
    "        COUNT(*) as count,\n",
    "        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train), 2) as percentage\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY \n",
    "        CASE WHEN thm_5 IS NULL THEN 'thm_5_missing' ELSE 'thm_5_present' END,\n",
    "        CASE WHEN tof_5_v0 IS NULL THEN 'tof_5_missing' ELSE 'tof_5_present' END\n",
    "    ORDER BY count DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(missing_cooccurrence.to_string(index=False))\n",
    "\n",
    "# ÂèÇÂä†ËÄÖÂà•„ÅÆÊ¨†Êêç„Éë„Çø„Éº„É≥\n",
    "print(\"\\nüë• Missing Data by Participant (Top 10 with most missing):\")\n",
    "participant_missing = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        subject,\n",
    "        COUNT(*) as total_rows,\n",
    "        COUNT(*) - COUNT(thm_5) as thm5_missing,\n",
    "        COUNT(*) - COUNT(tof_5_v0) as tof5_missing,\n",
    "        ROUND((COUNT(*) - COUNT(thm_5)) * 100.0 / COUNT(*), 1) as thm5_missing_pct,\n",
    "        ROUND((COUNT(*) - COUNT(tof_5_v0)) * 100.0 / COUNT(*), 1) as tof5_missing_pct\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY subject\n",
    "    HAVING (COUNT(*) - COUNT(thm_5)) > 0 OR (COUNT(*) - COUNT(tof_5_v0)) > 0\n",
    "    ORDER BY thm5_missing_pct DESC, tof5_missing_pct DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(participant_missing.to_string(index=False))\n",
    "\n",
    "# „Éá„Éº„ÇøÂìÅË≥™„Çµ„Éû„É™„Éº\n",
    "print(\"\\nüìã Data Quality Summary:\")\n",
    "quality_metrics = missing_analysis.groupby('sensor_group')['missing_pct'].agg(['mean', 'max']).round(2)\n",
    "print(\"Missing rate by sensor group:\")\n",
    "for group in quality_metrics.index:\n",
    "    mean_missing = quality_metrics.loc[group, 'mean']\n",
    "    max_missing = quality_metrics.loc[group, 'max']\n",
    "    status = \"üü¢ EXCELLENT\" if max_missing < 1 else \"üü° GOOD\" if max_missing < 5 else \"üî¥ NEEDS ATTENTION\"\n",
    "    print(f\"  {group}: avg={mean_missing}%, max={max_missing}% {status}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "wkpu64m5bs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è 4. TIME SERIES PATTERNS & SEQUENCE STRUCTURE ANALYSIS\n",
      "============================================================\n",
      "üìè Sequence Length Analysis:\n",
      "Total sequences: 8,151\n",
      "Length stats: mean=70.5, std=35.4\n",
      "Length range: 29 - 700 timesteps\n",
      "Quartiles: Q1=51.0, Q2=59.0, Q3=78.0\n",
      "95th percentile: 127.0 timesteps\n",
      "\n",
      "‚è±Ô∏è Time Duration (assuming 50Hz sampling):\n",
      "  ‚Ä¢ Average sequence duration: 1.41 seconds\n",
      "  ‚Ä¢ Median sequence duration: 1.18 seconds\n",
      "  ‚Ä¢ Longest sequence duration: 14.0 seconds\n",
      "\n",
      "üìä Sequence Length by Gesture Type:\n",
      "                                   gesture  num_sequences  avg_length  min_length  max_length\n",
      "Feel around in tray and pull out an object            161       106.3          50         322\n",
      "                             Text on phone            640        91.3          29         390\n",
      "                            Neck - scratch            640        88.5          41         700\n",
      "                            Glasses on/off            161        84.1          43         293\n",
      "                     Drink from bottle/cup            161        81.3          34         176\n",
      "                     Scratch knee/leg skin            161        76.6          42         229\n",
      "                                Wave hello            478        71.9          34         230\n",
      "                       Eyebrow - pull hair            638        69.4          34         371\n",
      "                         Write name in air            477        65.5          39         374\n",
      "                 Pull air toward your face            477        64.5          36         188\n",
      "\n",
      "üë• Sequence Count per Participant:\n",
      "Participants: 81\n",
      "Sequences per participant: mean=100.6, std=7.8\n",
      "Sequence range per participant: 51 - 102\n",
      "\n",
      "üîó Sequence Continuity Check:\n",
      "‚úÖ All sequences are continuous (no missing timesteps)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 4. ‚è±Ô∏è ÊôÇÁ≥ªÂàó„Éë„Çø„Éº„É≥„Å®ÊßãÈÄ†ÂàÜÊûê\n",
    "print(\"‚è±Ô∏è 4. TIME SERIES PATTERNS & SEQUENCE STRUCTURE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# „Ç∑„Éº„Ç±„É≥„ÇπÈï∑„ÅÆË©≥Á¥∞ÂàÜÊûê\n",
    "print(\"üìè Sequence Length Analysis:\")\n",
    "sequence_lengths = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(DISTINCT sequence_id) as total_sequences,\n",
    "        ROUND(AVG(length), 1) as avg_length,\n",
    "        ROUND(STDDEV(length), 1) as std_length,\n",
    "        MIN(length) as min_length,\n",
    "        MAX(length) as max_length,\n",
    "        ROUND(PERCENTILE_CONT(0.25) WITHIN GROUP (ORDER BY length), 1) as q25,\n",
    "        ROUND(PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY length), 1) as median,\n",
    "        ROUND(PERCENTILE_CONT(0.75) WITHIN GROUP (ORDER BY length), 1) as q75,\n",
    "        ROUND(PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY length), 1) as p95\n",
    "    FROM (\n",
    "        SELECT sequence_id, COUNT(*) as length\n",
    "        FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "        GROUP BY sequence_id\n",
    "    )\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"Total sequences: {sequence_lengths[0]:,}\")\n",
    "print(f\"Length stats: mean={sequence_lengths[1]}, std={sequence_lengths[2]}\")\n",
    "print(f\"Length range: {sequence_lengths[3]} - {sequence_lengths[4]} timesteps\")\n",
    "print(f\"Quartiles: Q1={sequence_lengths[5]}, Q2={sequence_lengths[6]}, Q3={sequence_lengths[7]}\")\n",
    "print(f\"95th percentile: {sequence_lengths[8]} timesteps\")\n",
    "\n",
    "# 50HzÂâçÊèê„Åß„ÅÆÊôÇÈñìË®àÁÆó\n",
    "print(f\"\\n‚è±Ô∏è Time Duration (assuming 50Hz sampling):\")\n",
    "print(f\"  ‚Ä¢ Average sequence duration: {sequence_lengths[1]/50:.2f} seconds\")\n",
    "print(f\"  ‚Ä¢ Median sequence duration: {sequence_lengths[6]/50:.2f} seconds\")\n",
    "print(f\"  ‚Ä¢ Longest sequence duration: {sequence_lengths[4]/50:.1f} seconds\")\n",
    "\n",
    "# „Ç∏„Çß„Çπ„ÉÅ„É£„ÉºÂà•„ÅÆ„Ç∑„Éº„Ç±„É≥„ÇπÈï∑ÂàÜÊûê\n",
    "print(\"\\nüìä Sequence Length by Gesture Type:\")\n",
    "gesture_lengths = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        gesture,\n",
    "        COUNT(DISTINCT sequence_id) as num_sequences,\n",
    "        ROUND(AVG(length), 1) as avg_length,\n",
    "        ROUND(MIN(length), 1) as min_length,\n",
    "        ROUND(MAX(length), 1) as max_length\n",
    "    FROM (\n",
    "        SELECT \n",
    "            sequence_id, \n",
    "            gesture,\n",
    "            COUNT(*) as length\n",
    "        FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "        GROUP BY sequence_id, gesture\n",
    "    )\n",
    "    GROUP BY gesture\n",
    "    ORDER BY avg_length DESC\n",
    "    LIMIT 10\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(gesture_lengths.to_string(index=False))\n",
    "\n",
    "# ÂèÇÂä†ËÄÖÂà•„ÅÆ„Ç∑„Éº„Ç±„É≥„ÇπÊï∞ÂàÜÊûê\n",
    "print(\"\\nüë• Sequence Count per Participant:\")\n",
    "participant_sequences = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(DISTINCT subject) as total_participants,\n",
    "        ROUND(AVG(seq_count), 1) as avg_sequences_per_participant,\n",
    "        MIN(seq_count) as min_sequences,\n",
    "        MAX(seq_count) as max_sequences,\n",
    "        ROUND(STDDEV(seq_count), 1) as std_sequences\n",
    "    FROM (\n",
    "        SELECT \n",
    "            subject, \n",
    "            COUNT(DISTINCT sequence_id) as seq_count\n",
    "        FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "        GROUP BY subject\n",
    "    )\n",
    "\"\"\").fetchone()\n",
    "\n",
    "print(f\"Participants: {participant_sequences[0]}\")\n",
    "print(f\"Sequences per participant: mean={participant_sequences[1]}, std={participant_sequences[4]}\")\n",
    "print(f\"Sequence range per participant: {participant_sequences[2]} - {participant_sequences[3]}\")\n",
    "\n",
    "# ÊôÇÁ≥ªÂàó„ÅÆÈÄ£Á∂öÊÄß„ÉÅ„Çß„ÉÉ„ÇØ\n",
    "print(\"\\nüîó Sequence Continuity Check:\")\n",
    "continuity_check = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(*) as total_gaps,\n",
    "        AVG(gap_size) as avg_gap_size,\n",
    "        MAX(gap_size) as max_gap_size\n",
    "    FROM (\n",
    "        SELECT \n",
    "            sequence_id,\n",
    "            sequence_counter - LAG(sequence_counter) OVER (PARTITION BY sequence_id ORDER BY sequence_counter) as gap_size\n",
    "        FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    )\n",
    "    WHERE gap_size > 1\n",
    "\"\"\").fetchone()\n",
    "\n",
    "if continuity_check[0] > 0:\n",
    "    print(f\"‚ö†Ô∏è  Found {continuity_check[0]} gaps in sequences\")\n",
    "    print(f\"   Average gap size: {continuity_check[1]:.1f}\")\n",
    "    print(f\"   Maximum gap size: {continuity_check[2]}\")\n",
    "else:\n",
    "    print(\"‚úÖ All sequences are continuous (no missing timesteps)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77z2wz6xjop",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ 3. TARGET VARIABLE CORRELATION & CLASS BALANCE ANALYSIS\n",
      "============================================================\n",
      "üîÑ Gesture vs Sequence Type Relationship:\n",
      "                                   gesture sequence_type  count  percentage\n",
      "                             Text on phone    Non-Target  58462       10.17\n",
      "                            Neck - scratch        Target  56619        9.85\n",
      "                       Eyebrow - pull hair        Target  44305        7.71\n",
      "                        Forehead - scratch        Target  40923        7.12\n",
      "                  Forehead - pull hairline        Target  40802        7.10\n",
      "                     Above ear - pull hair        Target  40560        7.05\n",
      "                         Neck - pinch skin        Target  40507        7.05\n",
      "                       Eyelash - pull hair        Target  40218        7.00\n",
      "                        Cheek - pinch skin        Target  40124        6.98\n",
      "                                Wave hello    Non-Target  34356        5.98\n",
      "                         Write name in air    Non-Target  31267        5.44\n",
      "                 Pull air toward your face    Non-Target  30743        5.35\n",
      "Feel around in tray and pull out an object    Non-Target  17114        2.98\n",
      "                            Glasses on/off    Non-Target  13542        2.36\n",
      "                     Drink from bottle/cup    Non-Target  13093        2.28\n",
      "\n",
      "üìä Behavior Phase Distribution by Gesture (Top 5):\n",
      "                 gesture                                  behavior  count  avg_timestamp\n",
      "     Eyebrow - pull hair                          Performs gesture  19549           53.9\n",
      "     Eyebrow - pull hair             Moves hand to target location  13295           41.1\n",
      "     Eyebrow - pull hair                   Hand at target location   6709           45.6\n",
      "     Eyebrow - pull hair Relaxes and moves hand to target location   4752            7.8\n",
      "Forehead - pull hairline                          Performs gesture  19862           48.4\n",
      "Forehead - pull hairline             Moves hand to target location   9114           18.9\n",
      "Forehead - pull hairline                   Hand at target location   7048           32.7\n",
      "Forehead - pull hairline Relaxes and moves hand to target location   4778            7.5\n",
      "      Forehead - scratch                          Performs gesture  19953           48.3\n",
      "      Forehead - scratch             Moves hand to target location   9219           22.1\n",
      "      Forehead - scratch                   Hand at target location   6947           32.7\n",
      "      Forehead - scratch Relaxes and moves hand to target location   4804            7.8\n",
      "          Neck - scratch             Moves hand to target location  23501           91.1\n",
      "          Neck - scratch                          Performs gesture  20008           73.1\n",
      "          Neck - scratch                   Hand at target location   7909           68.7\n",
      "          Neck - scratch Relaxes and moves hand to target location   5201            9.1\n",
      "           Text on phone             Moves hand to target location  21120           50.4\n",
      "           Text on phone                          Performs gesture  21066           75.2\n",
      "           Text on phone Relaxes and moves hand to target location   8917           15.0\n",
      "           Text on phone                   Hand at target location   7359           62.6\n",
      "\n",
      "‚öñÔ∏è Class Imbalance Analysis:\n",
      "Binary Classification (sequence_type):\n",
      "sequence_type  count  percentage\n",
      "       Target 344058       59.84\n",
      "   Non-Target 230887       40.16\n",
      "\n",
      "Multi-class Gesture Distribution (18 classes):\n",
      "                                   gesture  count  percentage  participants\n",
      "                             Text on phone  58462       10.17            81\n",
      "                            Neck - scratch  56619        9.85            81\n",
      "                       Eyebrow - pull hair  44305        7.71            81\n",
      "                        Forehead - scratch  40923        7.12            81\n",
      "                  Forehead - pull hairline  40802        7.10            81\n",
      "                     Above ear - pull hair  40560        7.05            81\n",
      "                         Neck - pinch skin  40507        7.05            81\n",
      "                       Eyelash - pull hair  40218        7.00            81\n",
      "                        Cheek - pinch skin  40124        6.98            81\n",
      "                                Wave hello  34356        5.98            81\n",
      "                         Write name in air  31267        5.44            81\n",
      "                 Pull air toward your face  30743        5.35            81\n",
      "Feel around in tray and pull out an object  17114        2.98            81\n",
      "                            Glasses on/off  13542        2.36            81\n",
      "                     Drink from bottle/cup  13093        2.28            81\n",
      "                     Scratch knee/leg skin  12328        2.14            81\n",
      "                         Write name on leg  10138        1.76            81\n",
      "                       Pinch knee/leg skin   9844        1.71            81\n",
      "\n",
      "üìà Class Imbalance Metrics:\n",
      "  ‚Ä¢ Most frequent gesture: Text on phone (58,462 samples)\n",
      "  ‚Ä¢ Least frequent gesture: Pinch knee/leg skin (9,844 samples)\n",
      "  ‚Ä¢ Imbalance ratio: 5.9:1\n",
      "  ‚Ä¢ Macro F1 challenge level: MEDIUM\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 3. üéØ „Çø„Éº„Ç≤„ÉÉ„ÉàÂ§âÊï∞„ÅÆË©≥Á¥∞ÂàÜÊûê\n",
    "print(\"üéØ 3. TARGET VARIABLE CORRELATION & CLASS BALANCE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# „Ç∏„Çß„Çπ„ÉÅ„É£„Éº„Å®sequence_type„ÅÆÈñ¢‰øÇ\n",
    "print(\"üîÑ Gesture vs Sequence Type Relationship:\")\n",
    "gesture_sequence_type = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        gesture,\n",
    "        sequence_type,\n",
    "        COUNT(*) as count,\n",
    "        ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as percentage\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY gesture, sequence_type\n",
    "    ORDER BY count DESC\n",
    "    LIMIT 15\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(gesture_sequence_type.to_string(index=False))\n",
    "\n",
    "# Ë°åÂãï„Éï„Çß„Éº„Ç∫„ÅÆË©≥Á¥∞ÂàÜÊûê\n",
    "print(\"\\nüìä Behavior Phase Distribution by Gesture (Top 5):\")\n",
    "behavior_phase = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        gesture,\n",
    "        behavior,\n",
    "        COUNT(*) as count,\n",
    "        ROUND(AVG(sequence_counter), 1) as avg_timestamp\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE gesture IN (\n",
    "        SELECT gesture \n",
    "        FROM \"cmi_detect_behavior_with_sensor_data\".train \n",
    "        GROUP BY gesture \n",
    "        ORDER BY COUNT(*) DESC \n",
    "        LIMIT 5\n",
    "    )\n",
    "    GROUP BY gesture, behavior\n",
    "    ORDER BY gesture, count DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(behavior_phase.to_string(index=False))\n",
    "\n",
    "# „ÇØ„É©„Çπ‰∏çÂùáË°°„ÅÆË©≥Á¥∞Ë©ï‰æ°\n",
    "print(\"\\n‚öñÔ∏è Class Imbalance Analysis:\")\n",
    "\n",
    "# Binary classification (sequence_type)\n",
    "binary_balance = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        sequence_type,\n",
    "        COUNT(*) as count,\n",
    "        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train), 2) as percentage\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY sequence_type\n",
    "    ORDER BY count DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(\"Binary Classification (sequence_type):\")\n",
    "print(binary_balance.to_string(index=False))\n",
    "\n",
    "# Multi-class gesture distribution\n",
    "gesture_balance = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        gesture,\n",
    "        COUNT(*) as count,\n",
    "        ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train), 2) as percentage,\n",
    "        COUNT(DISTINCT subject) as participants\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    GROUP BY gesture\n",
    "    ORDER BY count DESC\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(f\"\\nMulti-class Gesture Distribution (18 classes):\")\n",
    "print(gesture_balance.to_string(index=False))\n",
    "\n",
    "# ‰∏çÂùáË°°ÊØîÁéá„ÅÆË®àÁÆó\n",
    "max_class = gesture_balance['count'].max()\n",
    "min_class = gesture_balance['count'].min()\n",
    "imbalance_ratio = max_class / min_class\n",
    "\n",
    "print(f\"\\nüìà Class Imbalance Metrics:\")\n",
    "print(f\"  ‚Ä¢ Most frequent gesture: {gesture_balance.iloc[0]['gesture']} ({gesture_balance.iloc[0]['count']:,} samples)\")\n",
    "print(f\"  ‚Ä¢ Least frequent gesture: {gesture_balance.iloc[-1]['gesture']} ({gesture_balance.iloc[-1]['count']:,} samples)\")\n",
    "print(f\"  ‚Ä¢ Imbalance ratio: {imbalance_ratio:.1f}:1\")\n",
    "print(f\"  ‚Ä¢ Macro F1 challenge level: {'HIGH' if imbalance_ratio > 10 else 'MEDIUM' if imbalance_ratio > 3 else 'LOW'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nj20rd5q4hp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç 2. SENSOR DATA DISTRIBUTION ANALYSIS\n",
      "============================================================\n",
      "üéØ IMU Sensor Statistics:\n",
      "sensor  null_count  mean_val  std_val  min_val  max_val  median_val\n",
      " acc_x           0    1.6400   5.7813 -34.5859  46.3281      2.9727\n",
      " acc_y           0    1.7907   5.0039 -24.4023  27.1836      0.6953\n",
      " acc_z           0   -0.4598   6.0965 -42.8555  30.0781     -1.5625\n",
      "\n",
      "üîÑ Rotation Quaternion Statistics:\n",
      "sensor  null_count  mean_val  std_val  min_val  max_val\n",
      " rot_w           0    0.3604   0.2257   0.0000   0.9994\n",
      " rot_x           0   -0.1199   0.4655  -0.9991   0.9998\n",
      " rot_y           0   -0.0600   0.5430  -0.9997   0.9995\n",
      " rot_z           0   -0.1883   0.5041  -0.9982   0.9999\n",
      "\n",
      "üå°Ô∏è Thermopile Sensor Statistics:\n",
      "sensor  null_count  mean_val  std_val  min_val  max_val\n",
      " thm_1           0     27.08     3.23    -0.37    38.46\n",
      " thm_2           0     27.13     2.94    21.96    37.58\n",
      " thm_3           0     26.70     4.12     0.00    37.29\n",
      " thm_4           0     27.56     2.25    22.38    39.59\n",
      " thm_5           0     26.67     2.44    22.05    37.68\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 2. üîç „Çª„É≥„Çµ„Éº„Éá„Éº„ÇøÂàÜÂ∏ÉÂàÜÊûê\n",
    "print(\"üîç 2. SENSOR DATA DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# IMU„Çª„É≥„Çµ„Éº„ÅÆÂü∫Êú¨Áµ±Ë®àÈáè\n",
    "print(\"üéØ IMU Sensor Statistics:\")\n",
    "imu_stats = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        'acc_x' as sensor,\n",
    "        COUNT(*) - COUNT(acc_x) as null_count,\n",
    "        ROUND(AVG(acc_x), 4) as mean_val,\n",
    "        ROUND(STDDEV(acc_x), 4) as std_val,\n",
    "        ROUND(MIN(acc_x), 4) as min_val,\n",
    "        ROUND(MAX(acc_x), 4) as max_val,\n",
    "        ROUND(PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY acc_x), 4) as median_val\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE acc_x IS NOT NULL\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'acc_y',\n",
    "        COUNT(*) - COUNT(acc_y),\n",
    "        ROUND(AVG(acc_y), 4),\n",
    "        ROUND(STDDEV(acc_y), 4),\n",
    "        ROUND(MIN(acc_y), 4),\n",
    "        ROUND(MAX(acc_y), 4),\n",
    "        ROUND(PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY acc_y), 4)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE acc_y IS NOT NULL\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'acc_z',\n",
    "        COUNT(*) - COUNT(acc_z),\n",
    "        ROUND(AVG(acc_z), 4),\n",
    "        ROUND(STDDEV(acc_z), 4),\n",
    "        ROUND(MIN(acc_z), 4),\n",
    "        ROUND(MAX(acc_z), 4),\n",
    "        ROUND(PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY acc_z), 4)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE acc_z IS NOT NULL\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(imu_stats.to_string(index=False))\n",
    "\n",
    "# ÂõûËª¢„Çª„É≥„Çµ„ÉºÔºà„ÇØ„Ç©„Éº„Çø„Éã„Ç™„É≥Ôºâ„ÅÆÁµ±Ë®àÈáè\n",
    "print(\"\\nüîÑ Rotation Quaternion Statistics:\")\n",
    "rot_stats = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        'rot_w' as sensor,\n",
    "        COUNT(*) - COUNT(rot_w) as null_count,\n",
    "        ROUND(AVG(rot_w), 4) as mean_val,\n",
    "        ROUND(STDDEV(rot_w), 4) as std_val,\n",
    "        ROUND(MIN(rot_w), 4) as min_val,\n",
    "        ROUND(MAX(rot_w), 4) as max_val\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE rot_w IS NOT NULL\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT 'rot_x', COUNT(*) - COUNT(rot_x), ROUND(AVG(rot_x), 4), ROUND(STDDEV(rot_x), 4), ROUND(MIN(rot_x), 4), ROUND(MAX(rot_x), 4)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE rot_x IS NOT NULL\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT 'rot_y', COUNT(*) - COUNT(rot_y), ROUND(AVG(rot_y), 4), ROUND(STDDEV(rot_y), 4), ROUND(MIN(rot_y), 4), ROUND(MAX(rot_y), 4)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE rot_y IS NOT NULL\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT 'rot_z', COUNT(*) - COUNT(rot_z), ROUND(AVG(rot_z), 4), ROUND(STDDEV(rot_z), 4), ROUND(MIN(rot_z), 4), ROUND(MAX(rot_z), 4)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE rot_z IS NOT NULL\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(rot_stats.to_string(index=False))\n",
    "\n",
    "# Ê∏©Â∫¶„Çª„É≥„Çµ„Éº„ÅÆÁµ±Ë®àÈáè\n",
    "print(\"\\nüå°Ô∏è Thermopile Sensor Statistics:\")\n",
    "thm_stats = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        'thm_1' as sensor,\n",
    "        COUNT(*) - COUNT(thm_1) as null_count,\n",
    "        ROUND(AVG(thm_1), 2) as mean_val,\n",
    "        ROUND(STDDEV(thm_1), 2) as std_val,\n",
    "        ROUND(MIN(thm_1), 2) as min_val,\n",
    "        ROUND(MAX(thm_1), 2) as max_val\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    WHERE thm_1 IS NOT NULL\n",
    "    \n",
    "    UNION ALL SELECT 'thm_2', COUNT(*) - COUNT(thm_2), ROUND(AVG(thm_2), 2), ROUND(STDDEV(thm_2), 2), ROUND(MIN(thm_2), 2), ROUND(MAX(thm_2), 2)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE thm_2 IS NOT NULL\n",
    "    UNION ALL SELECT 'thm_3', COUNT(*) - COUNT(thm_3), ROUND(AVG(thm_3), 2), ROUND(STDDEV(thm_3), 2), ROUND(MIN(thm_3), 2), ROUND(MAX(thm_3), 2)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE thm_3 IS NOT NULL\n",
    "    UNION ALL SELECT 'thm_4', COUNT(*) - COUNT(thm_4), ROUND(AVG(thm_4), 2), ROUND(STDDEV(thm_4), 2), ROUND(MIN(thm_4), 2), ROUND(MAX(thm_4), 2)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE thm_4 IS NOT NULL\n",
    "    UNION ALL SELECT 'thm_5', COUNT(*) - COUNT(thm_5), ROUND(AVG(thm_5), 2), ROUND(STDDEV(thm_5), 2), ROUND(MIN(thm_5), 2), ROUND(MAX(thm_5), 2)\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train WHERE thm_5 IS NOT NULL\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(thm_stats.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dsndjmnwye4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç 1. COMPREHENSIVE DATA PROFILING\n",
      "============================================================\n",
      "üìã Dataset Structure:\n",
      "table_name  total_rows  unique_participants  unique_sequences  min_counter  max_counter\n",
      "     train      574945                   81              8151            0          699\n",
      "      test         107                    2                 2            0           55\n",
      "\n",
      "üßÆ Column Data Types and Non-null Counts:\n",
      "Total columns: 341\n",
      "  üìù Categorical columns: 8\n",
      "  üî¢ Sensor columns: 333\n",
      "    üéØ IMU sensors: 7 (['acc_x', 'acc_y', 'acc_z', 'rot_w', 'rot_x', 'rot_y', 'rot_z'])\n",
      "    üå°Ô∏è  Thermopile sensors: 5 (['thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5'])\n",
      "    üì° ToF sensors: 320 (5 sensors √ó 64 channels)\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 1. üìä ÂåÖÊã¨ÁöÑ„Éá„Éº„Çø„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞\n",
    "print(\"üîç 1. COMPREHENSIVE DATA PROFILING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Âü∫Êú¨„Éá„Éº„ÇøÊßãÈÄ†„ÅÆÁ¢∫Ë™ç\n",
    "print(\"üìã Dataset Structure:\")\n",
    "structure_info = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        'train' as table_name,\n",
    "        COUNT(*) as total_rows,\n",
    "        COUNT(DISTINCT subject) as unique_participants,\n",
    "        COUNT(DISTINCT sequence_id) as unique_sequences,\n",
    "        MIN(sequence_counter) as min_counter,\n",
    "        MAX(sequence_counter) as max_counter\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".train\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT \n",
    "        'test' as table_name,\n",
    "        COUNT(*) as total_rows,\n",
    "        COUNT(DISTINCT subject) as unique_participants,\n",
    "        COUNT(DISTINCT sequence_id) as unique_sequences,\n",
    "        MIN(sequence_counter) as min_counter,\n",
    "        MAX(sequence_counter) as max_counter\n",
    "    FROM \"cmi_detect_behavior_with_sensor_data\".test\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(structure_info.to_string(index=False))\n",
    "\n",
    "# „Éá„Éº„ÇøÂûã„Å®ÈùûNULLÂÄ§„ÅÆË©≥Á¥∞Á¢∫Ë™ç\n",
    "print(\"\\nüßÆ Column Data Types and Non-null Counts:\")\n",
    "column_info = conn.execute(\"\"\"\n",
    "    SELECT \n",
    "        column_name,\n",
    "        data_type,\n",
    "        is_nullable\n",
    "    FROM information_schema.columns \n",
    "    WHERE table_schema = 'cmi_detect_behavior_with_sensor_data' \n",
    "    AND table_name = 'train'\n",
    "    ORDER BY ordinal_position\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "print(f\"Total columns: {len(column_info)}\")\n",
    "\n",
    "# „Ç´„ÉÜ„Ç¥„É™Âà•„ÅÆÂàóÊï∞\n",
    "categorical_cols = ['row_id', 'sequence_type', 'sequence_id', 'subject', 'orientation', 'behavior', 'phase', 'gesture']\n",
    "sensor_cols = [col for col in column_info['column_name'] if col not in categorical_cols]\n",
    "\n",
    "print(f\"  üìù Categorical columns: {len(categorical_cols)}\")\n",
    "print(f\"  üî¢ Sensor columns: {len(sensor_cols)}\")\n",
    "\n",
    "# „Çª„É≥„Çµ„ÉºÂà•ÂàÜÈ°û\n",
    "imu_cols = [col for col in sensor_cols if col.startswith(('acc_', 'rot_'))]\n",
    "thermopile_cols = [col for col in sensor_cols if col.startswith('thm_')]\n",
    "tof_cols = [col for col in sensor_cols if col.startswith('tof_')]\n",
    "\n",
    "print(f\"    üéØ IMU sensors: {len(imu_cols)} ({imu_cols})\")\n",
    "print(f\"    üå°Ô∏è  Thermopile sensors: {len(thermopile_cols)} ({thermopile_cols})\")\n",
    "print(f\"    üì° ToF sensors: {len(tof_cols)} (5 sensors √ó 64 channels)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tbbteeni3z",
   "metadata": {},
   "source": [
    "# üß† CMI BFRB Detection - Êú¨Ê†ºÁöÑEDA\n",
    "\n",
    "## üìã ÂàÜÊûê„Éó„É©„É≥\n",
    "\n",
    "### üéØ ÁõÆÊ®ô\n",
    "- **„Ç≥„É≥„ÉöÊ¶ÇË¶Å**: Body-Focused Repetitive Behaviors (BFRB) Ê§úÂá∫\n",
    "- **Ë©ï‰æ°ÊåáÊ®ô**: 0.5√ó(Binary F1 + Macro F1) \n",
    "- **„Éá„Éº„Çø**: „Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´„Çª„É≥„Çµ„ÉºÊôÇÁ≥ªÂàó„Éá„Éº„Çø (50Hz)\n",
    "- **ÂèÇÂä†ËÄÖ**: 81Âêç„ÅÆË®ìÁ∑¥„Éá„Éº„Çø„ÄÅ18Á®ÆÈ°û„ÅÆ„Ç∏„Çß„Çπ„ÉÅ„É£„Éº\n",
    "\n",
    "### üìä Ë©≥Á¥∞ÂàÜÊûêÈ†ÖÁõÆ\n",
    "1. **„Éá„Éº„Çø„Éó„É≠„Éï„Ç°„Ç§„É™„É≥„Ç∞** - Âü∫Êú¨Áµ±Ë®àÈáè„Å®ÂìÅË≥™Ë©ï‰æ°\n",
    "2. **„Çª„É≥„Çµ„Éº„Éá„Éº„ÇøÂàÜÊûê** - ÂàÜÂ∏É„ÄÅÂ§ñ„ÇåÂÄ§„ÄÅ„Éé„Ç§„Ç∫ÁâπÊÄß\n",
    "3. **„Çø„Éº„Ç≤„ÉÉ„ÉàÂ§âÊï∞ÂàÜÊûê** - „ÇØ„É©„Çπ‰∏çÂùáË°°„ÄÅÁõ∏Èñ¢Èñ¢‰øÇ\n",
    "4. **ÊôÇÁ≥ªÂàó„Éë„Çø„Éº„É≥ÂàÜÊûê** - „Ç∑„Éº„Ç±„É≥„ÇπÊßãÈÄ†„ÄÅÂë®ÊúüÊÄß\n",
    "5. **Ê¨†ÊêçÂÄ§„Éë„Çø„Éº„É≥** - „Çª„É≥„Çµ„ÉºÊïÖÈöú„ÄÅ„Éá„Éº„ÇøÂìÅË≥™\n",
    "6. **ÂèÇÂä†ËÄÖÁâπÊÄßÂàÜÊûê** - ‰∫∫Âè£Áµ±Ë®àÂ≠¶ÁöÑÁâπÂæ¥\n",
    "7. **ÁâπÂæ¥Áõ∏Èñ¢ÂàÜÊûê** - „Éû„É´„ÉÅ„Ç≥„É™„Éã„Ç¢„É™„ÉÜ„Ç£„ÄÅÁâπÂæ¥ÈÅ∏Êäû\n",
    "8. **„Éû„É´„ÉÅ„É¢„Éº„ÉÄ„É´ÂàÜÊûê** - „Çª„É≥„Çµ„ÉºËûçÂêà„ÅÆÂèØËÉΩÊÄß\n",
    "9. **CVÊà¶Áï•Ê§úË®º** - „Éá„Éº„Çø„É™„Éº„ÇØÈò≤Ê≠¢Á≠ñ\n",
    "10. **ÁâπÂæ¥Â∑•Â≠¶ÊèêÊ°à** - „Éâ„É°„Ç§„É≥Áü•Ë≠òÊ¥ªÁî®\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ygt0djc9auc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DEBUG DATABASE TABLES ===\n",
      "Connection status: <duckdb.duckdb.DuckDBPyConnection object at 0x7f1a9af49870>\n",
      "\n",
      "=== ALL SCHEMAS ===\n",
      "  - cmi_detect_behavior_with_sensor_data\n",
      "  - main\n",
      "  - playground_series_s5e7\n",
      "  - information_schema\n",
      "  - main\n",
      "  - pg_catalog\n",
      "  - main\n",
      "\n",
      "=== ALL TABLES WITH SCHEMA ===\n",
      "Found 7 tables:\n",
      "  - cmi_detect_behavior_with_sensor_data.test\n",
      "  - cmi_detect_behavior_with_sensor_data.test_demographics\n",
      "  - cmi_detect_behavior_with_sensor_data.train\n",
      "  - cmi_detect_behavior_with_sensor_data.train_demographics\n",
      "  - playground_series_s5e7.sample_submission\n",
      "  - playground_series_s5e7.test\n",
      "  - playground_series_s5e7.train\n",
      "\n",
      "=== SHOW TABLES ===\n",
      "Default schema tables: 0 found\n",
      "\n",
      "=== TESTING CMI SCHEMA ACCESS ===\n",
      "‚úÖ cmi_detect_behavior_with_sensor_data.train accessible: 574945 rows\n",
      "\n",
      "=== KAGGLE_DATASETS SCHEMA CONTENTS ===\n",
      "Error listing cmi schema tables: Parser Error: syntax error at or near \"FROM\"\n",
      "\n",
      "=== DATABASE FILE INFO ===\n",
      "‚úÖ Database file exists, size: 286,273,536 bytes (273.0 MB)\n"
     ]
    }
   ],
   "source": [
    "# Debug database tables issue\n",
    "print(\"=== DEBUG DATABASE TABLES ===\")\n",
    "\n",
    "# Check if connection exists\n",
    "try:\n",
    "    print(f\"Connection status: {conn}\")\n",
    "except NameError:\n",
    "    print(\"Connection not found, creating new one...\")\n",
    "    import duckdb\n",
    "    conn = duckdb.connect('/home/wsl/dev/my-study/ml/ml-note/kaggle_datasets.duckdb')\n",
    "\n",
    "# Check all schemas\n",
    "print(\"\\n=== ALL SCHEMAS ===\")\n",
    "schemas = conn.execute(\"SELECT schema_name FROM information_schema.schemata\").fetchall()\n",
    "for schema in schemas:\n",
    "    print(f\"  - {schema[0]}\")\n",
    "\n",
    "# Check all tables with schema\n",
    "print(\"\\n=== ALL TABLES WITH SCHEMA ===\")\n",
    "tables = conn.execute(\"SELECT table_schema, table_name FROM information_schema.tables WHERE table_type = 'BASE TABLE'\").fetchall()\n",
    "print(f\"Found {len(tables)} tables:\")\n",
    "for schema, table in tables:\n",
    "    print(f\"  - {schema}.{table}\")\n",
    "\n",
    "# Try SHOW TABLES in different schemas\n",
    "print(\"\\n=== SHOW TABLES ===\")\n",
    "try:\n",
    "    show_tables = conn.execute(\"SHOW TABLES\").fetchall()\n",
    "    print(f\"Default schema tables: {len(show_tables)} found\")\n",
    "    for table in show_tables:\n",
    "        print(f\"  - {table[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with SHOW TABLES: {e}\")\n",
    "\n",
    "# Try to access the CMI tables directly\n",
    "print(\"\\n=== TESTING CMI SCHEMA ACCESS ===\")\n",
    "try:\n",
    "    result = conn.execute('SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train').fetchone()\n",
    "    print(f\"‚úÖ cmi_detect_behavior_with_sensor_data.train accessible: {result[0]} rows\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error accessing cmi_detect_behavior_with_sensor_data.train: {e}\")\n",
    "\n",
    "# List all objects in kaggle_datasets schema\n",
    "print(\"\\n=== KAGGLE_DATASETS SCHEMA CONTENTS ===\")\n",
    "try:\n",
    "    result = conn.execute('SHOW TABLES FROM \"kaggle_datasets\".\"cmi_detect_behavior_with_sensor_data\"').fetchall()\n",
    "    print(f\"Tables in cmi_detect_behavior_with_sensor_data schema:\")\n",
    "    for table in result:\n",
    "        print(f\"  - {table[0]}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error listing cmi schema tables: {e}\")\n",
    "\n",
    "print(\"\\n=== DATABASE FILE INFO ===\")\n",
    "import os\n",
    "db_path = '/home/wsl/dev/my-study/ml/ml-note/kaggle_datasets.duckdb'\n",
    "if os.path.exists(db_path):\n",
    "    size = os.path.getsize(db_path)\n",
    "    print(f\"‚úÖ Database file exists, size: {size:,} bytes ({size/1024/1024:.1f} MB)\")\n",
    "else:\n",
    "    print(\"‚ùå Database file does not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "gzao13pnms5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç CMI BFRB Detection Dataset - EDA\n",
      "==================================================\n",
      "üìä Available tables in cmi_detect_behavior_with_sensor_data schema:\n",
      "  ‚úÖ test\n",
      "  ‚úÖ test_demographics\n",
      "  ‚úÖ train\n",
      "  ‚úÖ train_demographics\n",
      "\n",
      "üìà Database size: 286.3 MB with 4 tables\n",
      "üéØ Target dataset: CMI Body-Focused Repetitive Behaviors Detection\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"üîç CMI BFRB Detection Dataset - EDA\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Connect to the DuckDB database\n",
    "conn = duckdb.connect('/home/wsl/dev/my-study/ml/ml-note/kaggle_datasets.duckdb')\n",
    "\n",
    "# Show tables from the correct schema\n",
    "print(\"üìä Available tables in cmi_detect_behavior_with_sensor_data schema:\")\n",
    "tables = conn.execute(\"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'cmi_detect_behavior_with_sensor_data'\n",
    "    ORDER BY table_name\n",
    "\"\"\").fetchall()\n",
    "\n",
    "for table in tables:\n",
    "    print(f\"  ‚úÖ {table[0]}\")\n",
    "\n",
    "print(f\"\\nüìà Database size: {286.3:.1f} MB with {len(tables)} tables\")\n",
    "print(f\"üéØ Target dataset: CMI Body-Focused Repetitive Behaviors Detection\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "htdje7frgh6",
   "metadata": {},
   "source": [
    "## Key Dataset Findings\n",
    "\n",
    "### Data Size\n",
    "- **Train**: 574,945 rows across 81 participants (8,151 sequences)\n",
    "- **Test**: 107 rows across 2 participants (2 sequences)  \n",
    "- **No participant overlap** between train and test sets\n",
    "\n",
    "### Data Distribution\n",
    "- Average ~7,098 rows per participant in training\n",
    "- Average ~71 sequences per participant in training\n",
    "- Test set appears to be a small sample for submission format\n",
    "\n",
    "### Important Notes\n",
    "- This is a **time series** dataset with sequence structure\n",
    "- Need **GroupKFold by participant** to prevent data leakage\n",
    "- Large training set (~575k timesteps) suggests 50Hz sampling over multiple sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "m4mtsa81enc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATA SIZE ANALYSIS ===\n",
      "Train data rows: 574,945\n",
      "Test data rows: 107\n",
      "Train demographics: 81\n",
      "Test demographics: 2\n",
      "\n",
      "=== PARTICIPANT ANALYSIS ===\n",
      "Unique participants in train: 81\n",
      "Unique participants in test: 2\n",
      "Participants appearing in both train and test: 0\n",
      "\n",
      "=== SEQUENCE ANALYSIS ===\n",
      "Unique sequences in train: 8151\n",
      "Unique sequences in test: 2\n"
     ]
    }
   ],
   "source": [
    "# Re-establish database connection for this cell\n",
    "import duckdb\n",
    "conn = duckdb.connect('/home/wsl/dev/my-study/ml/ml-note/kaggle_datasets.duckdb')\n",
    "\n",
    "# Data size and distribution analysis\n",
    "print(\"=== DATA SIZE ANALYSIS ===\")\n",
    "\n",
    "# Check row counts\n",
    "train_count = conn.execute('SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train').fetchone()[0]\n",
    "test_count = conn.execute('SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".test').fetchone()[0]\n",
    "train_demo_count = conn.execute('SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".train_demographics').fetchone()[0]\n",
    "test_demo_count = conn.execute('SELECT COUNT(*) FROM \"cmi_detect_behavior_with_sensor_data\".test_demographics').fetchone()[0]\n",
    "\n",
    "print(f\"Train data rows: {train_count:,}\")\n",
    "print(f\"Test data rows: {test_count:,}\")\n",
    "print(f\"Train demographics: {train_demo_count:,}\")\n",
    "print(f\"Test demographics: {test_demo_count:,}\")\n",
    "\n",
    "print(\"\\n=== PARTICIPANT ANALYSIS ===\")\n",
    "\n",
    "# Unique participants\n",
    "train_participants = conn.execute('SELECT COUNT(DISTINCT subject) FROM \"cmi_detect_behavior_with_sensor_data\".train').fetchone()[0]\n",
    "test_participants = conn.execute('SELECT COUNT(DISTINCT subject) FROM \"cmi_detect_behavior_with_sensor_data\".test').fetchone()[0]\n",
    "\n",
    "print(f\"Unique participants in train: {train_participants}\")\n",
    "print(f\"Unique participants in test: {test_participants}\")\n",
    "\n",
    "# Check for overlap in participants between train and test\n",
    "overlap_check = conn.execute('''\n",
    "    SELECT COUNT(*) FROM (\n",
    "        SELECT subject FROM \"cmi_detect_behavior_with_sensor_data\".train \n",
    "        INTERSECT \n",
    "        SELECT subject FROM \"cmi_detect_behavior_with_sensor_data\".test\n",
    "    )\n",
    "''').fetchone()[0]\n",
    "\n",
    "print(f\"Participants appearing in both train and test: {overlap_check}\")\n",
    "\n",
    "print(\"\\n=== SEQUENCE ANALYSIS ===\")\n",
    "\n",
    "# Sequence counts\n",
    "train_sequences = conn.execute('SELECT COUNT(DISTINCT sequence_id) FROM \"cmi_detect_behavior_with_sensor_data\".train').fetchone()[0]\n",
    "test_sequences = conn.execute('SELECT COUNT(DISTINCT sequence_id) FROM \"cmi_detect_behavior_with_sensor_data\".test').fetchone()[0]\n",
    "\n",
    "print(f\"Unique sequences in train: {train_sequences}\")\n",
    "print(f\"Unique sequences in test: {test_sequences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ll1cpx7x8b",
   "metadata": {},
   "source": [
    "# CMI BFRB Detection - Exploratory Data Analysis\n",
    "\n",
    "## Dataset Schema Analysis\n",
    "\n",
    "### Data Structure Overview\n",
    "- **Train table**: Contains sensor data with target labels (behavior, gesture, phase)\n",
    "- **Test table**: Contains sensor data without target labels  \n",
    "- **Demographics tables**: Participant information (age, sex, handedness, physical measurements)\n",
    "\n",
    "### Sensor Features\n",
    "- **IMU sensors**: acc_x/y/z (accelerometer), rot_w/x/y/z (rotation quaternion) = 7 features\n",
    "- **Thermopile sensors**: thm_1 to thm_5 = 5 features  \n",
    "- **ToF sensors**: tof_1 to tof_5 with 64 values each (v0 to v63) = 320 features\n",
    "- **Total sensor features**: 332 per timestep\n",
    "\n",
    "### Target Variables (Train only)\n",
    "- **behavior**: Binary classification (BFRB vs non-BFRB)\n",
    "- **gesture**: Multi-class classification (specific gesture types)\n",
    "- **phase**: Multi-class classification (gesture phases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
